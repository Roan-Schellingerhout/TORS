{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c702f0cc-388f-46bf-a28c-e690340b4500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0b37a384-2c81-4e0c-b48a-e55996f22c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = \"jobs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "44f3a7ba-1d49-4612-b2aa-00f913c47b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(f\"../pre_experiment_scripts/{domain}_explanations.xlsx\", dtype={\"code 0\": str,\n",
    "                                                                                   \"code 1\": str})\n",
    "# df = df.drop(columns = [\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "57b43489-5b65-4314-8d51-98518d863935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code 0</th>\n",
       "      <th>code 1</th>\n",
       "      <th>prompt A</th>\n",
       "      <th>prompt B</th>\n",
       "      <th>explanation A</th>\n",
       "      <th>explanation B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000</td>\n",
       "      <td>000001</td>\n",
       "      <td>Generate an explanation with the following dim...</td>\n",
       "      <td>Generate an explanation with the following dim...</td>\n",
       "      <td>```html\\n&lt;h3&gt;Recommended Role: Cashier&lt;/h3&gt;\\nT...</td>\n",
       "      <td>```html\\n&lt;h3&gt;Recommended Role: Cashier&lt;/h3&gt;\\nY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000000</td>\n",
       "      <td>000010</td>\n",
       "      <td>Generate an explanation with the following dim...</td>\n",
       "      <td>Generate an explanation with the following dim...</td>\n",
       "      <td>```html\\n&lt;h3&gt;Recommended Role: Cashier&lt;/h3&gt;\\nT...</td>\n",
       "      <td>```html\\n&lt;h3&gt;Recommended Role: Cashier&lt;/h3&gt;\\nY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000000</td>\n",
       "      <td>000100</td>\n",
       "      <td>Generate an explanation with the following dim...</td>\n",
       "      <td>Generate an explanation with the following dim...</td>\n",
       "      <td>```html\\n&lt;h3&gt;Recommended Role: Cashier&lt;/h3&gt;\\nT...</td>\n",
       "      <td>```html\\n&lt;h3&gt;Recommended Role: Cashier&lt;/h3&gt;\\nH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000000</td>\n",
       "      <td>001000</td>\n",
       "      <td>Generate an explanation with the following dim...</td>\n",
       "      <td>Generate an explanation with the following dim...</td>\n",
       "      <td>```html\\n&lt;h3&gt;Recommended Role: Cashier&lt;/h3&gt;\\nT...</td>\n",
       "      <td>```html\\n&lt;h3&gt;Recommended Role: Cashier&lt;/h3&gt;\\n&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000000</td>\n",
       "      <td>010000</td>\n",
       "      <td>Generate an explanation with the following dim...</td>\n",
       "      <td>Generate an explanation with the following dim...</td>\n",
       "      <td>```html\\n&lt;h3&gt;Recommended Role: Cashier&lt;/h3&gt;\\nT...</td>\n",
       "      <td>```html\\n&lt;h3&gt;Recommended Role: Cashier&lt;/h3&gt;\\nT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code 0  code 1                                           prompt A  \\\n",
       "0  000000  000001  Generate an explanation with the following dim...   \n",
       "1  000000  000010  Generate an explanation with the following dim...   \n",
       "2  000000  000100  Generate an explanation with the following dim...   \n",
       "3  000000  001000  Generate an explanation with the following dim...   \n",
       "4  000000  010000  Generate an explanation with the following dim...   \n",
       "\n",
       "                                            prompt B  \\\n",
       "0  Generate an explanation with the following dim...   \n",
       "1  Generate an explanation with the following dim...   \n",
       "2  Generate an explanation with the following dim...   \n",
       "3  Generate an explanation with the following dim...   \n",
       "4  Generate an explanation with the following dim...   \n",
       "\n",
       "                                       explanation A  \\\n",
       "0  ```html\\n<h3>Recommended Role: Cashier</h3>\\nT...   \n",
       "1  ```html\\n<h3>Recommended Role: Cashier</h3>\\nT...   \n",
       "2  ```html\\n<h3>Recommended Role: Cashier</h3>\\nT...   \n",
       "3  ```html\\n<h3>Recommended Role: Cashier</h3>\\nT...   \n",
       "4  ```html\\n<h3>Recommended Role: Cashier</h3>\\nT...   \n",
       "\n",
       "                                       explanation B  \n",
       "0  ```html\\n<h3>Recommended Role: Cashier</h3>\\nY...  \n",
       "1  ```html\\n<h3>Recommended Role: Cashier</h3>\\nY...  \n",
       "2  ```html\\n<h3>Recommended Role: Cashier</h3>\\nH...  \n",
       "3  ```html\\n<h3>Recommended Role: Cashier</h3>\\n<...  \n",
       "4  ```html\\n<h3>Recommended Role: Cashier</h3>\\nT...  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2f7347ea-1cd8-4592-9878-4c3368ff3eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = defaultdict(list)\n",
    "\n",
    "def code_to_list(row):\n",
    "\n",
    "    row_dict = defaultdict(list)\n",
    "    \n",
    "    features = [\"Domain\", \"Length\", \"Structure\", \"Formality\", \"Detail\", \"Persuasiveness\"]\n",
    "    flipped = [\"Formality\", \"Detail\", \"Persuasiveness\"]\n",
    "\n",
    "    mapping = {\"Domain\" : {\"1\": \"High-stakes\", \"0\": \"Low-stakes\"},\n",
    "               \"Length\" : {\"1\": \"Long\", \"0\": \"Short\"},\n",
    "               \"Structure\" : {\"1\": \"Bulleted\", \"0\": \"Running\"},\n",
    "               \"Formality\" : {\"1\": \"Informal\", \"0\": \"Formal\"},\n",
    "               \"Detail\" : {\"1\": \"Aggregated\", \"0\": \"Detailed\"},\n",
    "               \"Persuasiveness\": {\"1\": \"Decision-support\", \"0\": \"Persuasive\"}}\n",
    "\n",
    "    row_dict[\"Code\"].append(row[\"code 0\"])\n",
    "    row_dict[\"Explanation\"].append(row[\"explanation A\"])\n",
    "        \n",
    "    for feature, bit in enumerate(row[\"code 0\"]):\n",
    "        current = features[feature]\n",
    "        value = mapping[current][bit]\n",
    "\n",
    "        row_dict[current].append(value)\n",
    "\n",
    "    row_dict[\"Code\"].append(row[\"code 1\"])\n",
    "    row_dict[\"Explanation\"].append(row[\"explanation B\"])\n",
    "        \n",
    "    for feature, bit in enumerate(row[\"code 1\"]):\n",
    "        current = features[feature]\n",
    "        value = mapping[current][bit]\n",
    "\n",
    "        row_dict[current].append(value)\n",
    "\n",
    "    return row_dict\n",
    "\n",
    "for row in df.iterrows():\n",
    "    output = code_to_list(row[1])\n",
    "    for k, v in output.items():\n",
    "        new_df[k].extend(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "77860d5e-8797-4a3c-aa31-25d287d7e8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.DataFrame.from_dict(new_df).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9b59eb7f-a279-4af2-b617-46355da34505",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[\"Explanation\"] = df_clean[\"Explanation\"].apply(lambda x: BeautifulSoup(x, \"lxml\").text)\n",
    "df_clean[\"Explanation\"] = df_clean[\"Explanation\"].str.replace(\"```\", \"\").str.replace(\"html\", \"\").str.replace(\"\\n\", \" \").str.lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a2ae5c74-7aa0-413d-be6c-6b6c004f8d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Explanation</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Length</th>\n",
       "      <th>Structure</th>\n",
       "      <th>Formality</th>\n",
       "      <th>Detail</th>\n",
       "      <th>Persuasiveness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000</td>\n",
       "      <td>Recommended Role: Cashier The Cashier position...</td>\n",
       "      <td>Low-stakes</td>\n",
       "      <td>Short</td>\n",
       "      <td>Running</td>\n",
       "      <td>Formal</td>\n",
       "      <td>Detailed</td>\n",
       "      <td>Persuasive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000001</td>\n",
       "      <td>Recommended Role: Cashier Your previous custom...</td>\n",
       "      <td>Low-stakes</td>\n",
       "      <td>Short</td>\n",
       "      <td>Running</td>\n",
       "      <td>Formal</td>\n",
       "      <td>Detailed</td>\n",
       "      <td>Decision-support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000010</td>\n",
       "      <td>Recommended Role: Cashier Your skills make you...</td>\n",
       "      <td>Low-stakes</td>\n",
       "      <td>Short</td>\n",
       "      <td>Running</td>\n",
       "      <td>Formal</td>\n",
       "      <td>Aggregated</td>\n",
       "      <td>Persuasive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000100</td>\n",
       "      <td>Recommended Role: Cashier Hey! The Cashier rol...</td>\n",
       "      <td>Low-stakes</td>\n",
       "      <td>Short</td>\n",
       "      <td>Running</td>\n",
       "      <td>Informal</td>\n",
       "      <td>Detailed</td>\n",
       "      <td>Persuasive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>001000</td>\n",
       "      <td>Recommended Role: Cashier  Your customer servi...</td>\n",
       "      <td>Low-stakes</td>\n",
       "      <td>Short</td>\n",
       "      <td>Bulleted</td>\n",
       "      <td>Formal</td>\n",
       "      <td>Detailed</td>\n",
       "      <td>Persuasive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Code                                        Explanation      Domain  \\\n",
       "0  000000  Recommended Role: Cashier The Cashier position...  Low-stakes   \n",
       "1  000001  Recommended Role: Cashier Your previous custom...  Low-stakes   \n",
       "3  000010  Recommended Role: Cashier Your skills make you...  Low-stakes   \n",
       "5  000100  Recommended Role: Cashier Hey! The Cashier rol...  Low-stakes   \n",
       "7  001000  Recommended Role: Cashier  Your customer servi...  Low-stakes   \n",
       "\n",
       "  Length Structure Formality      Detail    Persuasiveness  \n",
       "0  Short   Running    Formal    Detailed        Persuasive  \n",
       "1  Short   Running    Formal    Detailed  Decision-support  \n",
       "3  Short   Running    Formal  Aggregated        Persuasive  \n",
       "5  Short   Running  Informal    Detailed        Persuasive  \n",
       "7  Short  Bulleted    Formal    Detailed        Persuasive  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f5ccf1ec-8667-480d-9600-36bd7632a68f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptives for Low-stakes:\n",
      "   - Mean word count     : 102.97297297297297 (42.375262822346)\n",
      "   - Mean word length    : 5.52422004774462 (0.5676359496476335)\n",
      "   - Mean sentence length: 15.55111075111075 (3.1795704886702594)\n",
      "\n",
      "Descriptives for High-stakes:\n",
      "   - Mean word count     : 105.34234234234235 (43.88093300895369)\n",
      "   - Mean word length    : 5.622403562437031 (0.550442769224684)\n",
      "   - Mean sentence length: 15.343408093408092 (3.45061768771275)\n",
      "\n",
      "\n",
      "Descriptives for Short:\n",
      "   - Mean word count     : 65.5625 (17.243648716342825)\n",
      "   - Mean word length    : 5.586629317102307 (0.6029008398895579)\n",
      "   - Mean sentence length: 13.368315972222225 (2.5946853379394117)\n",
      "\n",
      "Descriptives for Long:\n",
      "   - Mean word count     : 133.56349206349208 (32.17986849736861)\n",
      "   - Mean word length    : 5.563165129272554 (0.5272212890042761)\n",
      "   - Mean sentence length: 17.031216336573475 (2.9032230799883894)\n",
      "\n",
      "\n",
      "Descriptives for Running:\n",
      "   - Mean word count     : 118.76041666666667 (42.32126373390908)\n",
      "   - Mean word length    : 5.544864917654093 (0.5672312440577842)\n",
      "   - Mean sentence length: 17.030906911375663 (2.9482238537384022)\n",
      "\n",
      "Descriptives for Bulleted:\n",
      "   - Mean word count     : 93.03174603174604 (40.340736038488245)\n",
      "   - Mean word length    : 5.594985624090241 (0.5557231895840294)\n",
      "   - Mean sentence length: 14.24067085912324 (3.064975553200786)\n",
      "\n",
      "\n",
      "Descriptives for Formal:\n",
      "   - Mean word count     : 101.5625 (40.77352404634526)\n",
      "   - Mean word length    : 6.057167956375207 (0.3765501319327935)\n",
      "   - Mean sentence length: 15.387829936267437 (3.4823896971345363)\n",
      "\n",
      "Descriptives for Informal:\n",
      "   - Mean word count     : 106.13492063492063 (44.77219729691241)\n",
      "   - Mean word length    : 5.2046594993503446 (0.36041697186994914)\n",
      "   - Mean sentence length: 15.492539030634266 (3.1894020670780465)\n",
      "\n",
      "\n",
      "Descriptives for Detailed:\n",
      "   - Mean word count     : 113.0 (43.4380381450951)\n",
      "   - Mean word length    : 5.556761468809106 (0.47433006479075907)\n",
      "   - Mean sentence length: 15.70510797073297 (3.0206605316443373)\n",
      "\n",
      "Descriptives for Aggregated:\n",
      "   - Mean word count     : 97.42063492063492 (41.68133456109162)\n",
      "   - Mean word length    : 5.585921585114995 (0.6189442179117763)\n",
      "   - Mean sentence length: 15.250803385327194 (3.516974868027198)\n",
      "\n",
      "\n",
      "Descriptives for Persuasive:\n",
      "   - Mean word count     : 95.28125 (38.71806408954489)\n",
      "   - Mean word length    : 5.634980532744719 (0.5443274829312653)\n",
      "   - Mean sentence length: 15.978805916305916 (3.628272289683672)\n",
      "\n",
      "Descriptives for Decision-support:\n",
      "   - Mean word count     : 110.92063492063492 (45.06912081229953)\n",
      "   - Mean word length    : 5.526326107830717 (0.5693206134489807)\n",
      "   - Mean sentence length: 15.042271617271615 (3.001063284879717)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def calcs(exps):\n",
    "    print(f\"   - Mean word count     : {exps.str.split().apply(len).mean()} ({exps.str.split().apply(len).std()})\")\n",
    "    print(f\"   - Mean word length    : {exps.str.split().apply(lambda x : np.mean([len(i) for i in x])).mean()} ({exps.str.split().apply(lambda x : np.mean([len(i) for i in x])).std()})\")\n",
    "    print(f\"   - Mean sentence length: {exps.str.split(\".\").apply(lambda x: np.mean([len(i.split()) for i in x])).mean()} ({exps.str.split(\".\").apply(lambda x: np.mean([len(i.split()) for i in x])).std()})\")\n",
    "    print()\n",
    "\n",
    "def descriptive_checker(df, feature):\n",
    "    options = df[feature].unique()\n",
    "\n",
    "    for option in options:\n",
    "        print(f\"Descriptives for {option}:\")\n",
    "        calcs(df[df[feature] == option][\"Explanation\"])\n",
    "\n",
    "    print()\n",
    "\n",
    "for feature in [\"Domain\", \"Length\", \"Structure\", \"Formality\", \"Detail\", \"Persuasiveness\"]:\n",
    "    descriptive_checker(df_clean, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "15569033-655a-4d9d-8aec-40d10a6fcce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\roans\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "from textstat import flesch_reading_ease, flesch_kincaid_grade, gunning_fog\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import Tree\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "# Load spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "58cc9c44-cddc-4d83-9300-f0800ce3c816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_subordinate_clauses(doc):\n",
    "    return sum(1 for token in doc if token.dep_ in (\"advcl\", \"relcl\", \"csubj\", \"ccomp\", \"xcomp\"))\n",
    "\n",
    "def heylighen_formality(doc):\n",
    "    tags = [token.tag_ for token in doc]\n",
    "    pos_counts = Counter(tags)\n",
    "    total = sum(pos_counts.values())\n",
    "    formal = sum(pos_counts.get(tag, 0) for tag in ['NN', 'NNS', 'NNP', 'NNPS', 'JJ', 'IN', 'DT'])\n",
    "    informal = sum(pos_counts.get(tag, 0) for tag in ['PRP', 'PRP$', 'RB', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'])\n",
    "    return 50 * ((formal - informal) / total + 1) if total > 0 else 0.0\n",
    "\n",
    "\n",
    "# Apply feature extraction\n",
    "def extract_features(row):\n",
    "    text = row[\"Explanation\"]\n",
    "    doc = nlp(text)\n",
    "    blob = TextBlob(text)\n",
    "    \n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    word_count = len(words)\n",
    "    word_lengths = [len(w) for w in words if w.isalpha()]\n",
    "    sentence_lengths = [len(nltk.word_tokenize(s)) for s in sentences]\n",
    "\n",
    "    return pd.Series({\n",
    "        \"word_count\": word_count,\n",
    "        \"avg_word_length\": np.mean(word_lengths) if word_lengths else 0,\n",
    "        \"avg_sentence_length\": np.mean(sentence_lengths) if sentence_lengths else 0,\n",
    "        \"gunning_fog\": gunning_fog(text),\n",
    "        \"sentiment_polarity\": blob.sentiment.polarity,\n",
    "        \"sentiment_subjectivity\": blob.sentiment.subjectivity,\n",
    "        \"subordinate_clauses\": count_subordinate_clauses(doc),\n",
    "        \"formality_score\": heylighen_formality(doc),\n",
    "    })\n",
    "\n",
    "# Apply to the DataFrame\n",
    "df_features = df_clean.apply(extract_features, axis=1)\n",
    "\n",
    "# Combine with original\n",
    "df_enriched = pd.concat([df_clean, df_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75f8418-ee35-4d4c-9b89-e483a4e4e781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "73c2370f-9bf0-4dd4-9e69-fe21a69cfa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    " import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import statsmodels.api as sm\n",
    "\n",
    "data = [\n",
    "    (\"Need_for_Cognition:Detail\", 0.841, \"Detail\"),\n",
    "    (\"Need_for_Cognition:Formality\", 1.348, \"Formality\"),\n",
    "    (\"Need_for_Cognition:Length\", 0.535, \"Length\"),\n",
    "    (\"Need_for_Cognition:Persuasiveness\", 0.014, \"Persuasiveness\"),\n",
    "    (\"Need_for_Cognition:Structure\", -2.737, \"Structure\"),\n",
    "    \n",
    "    (\"Need_for_closure:Detail\", -2.751, \"Detail\"),\n",
    "    (\"Need_for_closure:Formality\", -0.738, \"Formality\"),\n",
    "    (\"Need_for_closure:Length\", -2.401, \"Length\"),\n",
    "    (\"Need_for_closure:Persuasiveness\", -0.662, \"Persuasiveness\"),\n",
    "    (\"Need_for_closure:Structure\", 6.553, \"Structure\"),\n",
    "    \n",
    "    (\"Susceptibility_to_persuasion:Detail\", -0.992, \"Detail\"),\n",
    "    (\"Susceptibility_to_persuasion:Formality\", -1.884, \"Formality\"),\n",
    "    (\"Susceptibility_to_persuasion:Length\", -0.185, \"Length\"),\n",
    "    (\"Susceptibility_to_persuasion:Persuasiveness\", 1.677, \"Persuasiveness\"),\n",
    "    (\"Susceptibility_to_persuasion:Structure\", 1.383, \"Structure\"),\n",
    "    \n",
    "    (\"Skepticism:Detail\", 3.332, \"Detail\"),\n",
    "    (\"Skepticism:Formality\", 1.882, \"Formality\"),\n",
    "    (\"Skepticism:Length\", 2.358, \"Length\"),\n",
    "    (\"Skepticism:Persuasiveness\", 0.606, \"Persuasiveness\"),\n",
    "    (\"Skepticism:Structure\", -8.178, \"Structure\"),\n",
    "    \n",
    "    (\"AI_Expertise:Detail\", -1.569, \"Detail\"),\n",
    "    (\"AI_Expertise:Formality\", -0.992, \"Formality\"),\n",
    "    (\"AI_Expertise:Length\", -0.749, \"Length\"),\n",
    "    (\"AI_Expertise:Persuasiveness\", -0.476, \"Persuasiveness\"),\n",
    "    (\"AI_Expertise:Structure\", 3.856, \"Structure\"),\n",
    "]\n",
    "\n",
    "\n",
    "# Convert to DataFrame\n",
    "interactions_df = pd.DataFrame(data, columns=[\"interaction\", \"coefficient\", \"dimension\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "969801c7-ed98-4af6-a6e8-14d65478474c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Detail  word_count  avg_word_length  avg_sentence_length  gunning_fog  \\\n",
      "0  Aggregated  111.087302         5.382220            19.297831    14.986934   \n",
      "1    Detailed  133.791667         5.438871            20.543579    15.522532   \n",
      "\n",
      "   sentiment_polarity  sentiment_subjectivity  subordinate_clauses  \\\n",
      "0            0.239371                0.502699             6.666667   \n",
      "1            0.185037                0.480172             6.906250   \n",
      "\n",
      "   formality_score  \n",
      "0        64.323932  \n",
      "1        67.867191  \n"
     ]
    }
   ],
   "source": [
    "# List of features to average\n",
    "features = [\"word_count\", \"avg_word_length\", \"avg_sentence_length\", \n",
    "            \"gunning_fog\", \"sentiment_polarity\", \"sentiment_subjectivity\",\n",
    "            \"subordinate_clauses\", \"formality_score\"\n",
    "]\n",
    "\n",
    "# Example: grouping by Detail level (Detailed vs Aggregated)\n",
    "grouped_detail = df_enriched.groupby(\"Detail\")[features].mean().reset_index()\n",
    "print(grouped_detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ec57773d-33f2-4acf-9c2c-28f053702fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of dimensions you're analyzing\n",
    "dimensions = [\"Detail\", \"Formality\", \"Length\", \"Structure\", \"Persuasiveness\"]\n",
    "\n",
    "# Collect difference vectors per design dimension\n",
    "dimension_diffs = {}\n",
    "\n",
    "for dim in dimensions:\n",
    "    grouped = df_enriched.groupby(dim)[features].mean()\n",
    "    \n",
    "    if grouped.shape[0] != 2:\n",
    "        print(f\"Skipping {dim}: not binary\")\n",
    "        continue\n",
    "\n",
    "    # Compute difference between high and low (order will depend on groupby key sort)\n",
    "    diff = grouped.diff().iloc[-1]  # assumes row order: [Low, High] → diff = High - Low\n",
    "    dimension_diffs[dim] = diff\n",
    "\n",
    "df_diffs = pd.DataFrame(dimension_diffs).T  # shape: (5 dimensions) × (n features)\n",
    "df_diffs.index.name = \"dimension\"\n",
    "df_diffs.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4b131f29-59c4-47bf-921b-b05c8af4945b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interaction</th>\n",
       "      <th>coefficient</th>\n",
       "      <th>dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Need_for_Cognition:Detail</td>\n",
       "      <td>0.841</td>\n",
       "      <td>Detail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Need_for_Cognition:Formality</td>\n",
       "      <td>1.348</td>\n",
       "      <td>Formality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Need_for_Cognition:Length</td>\n",
       "      <td>0.535</td>\n",
       "      <td>Length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Need_for_Cognition:Persuasiveness</td>\n",
       "      <td>0.014</td>\n",
       "      <td>Persuasiveness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Need_for_Cognition:Structure</td>\n",
       "      <td>-2.737</td>\n",
       "      <td>Structure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         interaction  coefficient       dimension\n",
       "0          Need_for_Cognition:Detail        0.841          Detail\n",
       "1       Need_for_Cognition:Formality        1.348       Formality\n",
       "2          Need_for_Cognition:Length        0.535          Length\n",
       "3  Need_for_Cognition:Persuasiveness        0.014  Persuasiveness\n",
       "4       Need_for_Cognition:Structure       -2.737       Structure"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interactions = pd.DataFrame(data).rename(columns = {0: \"interaction\", 1: \"coefficient\", 2: \"dimension\"})\n",
    "df_interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0757a001-644b-40a6-91c5-7e144b892adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between interaction coefficient and Δword_count: r = 0.004, p = 0.984\n",
      "Correlation between interaction coefficient and Δavg_word_length: r = 0.013, p = 0.953\n",
      "Correlation between interaction coefficient and Δavg_sentence_length: r = 0.020, p = 0.923\n",
      "Correlation between interaction coefficient and Δgunning_fog: r = 0.022, p = 0.915\n",
      "Correlation between interaction coefficient and Δsentiment_polarity: r = 0.031, p = 0.882\n",
      "Correlation between interaction coefficient and Δsentiment_subjectivity: r = 0.038, p = 0.857\n",
      "Correlation between interaction coefficient and Δsubordinate_clauses: r = 0.008, p = 0.971\n",
      "Correlation between interaction coefficient and Δformality_score: r = -0.027, p = 0.900\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have this already:\n",
    "# df_interactions = DataFrame with ['interaction', 'coefficient', 'dimension']\n",
    "\n",
    "# Merge in design feature diffs\n",
    "df_full = df_interactions.merge(df_diffs, on=\"dimension\", how=\"left\")\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "for feature in features:\n",
    "    corr, p = pearsonr(df_full[\"coefficient\"], df_full[feature])\n",
    "    print(f\"Correlation between interaction coefficient and Δ{feature}: r = {corr:.3f}, p = {p:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d09b7f68-5abe-4d29-aa3c-f1c875d5d3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trait: Need_for_Cognition\n",
      "  Correlation with Δavg_sentence_length: r = -0.669, p = 0.217\n",
      "  Correlation with Δgunning_fog: r = -0.574, p = 0.312\n",
      "\n",
      "Trait: Need_for_closure\n",
      "  Correlation with Δword_count: r = 0.490, p = 0.402\n",
      "  Correlation with Δavg_sentence_length: r = 0.618, p = 0.267\n",
      "  Correlation with Δsubordinate_clauses: r = 0.546, p = 0.341\n",
      "\n",
      "Trait: Susceptibility_to_persuasion\n",
      "  Correlation with Δavg_word_length: r = 0.658, p = 0.227\n",
      "  Correlation with Δavg_sentence_length: r = 0.450, p = 0.448\n",
      "  Correlation with Δgunning_fog: r = 0.754, p = 0.141\n",
      "  Correlation with Δsentiment_subjectivity: r = 0.495, p = 0.396\n",
      "\n",
      "Trait: Skepticism\n",
      "  Correlation with Δword_count: r = -0.422, p = 0.479\n",
      "  Correlation with Δavg_sentence_length: r = -0.622, p = 0.262\n",
      "  Correlation with Δsubordinate_clauses: r = -0.453, p = 0.444\n",
      "\n",
      "Trait: AI_Expertise\n",
      "  Correlation with Δavg_sentence_length: r = 0.581, p = 0.304\n"
     ]
    }
   ],
   "source": [
    "df_full[\"trait\"] = df_full[\"interaction\"].apply(lambda x: x.split(\":\")[0])\n",
    "traits = df_full[\"trait\"].unique()\n",
    "\n",
    "for trait in traits:\n",
    "    print(f\"\\nTrait: {trait}\")\n",
    "    subset = df_full[df_full[\"trait\"] == trait]\n",
    "    for feature in features:\n",
    "        corr, p = pearsonr(subset[\"coefficient\"], subset[feature])\n",
    "        if abs(corr) > 0.4:\n",
    "            print(f\"  Correlation with Δ{feature}: r = {corr:.3f}, p = {p:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05457ea3-09f5-43d6-a91f-4c0752e21282",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
