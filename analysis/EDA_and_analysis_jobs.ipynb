{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44b28984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import statsmodels\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import datetime as dt\n",
    "\n",
    "from factor_analyzer import FactorAnalyzer, ConfirmatoryFactorAnalyzer, ModelSpecificationParser\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import zscore, chi2, norm, multivariate_normal, spearmanr, pearsonr, shapiro\n",
    "from scipy.optimize import minimize\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b8d766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data, drop test entry\n",
    "df = pd.read_csv(\"jobs.csv\", on_bad_lines=\"skip\", delimiter=\";\")\n",
    "df = df[df[\"Finished\"] == \"TRUE\"].drop(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "302a2df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roans\\AppData\\Local\\Temp\\ipykernel_22700\\1763983717.py:3: UserWarning: Parsing dates in %d-%m-%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  times[\"total\"] = pd.to_datetime(times[\"EndDate\"]) - pd.to_datetime(times[\"StartDate\"])\n",
      "C:\\Users\\roans\\AppData\\Local\\Temp\\ipykernel_22700\\1763983717.py:3: UserWarning: Parsing dates in %d-%m-%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  times[\"total\"] = pd.to_datetime(times[\"EndDate\"]) - pd.to_datetime(times[\"StartDate\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timedelta('0 days 00:18:16.562500')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate average time to complete survey\n",
    "times = df.iloc[2:][[\"StartDate\", \"EndDate\"]]\n",
    "times[\"total\"] = pd.to_datetime(times[\"EndDate\"]) - pd.to_datetime(times[\"StartDate\"])\n",
    "times[\"total\"].sort_values().iloc[:-1].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba94619-42e1-4e06-b07a-824512c21106",
   "metadata": {},
   "source": [
    "## Drop evaluations that were made too quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dee5060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottom 10th percetile of time per question: 9.3463s\n",
      "Number of evaluations that took longer than b10: 1755\n"
     ]
    }
   ],
   "source": [
    "all_times = []\n",
    "qs = []\n",
    "\n",
    "for row in df.T.iloc[17:].itertuples():\n",
    "    if row[0].endswith(\"Page Submit\"):\n",
    "        \n",
    "        # Questions 201-361 are the actual explanation pair questions\n",
    "        qnum = int(row[0].split(\"_\")[0][1:])\n",
    "        \n",
    "        if 201 <= qnum <= 362:\n",
    "            times = np.array([float(i) for i in row[1:]])\n",
    "            times_filtered = [i for i in times if not np.isnan(i)]\n",
    "            all_times.extend(times_filtered)\n",
    "            qs.extend([qnum] * len(times_filtered))\n",
    "\n",
    "all_times = np.array(all_times)\n",
    "qs = np.array(qs)\n",
    "b10 = np.quantile(all_times, q=.1)\n",
    "print(f\"Bottom 10th percetile of time per question: {b10}s\")\n",
    "print(f\"Number of evaluations that took longer than b10: {len(qs[all_times >= b10])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88aaec27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKYAAAJOCAYAAACN2Q8zAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAACBrUlEQVR4nOzdZ3hU1fr38d8kQBIghBKqQIh0pDdRahQpAqKCiEoRGypSxAZKVRBFxYYFOEc4cqSIIoIUUTqHIl16kQ6hBEgCAVLX84J/5mFIJiSTSXYy8/1cF5fOrve919p7Zu7svcZmjDECAAAAAAAAspmP1QEAAAAAAADAO1GYAgAAAAAAgCUoTAEAAAAAAMASFKYAAAAAAABgCQpTAAAAAAAAsASFKQAAAAAAAFiCwhQAAAAAAAAsQWEKAAAAAAAAlqAwBQAAAAAAAEtQmAIA5EoVKlRQhQoV0r38tGnTZLPZNG3atCyLCfBErVq1ks1mszqMXG3lypWy2WwaNWqU1aF4ldTeJ3gvAICch8IUAOC2kr9UPf3005laxlscO3ZMvr6+stls+uijj6wOxyMkf5m8+V9AQICqVaumwYMHKyIiwtL4VqxYoccff1zlypWTn5+fihUrpubNm+vLL79UXFycpbHdzqhRo2Sz2bRy5UqrQ8kyV69e1SeffKInn3xS1apVk4+Pj2w2m44ePZrmegcOHFC3bt0UHBysgIAA1alTR998842MMSmWzWixHJn39NNPp6sdAQA5Wx6rAwAAwNN89913SkpKks1m03fffac33njD6pA8xv33369mzZpJks6fP6/ff/9dn376qebOnastW7aoWLFi2RpPQkKC+vXrp8mTJ6tAgQJq3769KlWqpKioKC1dulQDBgzQpEmTtGjRIpUvXz5bY3OX77//XlevXrU6jEw5d+6cXn/9dUlSSEiIihQpoosXL6a5zp49e3Tvvffq2rVr6tatm8qUKaOFCxfq5Zdf1p49e/Tll19mR+jIhGXLllkdAgAgHShMAQDgRklJSZo2bZqCg4PVsWNHTZs2TevWrdO9995rdWgeoXXr1hoyZIj9dXx8vNq2basVK1boyy+/zPZHpYYOHarJkyerUaNG+uWXX3THHXfY5yUmJurdd9/Vu+++qwcffFCbNm1SQEBAtsbnDrm1oHaz4OBgLV26VA0aNFDRokXVrl07/f7772mu89JLLykqKkqLFi1S+/btJUnvvfeeWrdurYkTJ+rJJ5/UPffckx3hw0UVK1a0OgQAQDrwKB8AIEsdPHhQffr0UWhoqPz8/FS0aFHVqVNHgwYNcngcZsuWLXrllVdUs2ZNBQUFKSAgQLVq1dIHH3yg+Ph4p9uPjIxU3759VapUKfn7+6tevXqaOXNmhmI8cuSInnvuOZUvX15+fn4qXbq0nn76aR07dizD+f7xxx86fvy4unfvrmeffVaS9O9//zvVZW8e62Tp0qW69957lT9/fhUrVky9e/fWhQsXUqyzYsUKtW/fXmXKlJGfn59Kliyp5s2ba/LkyfZl6tWrp6CgICUmJtqnJSUlqWjRorLZbPrXv/7lsM3kR7lWrVrl8nGx2Wxq1aqVTp06pV69eqlUqVLy8fGxPx6W3n6QUXnz5lXfvn0lSZs2bbJPj4uL04QJE1S/fn0VKFBAgYGBat68uebPn59iG8mPAx0+fFiffPKJatSoIT8/v9s+lnrgwAFNmDBBRYsW1YIFCxyKUpLk6+ur0aNH68knn9Tu3bv1+eefO8xPPmapcfZYWEbyioqK0ogRI1SjRg0VLFhQhQoVUqVKldS7d297G7Zq1UqjR4+WJIWFhdkfk7x5387GmEpISNCECRNUp04dBQQEKCgoSGFhYVqwYEGKZV3p6+5UsGBBPfDAAypatGi6lj9w4IBWr16tsLAwe1FKkvLly6f33ntPkjRlyhRJ0tGjR2Wz2XTs2DEdO3bM4XHT1Aqlmzdv1gMPPKDAwEAFBQXpkUceydCjaMntcf36dQ0ZMkTly5eXv7+/qlevri+//NLp+fTrr7/q/vvvV5EiReTv76+aNWvq448/drhOSI5ttWDBAjVt2lSBgYEOfSIuLk6ffvqpGjVqpMDAQBUsWFA1atTQ4MGDdenSJYftnTt3Tq+++qoqVaokPz8/BQcHq0uXLtq1a1eKGJP7/ZUrVzRw4ED7da527dr66aefUiz7n//8R5IUGhpqP+Y3n1MZfbzSne8FAID0444pAECWOX36tBo3bqyYmBh16NBBjz/+uGJiYnTw4EF9/fXX+vjjj5Unz423oilTpmjBggVq0aKFHnzwQV29elUrV67U0KFDtWnTJv38888pth8XF6fWrVvrypUr6tmzp2JiYvTjjz/qySefVEREhPr373/bGDdu3Ki2bdsqJiZGHTt2VOXKlXX06FH98MMPWrx4sdavX68777wz3TknF6F69eqlRo0a6c4779SPP/6ozz//XAULFkx1nfnz52vhwoXq1KmT7r33Xq1evVrff/+9/vnnH61du9a+XPIyhQsXVufOnVW6dGmdP39eO3bs0PTp0/XCCy9IulFg2L59u7Zu3apGjRpJknbs2GH/wrhixQo999xz9u2uWLFC/v7+atKkSaaOy4ULF3TPPfeoaNGi6t69u65fv65ChQplqB9kRnLxJDY2Vu3atdPKlStVt25dPfvss4qPj9fChQvVuXNnffnll3rllVdSrN+/f39t2LBBHTp0UKdOnVSiRIk09/ef//xHSUlJeuGFF1SyZEmnyw0fPlwzZszQlClTHO72yqiM5GWMUdu2bbVx40Y1bdpU7dq1k4+Pj44dO6b58+erZ8+eCgkJsRffVq1apd69e9u/xBcuXDjNWIwx6tq1q3799VdVqVJF/fr1U0xMjGbPnq2HHnpIEyZM0KuvvppivfT2daslF1TbtGmTYl6zZs1UoEABeyG3cOHCGjlypD777DNJ0qBBg+zL3lp43LRpk8aPH6+wsDD17dtX27Zt07x587Rz507t2rVL/v7+6Y6xW7du2rZtm7p06SJJ+vnnnzVgwAAdPXpUn3zyicOyQ4cO1QcffKA77rhDjz76qIKCgrRmzRq98cYb2rhxo+bMmZNi+3PmzNHSpUvVsWNHvfzyy4qOjpYkXbt2TQ888ID+97//qXLlyurTp4/8/Px08OBBTZo0Sb169VKRIkUkSf/8849atWqlkydPqk2bNnr44Yd17tw5/fzzz/r999+1bNky3X333Q77jY+PV5s2bXTp0iV16dJFV69e1axZs9StWzctWbLE3iaDBg3StGnTtGPHDg0cONDeZ10d58vd7wUAgAwwAADcxooVK4wk07t37wwt88UXXxhJ5rPPPkux/IULFxxeHzt2zCQkJDhMS0pKMs8884yRZNauXeswLyQkxEgyLVq0MLGxsfbpJ06cMMHBwcbPz8+cPHnSPn3q1KlGkpk6dap9WlxcnKlQoYIJDAw0W7duddj+mjVrjK+vr+nYsaPTnG8VERFh8uXLZ6pVq2afNmLECCPJ/Otf/0qxfHJMefLkccgvISHBtGrVykgy69evt09/9NFHjSSzffv2VPedbP78+UaS+fDDD+3TPvnkEyPJ3H///aZ06dL26VevXjX58uUz9913n32aK8dFkpFk+vTpk6IdM9IPnEk+VuPGjXOYHh8fb+677z4jyYwePdoYY8zbb79tJJnhw4ebpKQk+7LR0dGmYcOGJl++fObUqVP26b179zaSTNmyZc2xY8fSFY8xxt5Gf/zxx22XLVOmjJFkwsPD7dMkmZYtW6a6fEhIiAkJCXGYlpG8/v77byPJPPzwwym2ff36dXP58mX765EjRxpJZsWKFanG0rJlS3PrR8b//Oc/9vhvPv+OHTtmgoODTZ48ecw///xjn57Rvp7V2rZtaySZI0eOpDr/9ddfN5LMTz/9lOr8mjVrGh8fHxMfH2+fllqbJUu+Pkoys2bNcpjXs2dPI8nMnDkzXbEnt0fVqlVNZGSkfXpkZKSpWrWqsdlsZtOmTfbpS5cuNZJM27ZtzZUrV+zTk5KSzIsvvpgiz+S28vHxSbVvv/baa0aS6dmzZ4pzPTIy0qFv3XvvvcbX19csWbLEYbn9+/ebwMBAU6tWLYfpydf1zp07O/SrP//8057DzZLPXWftmFqbZMd7AQAgY3iUDwCQ5VIbV+fWR2rKly8vX19fh2k2m039+vWTJP3555+pbvv9999Xvnz57K/Lli2rgQMHKjY2VrNmzUozrt9++01Hjx7VG2+8oXr16jnMa9asmTp37qxFixbZ7xS4nenTpysuLk49e/a0T+vVq5ck54/zSdKTTz6ppk2b2l/7+vqqd+/ekhwfT0uW2vG8edDvFi1ayNfXV8uXL7dPW7FihapWraqnnnpK4eHh2rdvnyRp3bp1iouLc7izw9Xjki9fPo0fPz5FO6YVd3ofrUr2559/atSoURo1apT69++vGjVqaPny5QoNDdUrr7yipKQkffPNN6pYsaJGjx7t8AhaYGCgRowYobi4OM2dOzfFtt94440Mjad05swZSVK5cuVuu2zyMqdOnUr39m/mal6pHXM/Pz+nd++lV/IjVOPHj3c4/8qXL69XX31VCQkJ+uGHH1Ksl9G+bpWoqChJUlBQUKrzCxUqpKSkJF2+fDlD223RooUef/xxh2nPPPOMpIznP3z4cIf4goKCNGzYMBlj7O0jSRMnTpQk+wD9yWw2mz744APZbLZUH3/u3LmzWrdu7TAtISFBkydPVlBQkD7//PMU53pQUJC9b23btk3r1q1T79691bZtW4flqlSpoueff95+p9itPv30U4d+df/99yskJCTL+oi73wsAABnDo3wAgCzTqVMnDR06VP369dOyZcvUrl07tWzZMtXHIeLi4jRx4kTNmjVL+/bt05UrVxzGSjl9+nSKdfLkyZPq4MPNmzeXdOOLUVo2bNggSdq/f3+qY8GcOXNGSUlJOnDggBo2bJjmtqQbxSebzaYePXrYp1WsWFH33nuv1q1bp71796p69eop1mvQoEGKaWXLlpV0YwytZN27d9fcuXPVpEkTPfnkk7r//vvVvHlzBQcHO6wbFBSkevXqae3atYqPj5ePj49Wr16tp556SmFhYZJuFKqqVaumFStWSJJ9emaOS2hoaIpYpIz1g9tZtmyZ/Ze2/Pz8VKFCBQ0ePFhDhw5V0aJFtXfvXl26dEllypSxj510s/Pnz0uSvTB3s8aNG2c4noxKSkpyab39+/dnKK/q1aurdu3amjlzpk6ePKmHH35YrVq1Ut26deXjk/m/S27btk358+dP9Zgl96Xt27enmJfevu7MvHnzUmy3VatWTsfqymkym//Nkq9zqU27+dq3YcMGFShQQN99912q2wkICEj3+bBv3z5dvnxZrVu3tj+u50zydeTs2bOpXkeS97lv3z7VrFnTPr1w4cIKDQ1NsXzZsmW1fv36NPfpKne/FwAAMobCFADgtpK/yKb1pTp53s1feitUqKANGzZo1KhRWrRokX788UdJUrVq1fTuu+/qsccesy/btWtXLViwQFWqVNHjjz+uEiVKKG/evIqMjNTnn3+u2NjYFPsMDg5O9Ut28ng/yXc9OJP8c/Gp3dlxs5iYmDTnSzfGJ9m1a5fCwsJS3HXTq1cvrVu3Tt99950++uijFOsWKlQoxbTkMZduHpj4scce07x58zRhwgR9++23+uqrr2Sz2RQWFqZPPvlEdevWtS8bFhamzZs3a9OmTcqbN6+io6N133332QcDXrFihV566SWtWLEiRYHB1ePibJyljPSD2xk3blya4zQlx757927t3r073bGnFb8zpUqV0r59+3TixAlVrVo1zWVPnDghSSkGSE+vjOaVJ08eLV++XKNGjdLPP/+s1157TZJUvHhxvfLKK3rnnXec3tmWHtHR0U7vFCtdurR9mVult687M2/ePIe7gZK5uzCVfCeSs2tIdHS0bDabAgMDM7TdzOZ/s9T6a2rXvosXLyohISHVgmay9J4PydtNTz9O7rMLFy7UwoUL071vZ3ep5cmTx+XC7u24870AAJBxPMoHALit5C8Kaf1yVkREhMOyyWrWrKmffvpJFy9e1Pr16zVixAidOXNGjz/+uP73v/9JuvEIy4IFC9S2bVvt2bNHU6ZM0dixYzVq1Ch17949zX2m9kXl7NmzqcZyq+QviQsWLJAxxum/li1bprkd6f8/qrdixQqHX+Wy2Wx68cUXJUnff/99mr8wmB6dO3fWqlWrdOnSJS1evFjPPfecVq5cqXbt2jnccXHznVErV650+LWqsLAwrVy5UleuXNGmTZvUtGlTh8dmXD0uqf1yW7L09AN3SI69S5cuacY+derUFOumFX9q7r33Xkmy38HlzL59+3T69GkVKVJEpUqVcthfQkJCquvcWhBxJa9ixYrpyy+/1KlTp7Rnzx5NnDhRRYsW1ciRIzV+/PgM5XqrQoUK6dy5c6nOS37EMbUiTGZNmzYtRc6p3eGSWZUrV5Z049ckb5WYmKgjR44oNDTULYP2uyr5OpfatJuvfYUKFVKxYsXS7DdHjhxJsa3UzofkAcbT80hqcvsn/1Kgs3/Jj3JayZ3vBQCAjKMwBQC4rapVqypfvnzatGmT0y/SyY9Y1K5dO9X5efPmVZMmTTR69Gh98cUXMsbot99+k3Tjl5skqUOHDinu4lizZo3TuBISElJ9tCN5nVvHCrlV8q9BZfbxkJiYGM2aNUv58+fXs88+m+q/2rVr69y5c/acMyswMFDt2rXT5MmT9fTTT+vs2bPauHGjfX7z5s3td82sWLFCtWrVsj9md9999+n8+fOaNGmS4uPjU9xt4q7jkpq0+oE7VK9eXYUKFdLmzZszXQS8nd69e8vHx0dTpkyxP0qXmrFjx0qSevTo4XCHX5EiRVL9gn/06NEUj3VlJi+bzabq1aurX79++uOPPyTd+HW8ZMnnXEbu2KlXr56uXr2qv/76K8W85F+0u/kOvtwmuQCxdOnSFPPWrl2rmJiYFEUKX1/fDN/1lBmpXRtTu/bdfffdunDhQqpFtoyqWrWqChUqpE2bNtl/5dOZrLyOJHOl76YmO2IFADhHYQoAcFv+/v7q1q2bzp8/rzFjxqSYv3PnTv3rX/9SYGCgHnnkEfv0LVu2pPo4T/Jf9ZN/Gj0kJESSUvxc/O7duzVu3Lg0Y3v77bcVFxdnf33y5El9/vnn8vPzS/NuK+nG3Ufly5fXhAkTtHr16hTz4+Pj0/UT9nPmzNHly5fVtWtX/etf/0r1X/IjfGkNgn47q1evTvULWPKdKzf/1HzBggXVsGFDrVu3TmvWrNF9991nn5d8N9WHH37o8DqZu45LsvT2A3fIkyePXnrpJR07dkyvv/56qkWcXbt2Ob3bJyOqVKmiwYMH68KFC+rUqZPCw8Md5iclJem9997Tf//7XxUuXFiDBg1ymN+oUSMdPXpUq1atsk+Li4vT4MGDM53X0aNHdfTo0RTLpHbMkwegT37cMD2S73IZOnSoQywnTpzQhAkTlCdPHj311FPp3l5OU7VqVbVo0UIrVqzQ4sWL7dPj4uI0fPhwSdJzzz3nsE7RokUVERGh69evZ0uM7733nsOddVFRURozZoxsNpvDXUgDBgyQdGOQ9dTuej1z5oz27t2brn3myZNHffv2VVRUlAYOHJjiehQVFaUrV65IujFG1d13362ZM2dq9uzZKbaVlJTk0Pdd4UrfTY27r3kAgIxhjCkAQLp88skn2rhxo0aPHq3ffvtNLVu2lL+/vw4cOKD58+fLGKMffvjB/qiHdONX6iZNmqQWLVqoYsWKKlSokPbs2aNFixapaNGi6tOnj6QbX2AaN26sH3/8UeHh4WrSpImOHz+u+fPnq0OHDvrpp59Sjal06dKKiYlR7dq11alTJ8XExOjHH3/UhQsX9MUXX9x2HBQ/Pz/99NNPat++vVq2bKn77rtPtWrVks1m07Fjx7RmzRoVK1Ys1YGBb5ZcbErOJzWtW7dW2bJltWTJEp0+fVplypRJc5upGTBggE6fPq1mzZqpQoUKstlsWrt2rf766y81adJEzZo1c1g+LCzMPqjvzcWnO+64Q5UrV9bBgwdVsGBBNWrUyGE9dx2XZOntB+4yevRobd26VV988YUWLlyoFi1aqESJEjp16pR27typHTt2aP369SpRokSm9zVu3DhFRUVpypQpqly5sjp06KCKFSsqOjpaS5cu1cGDB+Xv769Zs2alGOx98ODBWrp0qR588EE98cQTyp8/v/744w8VLlzYPk6Tq3lt375djz76qBo3bqwaNWqoVKlSOnXqlObNmycfHx+9+uqr9u2GhYXJZrPp7bff1u7duxUUFKTChQvrlVdecZp3z549NXfuXP3666+qXbu2OnbsqJiYGM2ePVsXL17UJ5984tLg9lnp9ddftz9yvHPnTvu05F+Re+655xzOoa+//lpNmzbVww8/rMcff1ylS5fWwoULtXv3br3yyiv2RzmT3Xfffdq8ebPat2+v5s2bK1++fGrRooVatGiRJflUqVJFNWvWVJcuXSRJP//8s06ePKnBgwc7DNDdrl07DR8+XO+9954qVaqkdu3aKSQkRBcuXNChQ4e0Zs0ajRkzJtUfZkjNu+++qw0bNmj69OnasGGD2rdvLz8/Px0+fFhLlizR2rVr7XfLzZw5U2FhYerevbs+++wz1a9fXwEBATp+/LjWr1+v8+fPZ6qQd9999+njjz/WCy+8oC5duqhAgQIKCQlx+GXU9HD3NQ8AkEEGAIB0ioyMNCNHjjR16tQxBQoUMHnz5jXlypUzTz75pNm6dWuK5Tds2GD69u1ratasaQoXLmwCAgJM5cqVzSuvvGKOHTvmsOy5c+fMM888Y8qUKWP8/f1NrVq1zFdffWUOHz5sJJnevXs7LB8SEmJCQkLMxYsXzQsvvGBKlixp/Pz8TJ06dcyMGTNSxDJ16lQjyUydOjXFvJMnT5qBAweaypUrGz8/P1OoUCFTvXp189xzz5lly5aleUz27dtnJJnQ0FCTlJSU5rLvvPOOkWTGjh1725hWrFhhJJmRI0fap82aNct069bNVKxY0eTPn98EBQWZOnXqmA8//NBcvnw5xTaWLl1qJBlfX18TGRnpMO+FF14wkkzbtm2dxpuR4yLJtGzZMtXtZKQfOJN8rMaNG5eu5RMSEsykSZNM06ZNTaFChYyfn58pX768adeunfnmm2/MlStX7Mv27t3bSDJHjhxJ17ZTs2zZMtOtWzdTpkwZkydPHiPJSDJNmjQxhw4dcrrenDlzTK1atUy+fPlMqVKlTP/+/c3ly5ft/dvVvE6cOGGGDBlimjRpYkqUKGHy5ctnypcvbx599FGzfv36FNudNm2aqVWrlvHz8zOSHPbdsmVLk9pHxvj4ePPxxx/b1wsMDDQtW7Y0v/76a4plM9rXs0JISIi9XVL7l1ps+/btM127djVFixY1fn5+9utSauf65cuXzfPPP29Kly5tfH19HXJKK8cjR46keo1zJrk9rl27Zt58801Trlw5ky9fPlO1alXzxRdfOL0O/fHHH6ZTp06mePHiJm/evKZUqVLmnnvuMe+99545fvy4fbm02irZ9evXzccff2zq1q1rAgICTMGCBU2NGjXMa6+9Zi5duuSw7MWLF82wYcNMzZo17ctWrlzZPPnkk2bu3LkOyzrr9zfnfavx48ebypUrm7x586a4DqW2vax6LwAAuM5mzE2/xQ0AAIBMO3DggJo0aSI/Pz+tWbNGlSpVsjokeIhWrVpp1apV4iM8AMBTMMYUAACAm1WpUkU///yzLly4oAceeCBdv2IGAADgjShMAQAAZIGwsDD9/PPP6t27d5q/LgkAAODNeJQPAAAAyCV4lA8A4GkoTAEAAAAAAMASPMoHAAAAAAAAS1CYAgAAAAAAgCXyWB1AdktKStLp06cVGBgom81mdTgAAAAAAAAexRijy5cvq0yZMvLxSfueKK8rTJ0+fVrlypWzOgwAAAAAAACPduLECZUtWzbNZbyuMBUYGCjpxsEpVKiQxdEAAAAAAAB4lujoaJUrV85eg0mL1xWmkh/fK1SoEIUpAAAAAACALJKeIZQY/BwAAAAAAACWoDAFAAAAAAAAS1CYAgAAAAAAgCUoTAEAAAAAAMASFKYAAAAAAABgCQpTAAAAAAAAsASFKQAAAAAAAFiCwhQAAAAAAAAsQWEKAAAAAAAAlqAwBQAAAAAAAEtQmAIAAAAAAIAlKEwBAAAAAADAEhSmAAAAAAAAYAkKUwAAAAAAALAEhSkAAAAAAABYgsIUAAAAAAAALEFhCgAAAAAAAJagMAUAAAAAAABLUJgCAAAAAACAJfJYHQCyxvHjxxUREeEwLTg4WOXLl3fbOmkt78r+PZ07j0l2HV9n+5Hk8e1rdR+2ev+pSS0myfo+kVZcntQnkVJOvUblxPMXORN9JetlxzGmHXMXb24vK3Pn8xrSZLxMVFSUkWSioqKsDiXLHDt2zATkz28kOfwLyJ/fHDt2zC3rpLX8unXrMrx/T+dKm2THtlzZj5+/v/EPCPDo9s2uY5xT95+RmKzuE2nF5Ul9Einl1GtUTjx/kTPRV7Jedhxj2jF38eb2sjJ3Pq95p4zUXrhjygNFRETo2tWr6jbmG5UIrSxJOnfkoH4c9pIiIiJSrUhndJ20lj98+HCG9+/pXGmT7NiWq/uR5NHtm13HOKfuP70x3RyXZE2fuF1cntInkVJOvUblxPMXORN9JetlxzGmHXMXb24vK3Pn8xpuh8KUBysRWll3VK+Tpeuktbwr+/d07jwm2XV8ne3HG9rX6hyt3n9qcuo5nxOPFbJHTr1GWb1/5B70layXHceYdsxdvLm9+LyGnIjBzwEAAAAAAGAJClMAAAAAAACwBIUpAAAAAAAAWILCFAAAAAAAACxBYQoAAAAAAACWoDAFAAAAAAAAS1CYAgAAAAAAgCUoTAEAAAAAAMASFKYAAAAAAABgCQpTAAAAAAAAsASFKQAAAAAAAFiCwhQAAAAAAAAsQWEKAAAAAAAAlqAwBQAAAAAAAEtQmAIAAAAAAIAlKEwBAAAAAADAEhSmAAAAAAAAYAkKUwAAAAAAALAEhSkAAAAAAABYgsIUAAAAAAAALEFhCgAAAAAAAJagMAUAAAAAAABLUJgCAAAAAACAJShMAQAAAAAAwBIUpgAAAAAAAGAJClMAAAAAAACwBIUpAAAAAAAAWILCFAAAAAAAACyRowpTq1evVqdOnVSmTBnZbDbNmzfPPi8+Pl5vvfWWatWqpQIFCqhMmTLq1auXTp8+bV3AAAAAAAAAcFmOKkzFxMSoTp06+uqrr1LMu3r1qrZu3arhw4dr69atmjt3rvbv36+HHnrIgkgBAAAAAACQWXmsDuBm7du3V/v27VOdFxQUpD/++MNh2sSJE9W4cWMdP35c5cuXz44QAQAAAAAA4CY56o6pjIqKipLNZlPhwoWtDgUAAAAAAAAZlKPumMqI69ev66233tITTzyhQoUKOV0uNjZWsbGx9tfR0dHZER4y6Pjx44qIiHCYFhwc7NKdcK5sy9k6ktwWV1rcmX9uY3Xuqe0/PDzcsn0n9zt3bcvqPhQeHq6tW7c6THPnuX27tnK2fyl7zm1nMnrNcTa9fPnybr1+WX0tzoncmYc7zwdkjKf0R3fLjmtRdhxjV95Pc+r7gzP0YeQ02dEn3fm9zhviys1yZWEqPj5e3bp1kzFG33zzTZrLjhs3TqNHj86myOCK48ePq1r16rp29arD9ID8+bVv794MnayubMvZOn7+/rLZbLp+7Vqm40pLeHi4mjVv7pb8cxt3tr079+/n75+l+01r3wH582vOjz+6bVtW96GuXR/T9euZP4dcbavU9p9d57YzGb3mpBXvsj//1P2tW7vl+mX1tTgncnce7jofkDGe0h/dLTuuRdlxjF19P82J7w/O0IeR02RHn3Tn9zpviCu3y3WFqeSi1LFjx7R8+fI075aSpKFDh2rw4MH219HR0SpXrlxWh4kMiIiI0LWrV9VtzDcqEVpZknTuyEH9OOwlRUREZOhEdWVbaa0jyS1xpSUyMtJt+ec27mx7d+8/q6W178jISLdty+o+dP36tSw/t13Zv5T157YzrlxznE0/fPiw265fVl+LcyJ35+Gu8wEZ4yn90d2y61qU1cfY1ffTnPj+4Ax9GDlNdvRJd3+v8/S4crtcVZhKLkodPHhQK1asULFixW67jp+fn/z8/LIhOmRWidDKuqN6Hcu25Wwdd8blyv69gdW5W7l/q/t9drA6R6vPbWcyGlda8bozR6vbKyfimHgGjn3qsuNalB086f3BmZwaF7xXdvRJqz/LuHMfnMPO5ajC1JUrV3To0CH76yNHjmj79u0qWrSoSpcura5du2rr1q367bfflJiYqDNnzkiSihYtqnz58lkVNgAAAAAAAFyQowpTmzdvVlhYmP118iN4vXv31qhRozR//nxJUt26dR3WW7FihVq1apVdYQIAAAAAAMANclRhqlWrVjLGOJ2f1jwAAAAAAADkLj5WBwAAAAAAAADvRGEKAAAAAAAAlqAwBQAAAAAAAEtQmAIAAAAAAIAlKEwBAAAAAADAEhSmAAAAAAAAYAkKUwAAAAAAALAEhSkAAAAAAABYgsIUAAAAAAAALEFhCgAAAAAAAJagMAUAAAAAAABLUJgCAAAAAACAJShMAQAAAAAAwBIUpgAAAAAAAGAJClMAAAAAAACwBIUpAAAAAAAAWILCFAAAAAAAACxBYQoAAAAAAACWoDAFAAAAAAAAS1CYAgAAAAAAgCUoTAEAAAAAAMASFKYAAAAAAABgCQpTAAAAAAAAsASFKQAAAAAAAFiCwhQAAAAAAAAsQWEKAAAAAAAAlqAwBQAAAAAAAEtQmAIAAAAAAIAl8lgdADLn+PHjioiIcJgWHh7udPnw8HBt3brVYVpwcHCWxJbe/acVr5R6jsHBwSpfvnyG95/R45UbOTtektx2HN0Vl6vHPqN9Iq1jklHOzqHsOo6unEPOZKSvZOd5YuV56s72dWe/8yRpvQ/ltmtUdlzXpIwfF3e+b7pTTnx/Sq0/3i4uZ9Mz2iYZ/byWnv2kd9+32z+yXna8B2f1Z+iccF1xxp3vwd58HF3hzs+qGdmHq/txZ5tY/V07N6MwlYsdP35c1apX17WrVx2m+/n7O12na9fHdP36NYdpAfnza86PP2ZJjOnZf1rxhoeHq1nz5ilyDMifX/v27s3QBcPZttLaf26TVo42m03Xr6Vs+4weR1e40lczui1nuaS1vCv93tk5lB3H0dn+3XkcnfWV7DpP3NlXXOGu9nV3v/MkzvpwbrtGufM9xZ3X7oxeI7NLRq852RVvav0xrbjc2SYZ/bx2u/2kxtm+b7d/ZK3seA9257Ugp15XnHHne7A3H0dXueuzakb34cp+3N0mVn/Xzs0oTOViERERunb1qrqN+UYlQitLks4dOagfh73kdJ3r16+lunxkZGR2hOx0/85ERkY6zTEiIiJDF4u0tuUpbpejO46jK1zpq65sK7Vc0lrelX7vrA9nx3FMa/8Zdbs2seo8cWdfcYW72tfd/c6TpNWHc9M1yp3vKe68dmf0GpldXLnmZEe8t/bH9MSV0Xjd8XktPftJTWr7Ts/+kbWy4z3YndeCnHpdccad78HefBxd5a7PqhnZh6v7cXebWP1dOzejMOUBSoRW1h3V62TZ8u7myv7dGbPV+WcHZzlanbuV7ehJfSg7cvGkHK3ct9XHMafypH6XU89Hq4+lMzmx7dPat5VtwrXI82XH+ZBTt5Udcmruue04uiI7csypbeIN7ZsVGPwcAAAAAAAAlqAwBQAAAAAAAEtQmAIAAAAAAIAlKEwBAAAAAADAEhSmAAAAAAAAYAkKUwAAAAAAALAEhSkAAAAAAABYgsIUAAAAAAAALEFhCgAAAAAAAJagMAUAAAAAAABLUJgCAAAAAACAJShMAQAAAAAAwBIUpgAAAAAAAGAJClMAAAAAAACwBIUpAAAAAAAAWILCFAAAAAAAACxBYQoAAAAAAACWoDAFAAAAAAAAS1CYAgAAAAAAgCUoTAEAAAAAAMASFKYAAAAAAABgCQpTAAAAAAAAsASFKQAAAAAAAFiCwhQAAAAAAAAsQWEKAAAAAAAAlqAwBQAAAAAAAEtQmAIAAAAAAIAlKEwBAAAAAADAEjmqMLV69Wp16tRJZcqUkc1m07x58xzmG2M0YsQIlS5dWgEBAWrdurUOHjxoTbAAAAAAAADIlBxVmIqJiVGdOnX01VdfpTp//Pjx+uKLL/Ttt99q48aNKlCggNq2bavr169nc6QAAAAAAADIrDxWB3Cz9u3bq3379qnOM8bos88+07Bhw9S5c2dJ0vfff6+SJUtq3rx56t69e3aGCgAAAAAAgEzKUXdMpeXIkSM6c+aMWrdubZ8WFBSku+++W+vXr7cwMgAAAAAAALgiR90xlZYzZ85IkkqWLOkwvWTJkvZ5qYmNjVVsbKz9dXR09I3/2b5dKljQ7XFmp4C9e1VPUtkjB1Xi/6bZjhxUvf/7/4xML3LkiNNtxaxZo7179zrsOyYiwunyaW3LU+IK2LtX4eHhioyMdNh/4cKFJSnFdFfjyo4cU9tH4cKFFRAZmeu25Q19IqNxpXZMbrf/9O4js8crNe64rmUmrrTidda+pUuXzlAe2XWNdLaOu84tZ33b1XPe2XRnx96VPuzObVndjq6cQ87WSUtG+n1ay7vSJ9KK113n4637Tk9czqZn1/XW2fmY3twzk6Oz6Rn9LJNWH5Kct69k3fupK9cPd34uyo64nLVJWueQO9vX6j6R0c+RGb2munp9zkjuycfRXX0itX3cbltK5/Sb56WWv7uv3RndR3Z9ZnDlHMo1rlxJ96I2Y4zJwlBcZrPZ9Msvv+jhhx+WJK1bt05NmzbV6dOnHRqpW7dustlsmj17dqrbGTVqlEaPHp1iepSkQlkROAAAAAAAgBeLlhQkKSoqSoUKpV19cdsdU8YYrVixQrGxsWrWrJkCAwPdtWlJUqlSpSRJZ8+edShMnT17VnXr1nW63tChQzV48GD76+joaJUrV05atSrX3zG1d+9ePdWjhx4f841KhFaWJJ07clCzh70kSRmaPua99zRs+HCn67R5eaiKlCkvSbp0+riWfj3O5W15UlzO9u/OuLIjx9T2kVu35Q19IjPHMT37T+/0zMT1w3//q+rVq+tW7riuZfZ4ZbR9U8slrTyy8xqZHeeWO895V84tq7dlVTu6cg45W8eZ5G1ltN+7q0/cLkd3nI+37js9caU1Pbuut5nJPbM5uuuzjCvt62xbrsaVHdePnHqNdKVNsrp9c0KfyMi2XL2muut65yxed/aJW6end1sZva5lx7Xb1c9r2fGZISPnQ65y5YrUsmW6FnWpMPXOO+9o3bp1WrFihaQbRak2bdpo+fLlMsaofPnyWrZsmSpWrOjK5lMVGhqqUqVKadmyZfZCVHR0tDZu3KiXXnrJ6Xp+fn7y8/NLOaNuXek2Vbuc7pqkbZKahlaWqV5HknTq/6Ypg9MvhYamva2m96vw/02P2btD2/7vhHRpW54Ul7P9uzOu7MgxlX3k2m15Q5/IxHFMz/7TOz0zcV2rXl2qX1+3csd1LdPHK4Ptm1ouaeWRrdfI7Di33HnOu3JuWb0ti9rRlXPI2TrO2LeV0X7vpj5x2xzdcD7euu/0xJXm9Oy63mYi90zn6KbPMq60r7NtuRxXdlw/cuo10pU2yeL2zRF9IgPbcvma6qbrnbN43dknbp2e7m1l8LqWHddulz+vZcdnhgycD7lK8jBK6eDS4Oc///yzGjdubH/9008/admyZRozZox+++03JSYmatSoURne7pUrV7R9+3Zt375d0o0Bz7dv367jx4/LZrNp0KBBGjNmjObPn6+dO3eqV69eKlOmjP1xPwAAAAAAAOQeLt0xderUKVWqVMn+eu7cuapRo4aGDh0qSXrppZf0zTffZHi7mzdvVlhYmP118iN4vXv31rRp0/Tmm28qJiZGL7zwgiIjI9WsWTMtWbJE/v7+rqQBAAAAAAAAC7lUmMqTJ4/9l+6MMVq2bJl69epln1+yZElFRERkeLutWrVSWmOx22w2vfvuu3r33XczHjQAAAAAAAByFJce5atZs6b++9//6tKlS5o6daouXLigDh062OcfO3ZMwcHBbgsSAAAAAAAAnselO6ZGjBihTp062YtPTZs2dXgEb+HChWrUqJF7IgQAAAAAAIBHcqkw9cADD2jr1q36448/VLhwYT3++OP2eZcuXVKLFi3UuXNntwUJAAAAAAAAz5PhwtT169c1efJk1a1bVwMHDkwxv0iRIvr000/dEhwAAAAAAAA8V4bHmPL399dbb72l/fv3Z0U8AAAAAAAA8BIuD35+9OhRN4cCAAAAAAAAb+JSYWrs2LGaNGmS/vzzT3fHAwAAAAAAAC/h0uDnEydOVNGiRdW2bVuFhoYqNDRUAQEBDsvYbDb9+uuvbgkSAAAAAAAAnselwtTff/8tm82m8uXLKzExUYcOHUqxjM1my3RwAAAAAAAA8FwuFaYYXwoAAAAAAACZ5dIYUwAAAAAAAEBmuVyYSkxM1KxZs9S3b1898sgj2rlzpyQpKipKc+fO1dmzZ90WJAAAAAAAADyPS4WpyMhINW3aVE8++aRmzpyp+fPn6/z585KkggULasCAAfr888/dGigAAAAAAAA8i0uFqSFDhmj37t36/fffdfjwYRlj7PN8fX3VtWtXLVq0yG1BAgAAAAAAwPO4VJiaN2+e+vfvrwceeCDVX9+rUqUKA6QDAAAAAAAgTS4VpqKiohQaGup0fnx8vBISElwOCgAAAAAAAJ7PpcJUxYoVtXXrVqfzly5dqho1argcFAAAAAAAADyfS4Wp5557Tt99951mz55tH1/KZrMpNjZW77zzjpYsWaK+ffu6NVAAAAAAAAB4ljyurDRw4EDt3r1bTzzxhAoXLixJevLJJ3XhwgUlJCSob9++evbZZ90ZJwAAAAAAADyMS4Upm82mKVOmqHfv3vrpp5908OBBJSUlqWLFiurWrZtatGjh7jgBAAAAAADgYVwqTCVr1qyZmjVr5q5YAAAAAAAA4EVcGmNq6NChWrJkiaKjo90dDwAAAAAAALyES4WpiRMnqkOHDipWrJjq1aunAQMGaM6cOTp79qy74wMAAAAAAICHculRvqioKG3btk2rV6/W2rVrNXv2bE2cOFE2m00VK1ZU8+bN1aJFC/Xu3dvd8QIAAAAAAMBDuHTHlI+Pjxo0aKBXX31VP//8s86ePau9e/fqyy+/lI+Pj6ZOnapnnnnG3bECAAAAAADAg2Rq8POrV69q/fr1WrNmjdasWaMNGzbo2rVrqlq1qpo3b+6uGAEAAAAAAOCBXCpMvf7661qzZo22bdumpKQk1alTR82bN1e/fv3UvHlzFS9e3N1xAgAAAAAAwMO4VJiaMGGCfH191aVLFw0ZMkR169Z1c1gAAAAAAADwdC4Vpj766COtXbtWy5Yt05w5c1S6dGk1b97c/q9WrVrujhMA4EHCw8O1devWVKfnNqnlkhvzQO6SWr8LDg52eZ2IiIgMbQs5D9ciuMPx48dTXA9c7Ufu3FZOlVqOwcHBKl++vEURwRmukTmbS4Wp1157Ta+99pokac+ePVqzZo3Wrl2r8ePHq3///goKClLTpk21YMECtwYLAPAMXbs+puvXr6WY7ufvb0E0mZNaLrkxD+QuqfW7gPz5NefHHzO0jp+/v2w2m65fy9i2kPNwLUJmhYeHq1nz5rp29arDdFf6kTu3lVM5yzEgf37t27uX4lQOwzUyZ8vU4OeSVKNGDVWsWFFVq1ZV5cqVNXPmTO3fv1+LFi1yR3wAAA90/fo1dRvzjUqEVrZPO3fkoH4c9pKFUbnm1lxyax7IXZz1u8jIyAyvIynD20LOw7UImRUZGalrV6+6pR+5c1s5VVo5RkREUJjKYbhG5mwuFaaio6O1du1arVmzRqtXr9aWLVsUHx+vvHnzqlGjRnrkkUf4VT4AQJpKhFbWHdXrWB2GW3hSLsg9XOl3ztahD3sG2hHu4M5+5A190hty9BS0Vc7lUmGqaNGiMsYoMDBQ9957r0aOHKlmzZqpcePG8vPzc3eMAAAAAAAA8EAuFaY+/fRTNW/eXHXq1JHNZnN3TAAAAAAAAPACLhWm+vfv7+44AAAAAAAA4GV8XFlp+/btmjlzpsO033//XS1atNDdd9+tzz//3C3BAQAAAAAAwHO5VJh68803NXv2bPvrI0eO6JFHHtGRI0ckSYMHD9bkyZPdEyEAAAAAAAA8kkuFqR07dqhZs2b2199//718fX21bds2bdy4UV27dtW3337rtiABAAAAAADgeVwqTEVFRalYsWL214sWLdIDDzyg4OBgSdIDDzygQ4cOuSdCAAAAAAAAeCSXClOlS5fW3r17JUnh4eHasmWL2rRpY59/5coV+fi4tGkAAAAAAAB4CZd+la9z58768ssvdf36dW3cuFF+fn565JFH7PN37NihO++8021BAgAAAAAAwPO4VJgaM2aMzp8/r+nTp6tw4cKaNm2aSpYsKUmKjo7WTz/9pH79+rk1UAAAAAAAAHgWlwpTBQsW1A8//OB03smTJ5U/f/5MBQYAAAAAAADP5lJhKi0+Pj4KCgpy92YBAAAAAADgYVwuTF26dEkzZ87U4cOHdenSJRljHObbbDb9+9//znSAAAAAAAAA8EwuFaZ+//13de3aVTExMSpUqJCKFCmSYhmbzZbp4AAAAAAAAOC5XCpMvfbaaypVqpTmzp2rWrVquTsmAAAAAAAAeAEfV1Y6dOiQBgwYQFEKAAAAAAAALnOpMFW5cmVdvnzZ3bEAAAAAAADAi7hUmBozZoy+/vprHT161M3hAAAAAAAAwFu4NMbUsmXLVLx4cVWvXl0PPPCAypUrJ19fX4dlbDabPv/8c7cECQAAAAAAAM/jUmFq4sSJ9v//7bffUl2GwhQAAAAAAADS4lJhKikpyd1xAAAAAAAAwMu4NMZUeuzatSurNg0AAAAAAAAP4NbC1MmTJ/XRRx+pbt26qlOnjjs3DQAAAAAAAA/j0qN8N4uKitKcOXP0ww8/aM2aNTLGqH79+ho5cqQ74gMAAAAAAICHcqkwFRcXpwULFuiHH37Q4sWLFRsbK5vNpgEDBuiNN95QmTJl3B0nAAAAAAAAPEyGHuVbvny5nn32WZUsWVLdunXTuXPn9PHHH9vvlGrevDlFKQAAAAAAAKRLuu+YKlu2rMLDw1WvXj29/fbb6t69u8qVKydJ+ueff7IsQAAAAAAAAHimdBemTp8+rdDQUPXp00ePPfaYSpQokZVxAQAAAAAAwMOl+1G+hQsX6p577tGQIUN0xx13qE2bNpo6daqioqKyMj4HiYmJGj58uEJDQxUQEKCKFSvqvffekzEm22IAAAAAAACAe6T7jqn27durffv2unr1qubOnasZM2aob9++evnll9W4cWPZbDYlJSVlZaz68MMP9c033+g///mP7rrrLm3evFl9+vRRUFCQBgwYkKX7BgAAAAAAgHtlaPBzScqfP7969OihRYsW6dSpU/rwww91/fp1GWPUo0cPPfDAA5o4caKOHj3q9mDXrVunzp07q0OHDqpQoYK6du2qNm3a6K+//nL7vgAAAAAAAJC1MlyYulnx4sU1YMAAbdy4UQcOHNCQIUN07NgxDRgwQBUrVnRXjHb33nuvli1bpgMHDkiSduzYobVr16p9+/Zu3xcAAAAAAACyVrof5budSpUqadSoURo1apQ2btyoGTNmuGvTdkOGDFF0dLSqVasmX19fJSYmauzYsXrqqaecrhMbG6vY2Fj76+joaLfHBQAAAPcKDw/X1q1bHaYFBwdbFA3cjfbFrTypT6SWS3h4eJrrHD9+XBERERlaB/AUbitM3ezuu+/W3Xff7fbt/vjjj/rhhx80Y8YM3XXXXdq+fbsGDRqkMmXKqHfv3qmuM27cOI0ePdrtsQAAACDrdO36mK5fv+YwLSB/fs358UeLIoI70b64lSf1idRy8fP3d7p8eHi4mjVvrmtXr6Z7HcCTZElhKqu88cYbGjJkiLp37y5JqlWrlo4dO6Zx48Y5LUwNHTpUgwcPtr+Ojo5WuXLlsiVeAAAAuOb69WvqNuYblQitLEk6d+Sgfhz2kiIjI60NDG5B++JWntQnnOXiTGRkpK5dvZqhdQBPkqsKU1evXpWPj+OwWL6+vmn+GqCfn5/8/PyyOjQAAAC4WYnQyrqjeh2rw0AWoX1xK0/qE67k4kn5AxmRqwpTnTp10tixY1W+fHnddddd2rZtmyZMmKBnnnnG6tAAAAAAAACQQbmqMPXll19q+PDhevnll3Xu3DmVKVNGffv21YgRI6wODQAAAAAAABmUqwpTgYGB+uyzz/TZZ59ZHQoAAAAAAAAyyef2i6Tu+PHjevHFF1W1alUVLVpUq1evliRFRERowIAB2rZtm9uCBAAAAAAAgOdx6Y6pPXv2qHnz5kpKStLdd9+tQ4cOKSEhQZIUHBystWvXKiYmRv/+97/dGiwAAAAAAAA8h0uFqTfffFOFCxfWhg0bZLPZVKJECYf5HTp00OzZs90SIAAAAAAAADyTS4/yrV69Wi+99JKKFy8um82WYn758uV16tSpTAcHAAAAAAAAz+VSYSopKUn58+d3Ov/8+fPy8/NzOSgAAAAAAAB4PpcKU/Xr19fChQtTnZeQkKBZs2apSZMmmQoMAAAAAAAAns2lwtTQoUO1ZMkSvfTSS9q1a5ck6ezZs/rzzz/Vpk0b7d27V0OGDHFroAAAAAAAAPAsLg1+3r59e02bNk0DBw7U5MmTJUk9evSQMUaFChXS999/rxYtWrg1UAAAAAAAAHgWlwpTktSzZ089+uijWrp0qQ4dOqSkpCRVrFhRbdu2VWBgoDtjBAAAAAAAgAdyuTAlSQUKFNAjjzzirlgAAAAAAADgRdJVmDp+/LhLGy9fvrxL6wEAAAAAAMDzpaswVaFCBdlstgxvPDExMcPrAAAAAAAAwDukqzD13XffuVSYAgAAAAAAAJxJV2Hq6aefzuIwAAAAAAAA4G0yNfi5JBljdP78eUlS8eLFubMKAAAAAAAA6eLj6op79uxR165dVahQIZUuXVqlS5dWoUKF1LVrV+3atcudMQIAAAAAAMADuXTH1Jo1a9S+fXslJSWpc+fOqlKliiRp//79mj9/vhYvXqwlS5aoefPmbg0WAAAAAAAAnsOlwtSrr76qEiVKaNWqVSpXrpzDvBMnTqhFixYaPHiwNm3a5JYgAQAAAAAA4HlcepRv9+7devnll1MUpSSpXLlyeumll7R79+5MBwcAAAAAAADP5VJhKiQkRLGxsU7nx8XFpVq0AgAAAAAAAJK5VJgaMWKEvvjiC23fvj3FvG3btunLL7/UqFGjMhkaAAAAAAAAPFm6xpgaMGBAimklS5ZUgwYNdO+996pSpUqSpIMHD2r9+vWqWbOmNmzYoCeeeMK90QIAAAAAAMBjpKswNXHiRKfz/ve//+l///ufw7SdO3dq165d+vzzzzMXHQAAAAAAADxWugpTSUlJWR0HAAAAAAAAvIxLY0wBAAAAAAAAmUVhCgAAAAAAAJZwuTC1ePFiPfDAAypWrJjy5MkjX1/fFP8AAAAAAAAAZ1wqTP3888/q2LGjzp49q+7duyspKUlPPPGEunfvroCAANWuXVsjRoxwd6wAAAAAAADwIOka/PxW48aNU+PGjbV27VpdunRJ33zzjZ555hndd999Onr0qJo0aaLQ0FB3xwoAAIAcIDw8XFu3bk0xzWo5NS4AAOCcS4WpPXv2aNy4cfL19VWePDc2ER8fL0mqUKGCXn75ZX344Yfq1auX+yIFAABAjtC162O6fv2awzQ/f3+Lovn/cmpcAADAOZcKU/nz51e+fPkkSYULF5afn5/DX6NKliypI0eOuCdCAAAA5CjXr19TtzHfqERoZUnSuSMH9eOwlyyOKufGBQAAnHOpMFW1alXt2bPH/rpu3bqaPn26evTooYSEBM2YMUPly5d3W5AAAADIWUqEVtYd1etYHUYKOTUuAACQOpcGP3/kkUf066+/KjY2VpL0zjvvaOXKlSpcuLCKFy+uNWvWaMiQIW4NFAAAAAAAAJ7FpTumXn/9db3++uv21x07dtTKlSv1888/K0+ePOrQoYPCwsLcFiQAAAAAAAA8j0uFqdQ0b95czZs3d9fmAAAAAAAA4OHcVpi6evWqZs2apdjYWD344IMKCQlx16YBAAAAAADggVwqTD377LPauHGjdu3aJUmKi4tTkyZN7K+DgoK0fPly1atXz32RAgAAAAAAwKO4NPj5ihUr9Oijj9pfz5gxQ7t27dIPP/ygXbt2qVSpUho9erTbggQAAAAAAIDncakwdebMGVWoUMH+et68eWrYsKGeeOIJ1ahRQ88//7w2btzorhgBAAAAAADggVwqTBUoUECRkZGSpISEBK1cuVJt27a1zw8MDFRUVJRbAgQAAAAAAIBncmmMqfr162vKlCkKCwvT/PnzdfnyZXXq1Mk+/59//lHJkiXdFiQAAAAAAAA8j0uFqbFjx6pt27Zq2LChjDHq2rWrGjdubJ//yy+/qGnTpm4LEgAAAAAAAJ7HpcJUw4YNtW/fPq1bt06FCxdWy5Yt7fMiIyP18ssvO0wDAAAAAAAAbuVSYUqSihcvrs6dO6eYXrhwYQ0cODBTQQEAAAAAAMDzpbswdfz4cafzbDab/P39FRwcLJvN5pbAAAAAAAAA4NnSXZiqUKHCbYtO+fPnV9u2bTV27FhVrVo108EBAAAAAADAc6W7MDV+/Pg0C1NXr17Vvn379Ntvv2n58uXasGGDqlSp4pYgAQAAAAAA4HnSXZh6/fXX07Xc8ePH1aBBA7377rv673//63JgAAAAAAAA8Gw+7t5g+fLl9fzzz2vZsmXu3jQAAAAAAAA8iNsLU5IUGhqqixcvZsWmAQAAAAAA4CGypDB19OhRFS1aNCs2DQAAAAAAAA/h9sLUiRMnNHnyZIWFhbl70wAAAAAAAPAg6R78fMKECWnOv3btmvbv368FCxZIkkaNGpWpwAAAAAAAAODZ3PqrfPnz51ebNm30/vvvq0qVKpkKDAAAAAAAAJ4t3YWpI0eOpDnf399fxYsXl49PlgxbBQAAAAAAAA+T7sJUSEhIVsYBAAAAAAAAL8PtTQAAAAAAALAEhSkAAAAAAABYgsIUAAAAAAAALEFhCgAAAAAAAJZIV2Hqiy++0IEDB7I6FgAAAAAAAHiRdBWmXn31VW3evNn+2tfXVzNmzMiyoNJy6tQp9ejRQ8WKFVNAQIBq1arlEBsAAAAAAAByhzzpWahIkSI6e/as/bUxJssCSsulS5fUtGlThYWFafHixSpevLgOHjyoIkWKWBIPAAAAAAAAXJeuwlSrVq00atQobd++XUFBQZKk77//Xhs2bHC6js1m0+eff+6eKP/Phx9+qHLlymnq1Kn2aaGhoW7dBwAAAAAAALJHugpTX3/9tQYNGqSlS5fq3LlzstlsWrp0qZYuXep0nawoTM2fP19t27bVY489plWrVumOO+7Qyy+/rOeff97pOrGxsYqNjbW/jo6OdmtMAAAAAAAAcE26xpgqUaKEZsyYofDwcCUmJsoYo//+979KSkpy+i8xMdHtwR4+fFjffPONKleurN9//10vvfSSBgwYoP/85z9O1xk3bpyCgoLs/8qVK+f2uAAAAAAAAJBx6SpM3Wrq1Km699573R3LbSUlJal+/fp6//33Va9ePb3wwgt6/vnn9e233zpdZ+jQoYqKirL/O3HiRDZGDAAAAAAAAGfS9SjfrXr37m3//z179ujYsWOSpJCQENWoUcM9kaWidOnSKbZfvXp1/fzzz07X8fPzk5+fX5bFBAAAAAAAANe4VJiSpF9//VWDBw/W0aNHHaaHhoZqwoQJeuihhzIbWwpNmzbV/v37HaYdOHBAISEhbt8XAAAAAAAAspZLj/ItWrRIXbp0kSS9//77+uWXX/TLL7/o/ffflzFGjz76qJYsWeLWQCXp1Vdf1YYNG/T+++/r0KFDmjFjhiZPnqx+/fq5fV8AAAAAAADIWi7dMfXee++pdu3aWrNmjQoUKGCf/tBDD+mVV15Rs2bNNHr0aLVr185tgUpSo0aN9Msvv2jo0KF69913FRoaqs8++0xPPfWUW/cDAAAAAACArOdSYervv//W+++/71CUSlagQAE9/fTTevvttzMdXGo6duyojh07Zsm2AQAAAAAAkH1cepTP399fFy9edDr/4sWL8vf3dzkoAAAAAAAAeD6XClP33XefPv/8c61fvz7FvI0bN+qLL75Q69atMx0cAAAAAAAAPJdLj/KNHz9e99xzj5o1a6bGjRuratWqkqT9+/frr7/+UokSJfThhx+6NVAAAAAAAAB4FpfumAoNDdXff/+tAQMG6NKlS5o9e7Zmz56tS5cuaeDAgdqxY4cqVKjg5lABAAAAAADgSVy6Y0qSSpQooU8//VSffvqpO+MBAAAAAACAl3DpjikAAAAAAAAgsyhMAQAAAAAAwBIUpgAAAAAAAGAJClMAAAAAAACwBIUpAAAAAAAAWCLDhamrV6+qQYMG+vbbb7MiHgAAAAAAAHiJDBem8ufPryNHjshms2VFPAAAAAAAAPASLj3K165dO/3+++/ujgUAAAAAAABexKXC1PDhw3XgwAH17NlTa9eu1alTp3Tx4sUU/wAAAAAAAABn8riy0l133SVJ2rNnj2bMmOF0ucTERNeiAgAAAAAAgMdzqTA1YsQIxpgCAAAAAABAprhUmBo1apSbwwAAAAAAAIC3cWmMqVtFRUXx2B4AAAAAAAAyxOXC1ObNm9WuXTvlz59fxYoV06pVqyRJERER6ty5s1auXOmuGAEAAAAAAOCBXCpMrVu3Ts2aNdPBgwfVo0cPJSUl2ecFBwcrKipKkyZNcluQAAAAAAAA8DwuFabefvttVa9eXXv27NH777+fYn5YWJg2btyY6eAAAAAAAADguVwqTG3atEl9+vSRn59fqr/Od8cdd+jMmTOZDg4AAAAAAACey6XCVN68eR0e37vVqVOnVLBgQZeDAgAAAAAAgOdzqTDVpEkT/fTTT6nOi4mJ0dSpU9WyZctMBQYAAAAAAADP5lJhavTo0dq8ebM6dOigxYsXS5J27Nihf/3rX2rQoIHOnz+v4cOHuzVQAAAAAAAAeJY8rqx09913a9GiRXrppZfUq1cvSdJrr70mSapYsaIWLVqk2rVruy9KAAAAAAAAeByXClOSdN9992n//v3atm2bDh06pKSkJFWsWFENGjRIdUB0AAAAAAAA4GYuF6aS1atXT/Xq1XNHLAAAAAAAAPAiLhemYmNjNWXKFC1atEhHjx6VJFWoUEEPPvignnvuOfn7+7srRgAAAAAAAHgglwY/P3nypOrWrasBAwZox44dKl68uIoXL64dO3ZowIABqlu3rk6ePOnuWAEAAAAAAOBBXCpM9evXT8eOHdOPP/6oU6dOadWqVVq1apVOnTql2bNn6/jx4+rXr5+7YwUAAAAAAIAHcelRvmXLlunVV19V165dU8x77LHHtHXrVn355ZeZDg4AAAAAAACey6U7pgIDA1WiRAmn80uVKqXAwECXgwIAAAAAAIDnc6kw1adPH02bNk1Xr15NMe/KlSuaOnWqnn322UwHBwAAAAAAAM+Vrkf55s6d6/C6Xr16WrhwoapVq6bevXurUqVKkqSDBw/q+++/V9GiRVW7dm33RwsAAAAAAACPka7CVNeuXWWz2WSMkSSH/x87dmyK5U+ePKknnnhC3bp1c2OoAAAAAAAA8CTpKkytWLEiq+MAAAAAAACAl0lXYaply5ZZHQcAAAAAAAC8jEuDnwMAAAAAAACZla47plKzdu1afffddzp8+LAuXbpkH3Mqmc1m044dOzIdIAAAAAAAADyTS4WpCRMm6I033pC/v7+qVq2qokWLujsuAAAAAAAAeDiXClMfffSRmjZtqgULFigoKMjdMQEAAAAAAMALuDTG1NWrV/XUU09RlAIAAAAAAIDLXCpMhYWFaefOne6OBQAAAAAAAF7EpcLUl19+qWXLlunjjz/WxYsX3R0TAAAAAAAAvIBLhaly5cqpb9++GjJkiIoXL64CBQqoUKFCDv94zA8AAAAAAABpcWnw8xEjRmjs2LG644471LBhQ4pQAAAAAAAAyDCXClPffvutOnTooHnz5snHx6WbrgAAAAAAAODlXKoqxcXFqUOHDhSlAAAAAAAA4DKXKksdO3bUmjVr3B0LAAAAAAAAvIhLhamRI0dqz549evnll7VlyxadP39eFy9eTPEPAAAAAAAAcMalMaaqVq0qSdq+fbsmTZrkdLnExETXogIAAAAAAIDHc/lX+Ww2m7tjAQAAAAAAgBdxqTA1atQoN4cBAAAAAAAAb8PP6gEAAAAAAMASLt0x9e677952GZvNpuHDh7uyeQAAAAAAAHgBtz/KZ7PZZIyhMAUAAAAAAIA0ufQoX1JSUop/CQkJ+ueff/Tqq6+qYcOGOnfunLtjBQAAAAAAgAdx2xhTPj4+Cg0N1ccff6zKlSurf//+7to0AAAAAAAAPFCWDH7eokULLVq0KCs2DQAAAAAAAA+RJYWpzZs3y8cn63/w74MPPpDNZtOgQYOyfF8AAAAAAABwL5cGP//+++9TnR4ZGanVq1dr7ty5eu655zIV2O1s2rRJkyZNUu3atbN0PwAAAAAAAMgaLhWmnn76aafzgoODNWTIEI0YMcLVmG7rypUreuqppzRlyhSNGTMmy/YDAAAAAACArONSYerIkSMpptlsNhUpUkSBgYGZDup2+vXrpw4dOqh169a3LUzFxsYqNjbW/jo6OjqrwwMAAAAAAEA6uFSYCgkJcXcc6TZr1ixt3bpVmzZtStfy48aN0+jRo7M4KgAAAAAAAGRU1o9Q7kYnTpzQwIED9cMPP8jf3z9d6wwdOlRRUVH2fydOnMjiKAEAAAAAAJAe6b5jKqODjNtsNu3YsSPDAaVly5YtOnfunOrXr2+flpiYqNWrV2vixImKjY2Vr6+vwzp+fn7y8/NzaxwAAAAAAADIvHQXpooWLSqbzXbb5c6cOaP9+/ena9mMuv/++7Vz506HaX369FG1atX01ltvpShKAQAAAAAAIOdKd2Fq5cqVac4/c+aMPvzwQ02aNEm+vr7q2bNnZmNLITAwUDVr1nSYVqBAARUrVizFdAAAAAAAAORsLg1+frOzZ8/qgw8+0OTJkxUfH68ePXronXfeUcWKFd0RHwAAAAAAADyUy4Wp5Dukbi5IDRs2THfeeac747ut293JBQAAAAAAgJwpw4WpM2fO6IMPPtCUKVMUHx+vnj17atiwYQoNDc2K+AAAAAAAAOCh0l2YCg8PtxekEhIS1KtXL73zzjsUpAAAAAAAAOCSdBemKlasqNjYWNWtW1dvv/22QkNDdenSJV26dMnpOvXr13dLkAAAAAAAAPA86S5MXb9+XZK0bds2devWLc1ljTGy2WxKTEzMXHQAAAAAAADwWOkuTE2dOjUr4wAAAAAAAICXSXdhqnfv3lkZBwAAAAAAALyMj9UBAAAAAAAAwDtRmAIAAAAAAIAlKEwBAAAAAADAEhSmAAAAAAAAYAkKUwAAAAAAALAEhSkAAAAAAABYgsIUAAAAAAAALEFhCgAAAAAAAJagMAUAAAAAAABLUJgCAAAAAACAJShMAQAAAAAAwBIUpgAAAAAAAGAJClMAAAAAAACwBIUpAAAAAAAAWILCFAAAAAAAACxBYQoAAAAAAACWoDAFAAAAAAAAS1CYAgAAAAAAgCUoTAEAAAAAAMASFKYAAAAAAABgCQpTAAAAAAAAsASFKQAAAAAAAFiCwhQAAAAAAAAsQWEKAAAAAAAAlqAwBQAAAAAAAEtQmAIAAAAAAIAlKEwBAAAAAADAEhSmAAAAAAAAYAkKUwAAAAAAALAEhSkAAAAAAABYgsIUAAAAAAAALEFhCgAAAAAAAJagMAUAAAAAAABLUJgCAAAAAACAJShMAQAAAAAAwBIUpgAAAAAAAGAJClMAAAAAAACwBIUpAAAAAAAAWILCFAAAAAAAACxBYQoAAAAAAACWoDAFAAAAAAAAS1CYAgAAAAAAgCUoTAEAAAAAAMASFKYAAAAAAABgCQpTAAAAAAAAsASFKQAAAAAAAFiCwhQAAAAAAAAsQWEKAAAAAAAAlqAwBQAAAAAAAEtQmAIAAAAAAIAlKEwBAAAAAADAEhSmAAAAAAAAYAkKUwAAAAAAALAEhSkAAAAAAABYIlcVpsaNG6dGjRopMDBQJUqU0MMPP6z9+/dbHRYAAAAAAABckKsKU6tWrVK/fv20YcMG/fHHH4qPj1ebNm0UExNjdWgAAAAAAADIoDxWB5ARS5YscXg9bdo0lShRQlu2bFGLFi0sigoAAAAAAACuyFWFqVtFRUVJkooWLep0mdjYWMXGxtpfR0dHZ3lcAAAAAAAAuL1c9SjfzZKSkjRo0CA1bdpUNWvWdLrcuHHjFBQUZP9Xrly5bIwSAAAAAAAAzuTawlS/fv20a9cuzZo1K83lhg4dqqioKPu/EydOZFOEAAAAAAAASEuufJTvlVde0W+//abVq1erbNmyaS7r5+cnPz+/bIoMAAAAAAAA6ZWrClPGGPXv31+//PKLVq5cqdDQUKtDAgAAAAAAgItyVWGqX79+mjFjhn799VcFBgbqzJkzkqSgoCAFBARYHB0AAAAAAAAyIleNMfXNN98oKipKrVq1UunSpe3/Zs+ebXVoAAAAAAAAyKBcdceUMcbqEAAAAAAAAOAmueqOKQAAAAAAAHgOClMAAAAAAACwBIUpAAAAAAAAWILCFAAAAAAAACxBYQoAAAAAAACWoDAFAAAAAAAAS1CYAgAAAAAAgCUoTAEAAAAAAMASFKYAAAAAAABgCQpTAAAAAAAAsASFKQAAAAAAAFiCwhQAAAAAAAAsQWEKAAAAAAAAlqAwBQAAAAAAAEtQmAIAAAAAAIAlKEwBAAAAAADAEhSmAAAAAAAAYAkKUwAAAAAAALAEhSkAAAAAAABYgsIUAAAAAAAALEFhCgAAAAAAAJagMAUAAAAAAABLUJgCAAAAAACAJShMAQAAAAAAwBIUpgAAAAAAAGAJClMAAAAAAACwBIUpAAAAAAAAWILCFAAAAAAAACxBYQoAAAAAAACWoDAFAAAAAAAAS1CYAgAAAAAAgCUoTAEAAAAAAMASFKYAAAAAAABgCQpTAAAAAAAAsASFKQAAAAAAAFiCwhQAAAAAAAAsQWEKAAAAAAAAlqAwBQAAAAAAAEtQmAIAAAAAAIAlKEwBAAAAAADAEhSmAAAAAAAAYAkKUwAAAAAAALAEhSkAAAAAAABYgsIUAAAAAAAALEFhCgAAAAAAAJagMAUAAAAAAABLUJgCAAAAAACAJShMAQAAAAAAwBIUpgAAAAAAAGAJClMAAAAAAACwBIUpAAAAAAAAWILCFAAAAAAAACxBYQoAAAAAAACWoDAFAAAAAAAAS1CYAgAAAAAAgCUoTAEAAAAAAMASFKYAAAAAAABgCQpTAAAAAAAAsASFKQAAAAAAAFiCwhQAAAAAAAAskSsLU1999ZUqVKggf39/3X333frrr7+sDgkAAAAAAAAZlOsKU7Nnz9bgwYM1cuRIbd26VXXq1FHbtm117tw5q0MDAAAAAABABuS6wtSECRP0/PPPq0+fPqpRo4a+/fZb5c+fX999953VoQEAAAAAACAD8lgdQEbExcVpy5YtGjp0qH2aj4+PWrdurfXr16e6TmxsrGJjY+2vo6KiJEnR0dFZG2w2uHLliiTp1N6/FXc1RpJ0/tg/9vkZmX716lW2xbbYlgdu69bpbMv6NmFbbItt5Zxt3TqdbVnfJmyLbbGtnLOtW6dn1bauXLmS4vt5Rr7rujOunNImqR2T3CY5fmPMbZe1mfQslUOcPn1ad9xxh9atW6d77rnHPv3NN9/UqlWrtHHjxhTrjBo1SqNHj87OMAEAAAAAALzeiRMnVLZs2TSXyVV3TLli6NChGjx4sP11UlKSLl68qGLFislms1kYmftER0erXLlyOnHihAoVKmR1ONnOm/Mnd3L3ttwl786f3Mnd23KXvDt/cvfO3CXvzp/cvTP3tHBccidjjC5fvqwyZcrcdtlcVZgKDg6Wr6+vzp496zD97NmzKlWqVKrr+Pn5yc/Pz2Fa4cKFsypESxUqVMirT1Rvzp/cyd0beXP+5E7u3sib8yd378xd8u78yd07c08LxyX3CQoKStdyuWrw83z58qlBgwZatmyZfVpSUpKWLVvm8GgfAAAAAAAAcr5cdceUJA0ePFi9e/dWw4YN1bhxY3322WeKiYlRnz59rA4NAAAAAAAAGZDrClOPP/64zp8/rxEjRujMmTOqW7eulixZopIlS1odmmX8/Pw0cuTIFI8segtvzp/cyd0beXP+5E7u3sib8yd378xd8u78yd07c08Lx8Xz5apf5QMAAAAAAIDnyFVjTAEAAAAAAMBzUJgCAAAAAACAJShMAQAAAAAAwBIUpgAAAAAAAGAJClMAAAAAAACwBIUpD5WUlGR1CJZJTEy0OgTLeHO7S96dP7l7J2++3km0vbfy5twBAJIxxuoQ4GYUpjxMZGSkJMnHx8frPrBHRERIknx9fb3uQ6s3t7vk3fmTu3fm7s3XO4m2l7yz7b0592Te/GWM3L2TN+cukf+tbj0e3vYZwJNRmPIge/fuVf369TVixAhJ3vWBfe/evSpXrpyee+45Sd71odWb213y7vzJ3Xtz99brnUTbe2vbe3PuknTs2DHt3r1bNpvN676oHjp0SJs2bZLNZvOacz2ZN7e7N+cukX9qDh06pNGjR6tPnz766KOPdPbsWfn4+HB8PASFKQ9x4sQJPfnkk8qTJ49++eUXvfvuu5K84wP7qVOn9PTTT6tGjRpavHix+vbtK8k7PrR6c7tL3p0/uXtn7t58vZNoe29te2/OXZL279+v+vXrq1OnTtq8ebNXfVE9cOCAateurbvvvlsrV670inM9mTe3uzfnLpF/anbu3Kl77rlHBw8e1OHDhzV//nwNGDBAMTExstlsVocHN6Aw5QGMMZo5c6bKlCmjr776Sl26dNHMmTMdPrB76gc3Y4x+//13lS1bVp988onGjh2rX3/91eFDa0JCgsVRZg1vbnfJu/Mnd+/N3Vuvd9KN/GfMmEHbe1nbe3PuknTmzBm98sorql27tmrVqqW+ffvqr7/+8oovqhEREXrttdd033336YknntCjjz6q5cuXe0Vxypvb3Ztzl8g/NSdPntQTTzyh5557Tj/88INWrVql559/Xnv27NHZs2etDg9uksfqAJB5NptNvXr1UsmSJfXAAw+oTp06kqSZM2fKGKORI0fK19dXSUlJ8vHxrFqkzWbTQw89pKCgILVq1UrXr1+XMUZDhw6VMUaTJ09Wnjx5lJiYKF9fX6vDdStvbnfJu/Mnd+/N3Vuvd8YYe9uXKlWKtveitvfm3CXp6NGj8vX11bBhwyRJn3/+uV588UV9++23aty4sUf292Th4eEKCgpS7969FRoaKj8/P3Xt2lVz5szR/fff79G5e3O7e3PuEvnfyhij1atXq1y5cnrxxRft+T/++OMaNmyYdu7cqTvvvNPqMOEOBh7p9OnTZuTIkaZatWpm1KhR9unz5s0ziYmJFkbmXklJSSmmXb582UydOtWULFnSPP/88/bp06dPN8eOHcvO8LKdt7S7M56ef3x8vNN5np77pUuXnM7z9NzPnTuX6rXOGO+43h09etQsWrQo1Xme3va3urkfeEPbO+NtuW/evNn+/8uXLzcPP/ywqVevntmwYYMx5ka/8MT+bowxO3futP///v37zdNPP22KFCli/vjjD2PMjdwTEhJMXFycVSFmGW9u902bNtn/39tyN8a72z41y5cvN//+97/trxMSEsz169dNxYoVzaxZs1Is703HxpNQmMqlTp8+bTZu3GiWLFliEhIS7NMTExPtH1xPnTpl/8A+cuRIM2jQIGOz2cypU6esCtstkvNN66ITHR1t/9D6wgsvmMGDBxubzZbrP7BGRESYvXv3mvXr19un3Vqs8NR2N8aYkydPmqVLl5pp06bZ8765/xvjufnv27fPvPXWW+bgwYP2abcWKzw1923btplmzZqZHTt2OF3GU3PfuXOnqVq1qvnqq6+cXvM89XpnzI388+TJY2rWrGmf5i39/p9//jGffvqpGTx4sFm9erW5evVqimU8te1PnTpl/vrrL7NgwQJz/fp1e5vffA54au7psWLFCvsX1Y0bNxpjjHnrrbfMmjVrLI7MPZKSkpwW4w8cOGAvTv3555/GGGNef/1188MPPzhdJ7e6NR9Pb/e0eHru0dHRJiYmxul8T88/NceOHTN79uwxxjieCze/DzRp0sTMnDnT/nry5Mm5/r3fm1GYyoV27NhhQkJCTJUqVUxQUJCpVq2amTFjhrlw4YIxxrE4dfr0aTNixAhjs9lMkSJFHCrwudHOnTtNq1atzPHjx40xaRenLl++bP79738bm81mihYtmutz//vvv03jxo1N1apVTYkSJUzbtm3t85Lb21Pb3Zgb+VepUsXUr1/fFChQwNSvXz/FX0g9Mf+kpCRz9epV06hRI2Oz2cyLL75o7//J82/+ryflbowx27dvN3nz5jVvvPFGinnJ57+n5r53715TpEgRM3jw4FS/bN/85c3TrnfG3ChIFihQwHTo0MFUrFjRfP/99ymW8dS2//vvv02JEiVM+/btzZ133mkqVKiQojDrqW2/Y8cOU6FCBdOoUSNTunRpU6FCBTNp0iRz/vx5Y4zjZxxPy90YYw4ePGjGjRtnhgwZYmbMmGEuX75sn3fzH6JWrFhhHnnkEdOwYUPTpUsXY7PZzN9//21FyG4TERFh//+0ikzJxakSJUqYjh07GpvNluYfLnKDY8eOme+++8588skn9rvBkt18LDyx3Q8ePGiGDx9uevToYaZMmeIwz9NzN+bGnYC1a9c23333XYrilDfkn5qtW7ea4sWLmzlz5jhMv/W60KhRIzN9+nRjjDHDhg0zNpvN7N27N9vihHtRmMplzp07Z6pVq2befvtt888//5hTp06Zxx9/3FSvXt2MHDnSnDt3zhjjeOL27NnTFCpUyOzevduqsN3iyJEjplKlSsZms5nKlSubEydOGGPSLk716dPHFCxYMNfnvm/fPhMcHGyGDBli1q9fb37//Xdz5513mqFDhzpdx1Pa3ZgbX9CDg4PNsGHDzLFjx8zhw4dNcHCw+e233xyW88R+n+ztt982ffr0MQEBAeaJJ54wR44ccZh/83ngKbnv2rXLBAQEmBEjRhhjbrTvhQsXzOHDhx2W88R2T0xMNC+88ILp06eP/fXq1avNd999Z/bv329/tPHmdveU650xNwqS+fPnN8OHDzdxcXGmSZMmpmfPnmmu4yltf/r0aVO9enUzatQo+x2hNWrUMF9//bXDcp7Y9idOnDCVKlUyo0ePNqdPnzZJSUnm0UcfNf7+/mbQoEH2v4TffM57Su7G3LjmFS5c2LRs2dK0aNHC5MmTx3Tp0sUsWbLEvszNxak//vjDFC9e3BQuXNhs377dipDdZvfu3cbX19f069fPPu3WL6E3v969e7cpV66cKVq0aK7P/e+//zYhISGmadOmpkaNGiZv3rzmP//5j8MyN+fuSe2+Y8cOU7p0adOhQwfTuXNn4+vra7799luHZW6+1nlS7sneeecdY7PZTOnSpc306dPNtWvXHOZ76jnvzPbt202BAgXMq6++6nSZhIQEExsba6pUqWJ++ukn88knnxg/Pz+zZcuWbIwU7kZhKpfZvXu3qVChQoq/Cr711lumVq1aZvz48Q7V9n/961+mcOHCZuvWrdkdqltdu3bNDBs2zDzyyCNm2bJlpkWLFiYkJCTN4tTcuXNNSEhIrv8L6uXLl023bt3Myy+/bJ+WmJho+vfvbx566KFU15kyZYpHtLsxxkRGRpoHH3zQDBo0yGF627ZtzZQpU8yECRPMnj177I+5JCUleVT+yX174MCB5quvvjK7d+82fn5+plevXiYmJsZ89NFH5ujRo/blPeWcj4iIMJUqVTL16tWzT+vTp49p0KCBKV26tGnRooXZtm2bw4d1T8ndmBsfupo1a2b/ctKyZUvToEEDExQUZCpWrGj69u1rv3MuKSnJY653xtz467nNZjPvvPOOfdqcOXOMn5+fWbFiRarreFLbr1271tSsWdMcOHDAPu3xxx83r7/+uunRo4f57rvvPLbtlyxZYu6++25z/vx5Exsba4y5MdZMcHCwqVevnhk5cqTDlzZPyv3q1aumY8eODoWZLVu2mIYNG5rWrVubuXPn2qcnvy8MGjTIBAQEOIzDlBudOnXKNG7c2DRs2NAULFjQ9O/f3z4vtTunkpKSzKBBg0zevHlzfe6HDx82ISEh5q233jLXr18358+fN6NHjzb16tUz4eHhDvkn/7+ntPvBgwdN+fLlzdChQ+19+vnnnzfDhg1LsWxykd5Tcr/ZH3/8Yd555x3z1ltvmXz58plp06al6Peeds47s3fvXpM/f37z9ttvG2NuFOVWrlxpfvnlF7N69eoUy4eFhZlKlSqZ/PnzO4xLhtyJwlQus337dlO2bFn7yXnzmBMDBgwwoaGhDrcznzlzJsXdBbnVrFmzzOzZs40xNwbDbd68eZrFqYiICHPy5Mlsj9PdLl++bJ599lkzefJkh+mzZ882tWrVMrGxsSkeaQsPD/eYdjfGmG+//dasW7fO/vq9994zefLkMWFhYaZ69eqmZMmS9r5hjGf1+2SLFy82zz77rDHGmL/++sv4+fmZChUqmDvuuMMhV0/K/ZVXXjHNmjUzI0eONI0aNTLt2rUzkydPNr/88ou55557TEhIiMOYW56UuzHGPProo+bzzz83w4cPN23atDGHDh0y8fHx5rPPPjP33nuvGT16tP3D64ULFzziemfMjbtmJk2aZH+dlJRkTp48aZo2bWr/C+qt13tPavuFCxeaEiVKmMWLF5vr16+b8ePHm7x585r+/fub9u3bm0aNGpn+/fvb/wjlSW0/efJkU6JECYdpK1asMJ06dTK9evUypUuXdnis1ZNyN8aYe++914wcOdIY8//7+N69e02rVq1Mu3btHO6Q2LZtm6ldu3auv0MgMTHR/PDDD+axxx4z//vf/8zs2bNNQECAQ3Hq1vN93759pkOHDrm+EB0fH2+GDx9uOnfu7PB5funSpaZUqVLm9OnTKdbZunWrR7R7fHy8ee2118xzzz3nUGzu0aOHad++vWnXrp155513HPq8p+R+qz/++MPUqFHDGGNM3759TUBAgJk3b57p27ev+eyzz+zLeWr+yeLi4swjjzxiihcvbh/kvVOnTqZOnTqmZMmSJm/evKZfv37m7Nmzxpgb14WWLVuaAgUKeOwjjd6GwlQu1KhRIxMWFmZ/ff36dfv/N2zY0HTv3t0Yk3JQaE+SlJRk/vnnH/udU8kfTK9fv262bt3qMCZDbpeYmOhwR0zyF9HkwtTNrly5kq2xZbXU/lK6evVqU7FiRTN//nz7F7OHHnrINGzY0BjjWb/EcXP+y5YtM1WrVrV/eG3fvr3x8fEx7du3N+Hh4VaFmCVubsPBgwebkiVLmg4dOpgzZ844LHfXXXeZ3r17G2M863qXnP+LL75o6tata5566imHQo0xNwb7rV69ukf+EpUzI0aMMEWKFLGPQ5PagNieIiwszJQuXdrcf//9xs/PzyxevNg+74MPPjDly5f3yEG+w8PDTalSpUzPnj3NoUOHzNq1a03+/PnNBx98YIwxpmrVqua9994zxnjWOW/MjT9ChYWFmRdffNEYcyO/5Ed4du/ebcqWLWsGDhzosE5kZGR2h5kljh8/bubPn29/PXPmzBTFqVs/D3jK57wff/zRjB071mFaZGSkKVeunNMv257S7gcPHjQrV660vx4zZozx8fEx/fr1M6NHjzbBwcHmkUcecXiUzVNyN+b/9+moqCjTokUL+2fawYMHG19fX1O4cOEUdwF5Uv6p2bJli2nbtq1p06aNqVatmmnXrp3ZunWrOXbsmFm4cKHJly+ffRiTpKQkM2vWLI/5oxQoTOV4V65cMdHR0SYqKso+bevWraZEiRLmiSeesE9LvmgPHjzYdOrUKdvjzAqp5W6M45eQQ4cO2YtThw8fNv369TMNGzZM86flc4P05D5nzhxz11132V8PHjzYdOzY0SM+rDvL35gbv8z3zz//GGP+f7//6KOPzN133+0RX9Kd5X769GnTsWNHY8yNR9rKli1rpk2bZgoWLGgeeughj7hrwFnuH3/8sfn555/tH+KS+3iXLl1M165dsz3OrJBa7jExMaZOnTrGZrPZb2tPtnTpUlOnTp1cf61LltY5n9zu58+fN9WrVzdDhgzxqF/fcpb72rVrzbx580yDBg1MRESE/Xq3bt06U6lSJbN//34rwnWr1HL/5ZdfTLly5UyJEiVM0aJFzeDBg+3zmjVrZoYMGWJFqFniwoULZu/evfa2XLBggbHZbObnn382xtx4z09+X5sxY4YpUqSIOXbsmEe8z1+4cMHs2bMn1X6ckJBgZs2a5VCcSkhIMNOnT/eIcXWScz948KBD30++rl25csWUK1fO4c6Y5DtIcrvk3Pft2+cw/ciRI+app55yKMJv2LDB2Gw2s2HDBo+55ief8wcOHLA/rmzMjZsOkge9f/75503BggWNn5+fmTVrVqq/yOpJbu0Te/fuNU2bNjUPPPBAivFUJ06caIKDgz3yDzOgMJWj7d6927Rp08bUq1fPlClTxvz3v/81xtwYb2nmzJkmODjYdO3a1cTFxdkLFj169DDdu3c38fHxufoi7iz31HL6559/TKtWrYzNZjMFChQwf/31V3aH61bpzX3hwoWmatWqxhhjhg4dagICAsz69euzPV53y0jbJ3v22WfNM8884/BXtdzIWe7G3PhQ3rJlS1O6dGlTsmRJ+1/RVq9ebUqWLJnrfx43tdxv/vJ18wc4Y270h65duzoMjJ5bpZX7hg0bTM2aNU1oaKhZsmSJ/a7I1157zbRs2TLNn5fOLdJ7zsfHx5s+ffqYe+65xyOK0MaknvvN17HFixenuDP29ddfNw0bNjQXL17M7nDd6tbck39ZyZgbd8Ns3LjRYWiC69evm3bt2pmvvvrKGJO7z3ljbvzKcL169UytWrVM3rx5zejRo83169dN//79jZ+fn1mwYIHD8osWLTLVq1d3+OW63Orm3PPly2fee++9FJ9b4+PjHR7rGzBggMmTJ0+u/0KanHvNmjWNn5+fee+990xiYqL9c3x8fLw5c+aMKVOmjP3XxYYOHWpsNpv9B45yq9Ta/eb3+eRrWlJSkklMTDRr1qwxtWvXdnhqIDe7Of/ktk8uOj355JNm0aJFZsCAAaZMmTLm2LFjZuDAgcZmszkMVeFpbr0Ojho1yhhz43Hdn376yf5en3xtmDhxoqlVq1aKAeLhGShM5VC7d+82xYoVM6+++qr54YcfzODBg03evHntz9PHxMSY+fPnm7Jly5pq1aqZhx9+2HTr1s0UKFAg1w+I5yz3bdu2pbp8bGys6d69uylatGiu/1WejOT+66+/miZNmpi3337b5MuXzyOeOc9o28fFxZlhw4aZ4ODgXP/zsLfLPT4+3gwbNsy0atXK3tbJH+hy+xt0Rts9+ViULl3aYYyp3Oh21/rExESza9cuU69ePVO+fHlTp04d06lTJ4/5RZ70tn3yh9LDhw8bm82W4tHG3Cg9uUdGRpo77rjDNG/e3AwfPtw8++yzplixYrm+7W/X728VHR1thgwZYkqUKGG/YzY3S87/9ddfN7t37zYff/yxsdls5tSpU+bUqVPm+eefN3nz5jXffPONCQ8PN9euXTNDhgwxderU8YiCZGq5Jw/of7OEhAQzY8YMY7PZTJEiRXL9IPfpyT0pKcmcO3fOlClTxhw+fNi8++67pmDBgh7xR9f05H6zIUOGmJYtW+b6Pm+M8/yTi24fffSRsdlsDn94NObGHyJy++dbZ253TFJ7TH/gwIGmS5cuHvFHOaREYSoHunDhgmnTpo0ZMGCAw/RWrVo5PG9vzI0Pa2+++aZ57rnnzCuvvJLrCzPpyf3mN67ExETz5ZdfGl9f31w/CGZGc589e7bHfFgzJuP5//nnn6ZLly6mbNmyXtH2xtwYfyW1wVBz850DGW33pUuXmk6dOplSpUp5RbvfnPvkyZPNiBEjzAcffOARj3G5cr2Pjo42/fv3d/jFutwoPbnfPL5QWFiYueeee8xjjz3mFe/zN38h2bZtm3nxxRdNmTJlPOIPMOfPnzctWrRwGC8qKSnJtG3b1mzYsMH8/fff5q+//jJff/21yZcvnwkNDTW1a9c2xYsXz/XXPGe5t2vXzqxbt85s27bNoVCRkJBgnn32WRMYGGj27NljQcTuk57ck3/M5/r16+auu+4yrVu3Nvny5cv1n/Ey2u6HDh0yw4YNM4GBgR4xqHVa+f/vf/8zO3bsMNOnTzdvvvmm/Y8OnvC4blpud0ySx5VKdujQITN8+HBTuHBhs2vXLgsiRnbII+Q48fHxioyMVNeuXSVJSUlJ8vHxUWhoqC5evChJMjeKigoMDNSHH37osFxulp7cbTabfXkfHx+FhIRo7969qly5siUxu0tGc2/QoIGaNWumr776SrVq1bIkZnfKSP7GGIWGhqpWrVoaO3asqlatalnc7pCe3JOSklSqVKlU17+5X+Q2rrR7jRo1NH78eFWrVs2yuN0hvbknJibK19dXzz//vJXhup0r1/vAwEB99NFH8vPzsyRmd0lP7nny3PiIVqNGDS1fvlyxsbGy2WzKly+fZXG7Q3pyv/mzTN26ddW6dWu9+eabCg0NtSRmd7LZbGrXrp09f0kaM2aMli5dqvDwcEVGRqpGjRqaMGGC/v77b+3YsUPGGDVp0kQhISEWRp55znL//fffdebMGUVEROiuu+7SsGHD1KxZM/3xxx9auXKlli9frurVq1sYeealN/e3335b1atX1549e3To0CFt2rRJtWvXtjDyzEtv7sOHD1fp0qX1zjvvaNu2bVq9erVHfL5NK//w8HBFRUWpdu3aevHFF1WnTh1Jkq+vr1XhZovb9YkLFy6oRo0aGj58uEqVKqXXXntNO3bs0IoVK3TXXXdZGDmylKVlMTh181+Dk5+vHTZsmOnZs6fDcqkNmpjbpTf36OjobI0rO6Q39+Rfo/G0X+FLb/7JeXvSr3FltO09SXpzT75125P+kujK9c5TrvXG0O+TpZW7J/4KkyufcTzJzefzzJkz7ePIXLhwwaxcudI0bNjQPn6ep0kr91WrVplGjRrZx5k5c+aMR/3qbHpyHzlypDHGmE8//TTX3x15s/TkPnr0aBMXF2fWrFmT68cSu1Va+S9fvtw0btzY3u+9RUb6xPLly1MMhA7Pwx1TOVTy3T9JSUnKmzevpBt3C5w7d86+zLhx4+Tn56cBAwYoT548ufquiZu5krunSG/u+fLl06BBg1SgQAFL4swqtD25367fDxw40Ctz98RrvUS/l8jd23KXpMDAQPv/33PPPdq8ebPq168vSWrZsqVKliyprVu3WhVelkor9xYtWqhEiRLavHmzJKlkyZKWxJhV0pN7crsPGDAg1z8FcbP0tnvevHnVrFkzq8LMMmnlHxYWpuLFi2vLli1WhWeJjPSJsLAwq8JENvKsd3oP5OPjI2OM/YtI8pvUiBEjNGbMGG3bts3jPrAlI/e0c/fk23xpe3JPfi2Ru6fnLnl3/uTunbknCwkJsT+il5SUpLi4OBUsWDDXP76VHuSeMvfkR9c8qSh1K29ud4n8U8MxgSR57lXPgxhjJN0Yb6JcuXL6+OOPNX78eG3evNn+LLKnInfvzF3y7vzJndy9LXfJu/Mnd+/M/VY+Pj56//33tX79ej322GNWh5OtyP1G7t26dbM6nGzlze0ukX9qOCbey7P/DOUhkv9qkjdvXk2ZMkWFChXS2rVr7bc7ejJy987cJe/On9zJ3dtyl7w7f3L3ztxvNmfOHK1atUqzZs3SH3/8ket/0CUjyJ3cvS13ifxTwzHxbtwxlYu0bdtWkrRu3To1bNjQ4miyF7l7Z+6Sd+dP7uTubblL3p0/uXtn7tKNX188f/681qxZo3r16lkdTrYid3L3ttwl8k8Nx8S72UzyPdTIFWJiYjxuwOv0InfvzF3y7vzJndy9kTfnT+7embskxcfH2weD9zbkTu7eyNvzTw3HxHtRmAIAAAAAAIAleJQPAAAAAAAAlqAwBQAAAAAAAEtQmAIAAAAAAIAlKEwBAAAAAADAEhSmAAAAAAAAYAkKUwAAAAAAALAEhSkAAAA3mDZtmmw2m44ePWp1KDlKq1atVLNmTavDAAAAORSFKQAAkGPs3r1bPXr00B133CE/Pz+VKVNGPXr00J49e6wOze7999/XvHnzrA7DQYUKFWSz2dS/f/8U81auXCmbzaaffvrJgsgAAADSRmEKAADkCHPnzlX9+vW1bNky9enTR19//bWeffZZLV++XPXr19evv/5qdYiSnBemevbsqWvXrikkJCT7g/o/U6ZM0enTpy3bPwAAQEblsToAAACAf/75Rz179tSdd96p1atXq3jx4vZ5AwcOVPPmzdWjRw/9/fffCg0NtTBS53x9feXr62vZ/u+66y7t379fH3zwgb744gvL4rBCUlKS4uLi5O/vb3UoAAAgg7hjCgAAWO6jjz7S1atXNXnyZIeilCQFBwdr0qRJunLlij766CP79KeffloVKlRIsa1Ro0bJZrOlmP7f//5XDRo0UEBAgIoWLaru3bvrxIkTDsscPHhQXbp0UalSpeTv76+yZcuqe/fuioqKkiTZbDbFxMToP//5j2w2m2w2m55++mlJzseY+vrrr3XXXXfZH03s16+fIiMjHZZJHodpz549CgsLU/78+XXHHXdo/Pjx6TyCNx7n69WrV7rumsrIsbPZbHrllVc0Z84c1ahRQwEBAbrnnnu0c+dOSdKkSZNUqVIl+fv7q1WrVk7H2NqyZYvuvfdeBQQEKDQ0VN9++22KZWJjYzVy5EhVqlRJfn5+KleunN58803FxsamGtMPP/xgP7ZLlixJM2cAAJAzUZgCAACWW7BggSpUqKDmzZunOr9FixaqUKGCFixY4NL2x44dq169eqly5cqaMGGCBg0apGXLlqlFixb2IlFcXJzatm2rDRs2qH///vrqq6/0wgsv6PDhw/Zlpk+fLj8/PzVv3lzTp0/X9OnT1bdvX6f7HTVqlPr166cyZcrok08+UZcuXTRp0iS1adNG8fHxDsteunRJ7dq1U506dfTJJ5+oWrVqeuutt7R48eJ05/nOO+8oISFBH3zwQYaPUVrWrFmj1157Tb1799aoUaO0d+9edezYUV999ZW++OILvfzyy3rjjTe0fv16PfPMMynWv3Tpkh588EE1aNBA48ePV9myZfXSSy/pu+++sy+TlJSkhx56SB9//LE6deqkL7/8Ug8//LA+/fRTPf744ym2uXz5cr366qt6/PHH9fnnn6daaAMAALmAAQAAsFBkZKSRZDp37pzmcg899JCRZKKjo40xxvTu3duEhISkWG7kyJHm5o84R48eNb6+vmbs2LEOy+3cudPkyZPHPn3btm1GkpkzZ06acRQoUMD07t07xfSpU6caSebIkSPGGGPOnTtn8uXLZ9q0aWMSExPty02cONFIMt999519WsuWLY0k8/3339unxcbGmlKlSpkuXbqkGY8xxoSEhJgOHToYY4zp06eP8ff3N6dPnzbGGLNixYoUeaX32BljjCTj5+dnz8sYYyZNmmQkmVKlStnbwxhjhg4d6nAMbs7tk08+ccitbt26pkSJEiYuLs4YY8z06dONj4+PWbNmjcP+v/32WyPJ/O9//3OIycfHx+zevfu2xwYAAORs3DEFAAAsdfnyZUlSYGBgmsslz09ePr3mzp2rpKQkdevWTREREfZ/pUqVUuXKlbVixQpJUlBQkCTp999/19WrVzOaRgp//vmn4uLiNGjQIPn4/P+PXM8//7wKFSqkhQsXOixfsGBB9ejRw/46X758aty4sQ4fPpyh/Q4bNsztd03df//9Dnck3X333ZKkLl26OLRb8vRbY86TJ4/DnWX58uVT3759de7cOW3ZskWSNGfOHFWvXl3VqlVzaKf77rtPkuztlKxly5aqUaOG23IEAADWoDAFAAAsld6C0+XLl2Wz2RQcHJyh7R88eFDGGFWuXFnFixd3+Ld3716dO3dOkhQaGqrBgwfrX//6l4KDg9W2bVt99dVX9vGlMurYsWOSpKpVqzpMz5cvn+688077/GRly5ZNMb5TkSJFdOnSpQzt984771TPnj01efJkhYeHuxB5SuXLl3d4nVzEK1euXKrTb425TJkyKlCggMO0KlWqSJJ9TKqDBw9q9+7dKdooebnkdkqWUwfBBwAAGcOv8gEAAEsFBQWpTJky+vvvv9Nc7u+//1bZsmWVL18+SUp1gHNJSkxMdHidlJQkm82mxYsXp/qreQULFrT//yeffKKnn35av/76q5YuXaoBAwZo3Lhx2rBhg8qWLZvR1DLE2S/6GWMyvK133nlH06dP14cffqiHH344xfz0HrvbxebOmJOSklSrVi1NmDAh1fm3FsECAgIyvA8AAJDzUJgCAACW69SpkyZNmqS1a9eqWbNmKeavWbNGR48e1eDBg+3TihQpkuLX7SSluBOpYsWKMsYoNDTUfvdNWmrVqqVatWpp2LBhWrdunZo2bapvv/1WY8aMkeS8qHOrkJAQSdL+/ft155132qfHxcXpyJEjat26dbq244qKFSuqR48emjRpkv3xupul99i5y+nTpxUTE+Nw19SBAwckyf6IYMWKFbVjxw7df//96T7GAAAg9+NRPgAAYLnXX39d+fPnV9++fXXhwgWHeRcvXtSLL76oQoUK6ZVXXrFPr1ixoqKiohzutAoPD9cvv/zisP6jjz4qX19fjR49OsWdPMYY+/6io6OVkJDgML9WrVry8fFRbGysfVqBAgVSLercqnXr1sqXL5+++OILh/3++9//VlRUlDp06HDbbWTGsGHDFB8fr/Hjx6eYl95j5y4JCQmaNGmS/XVcXJwmTZqk4sWLq0GDBpKkbt266dSpU5oyZUqK9a9du6aYmJgsiQ0AAFiLO6YAAIDlKlWqpO+//15PPPGEatWqpWeffVahoaE6evSo/v3vf+vSpUuaNWuWw7hC3bt311tvvaVHHnlEAwYM0NWrV/XNN9+oSpUq2rp1q325ihUrasyYMRo6dKiOHj2qhx9+WIGBgTpy5Ih++eWX/9fe3bM0EoUBFD6rCJJOJQjBJhbTplBBsFerNMHOr8bBQhFFJEIK0yTYJE2wUJuMNqaJYCGC6C9QLBUbGxH8AzbqbrGssLjF7hJ3XDhPO8PlMuXhnXsJw5DV1VXOzs5YWFhgYmKCIAh4fn5mb2+P9vZ2crnc23oDAwOcnp5SqVRIpVKk0+lfTiUlk0nW19cpFouMj4+TzWa5ublha2uLoaGhnw46/wg/pqbq9fq7Z7/77VollUqxubnJ3d0dQRBwcHDA1dUV29vbdHR0ADA1NUWj0WB+fp7z83NGRkZ4eXnh+vqaRqPByckJg4ODLd+bJEmKl2FKkiR9CrlcjsvLS8rlMru7uzw+PvL6+kpnZycXFxfvbmDr6emh2WyysrLC2toa6XSacrnM7e3tu7iSz+cJgoBqtUqxWAS+n1k0OjpKNpsFIJPJMDY2xtHREff39yQSCTKZDMfHxwwPD7+tValUCMOQQqHA09MTMzMzvwxTABsbGySTSWq1GsvLy3R3dxOGIaVS6S3IfKRCocD+/v67s6P+5Nu1QldXF/V6ncXFRXZ2dujt7aVWqzE3N/f2TltbG4eHh1SrVaIootlskkgk6O/vZ2lp6bd+w5QkSf+fL1//5nRKSZKkfyCKImZnZ5mcnCSKori3I0mSpBZzYkqSJH1a09PTPDw8kM/n6evro1Qqxb0lSZIktZATU5IkSZIkSYqFt/JJkiRJkiQpFoYpSZIkSZIkxcIwJUmSJEmSpFgYpiRJkiRJkhQLw5QkSZIkSZJiYZiSJEmSJElSLAxTkiRJkiRJioVhSpIkSZIkSbEwTEmSJEmSJCkWhilJkiRJkiTFwjAlSZIkSZKkWHwDgQddJHSBzikAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique, counts = np.unique(qs[all_times >= b10], return_counts=True)\n",
    "\n",
    "plt.figure(figsize=(12, 6))  # Increase figure size\n",
    "plt.bar(unique, counts, color='skyblue', edgecolor='black')  # Add color and edge for clarity\n",
    "plt.xlabel('Question Number', fontsize=12)\n",
    "plt.ylabel('Number of Usable Answers', fontsize=12)\n",
    "plt.title('Usable Answers Per Question - 10th percentile', fontsize=14)\n",
    "plt.xticks(unique[::10], rotation=45, fontsize=10)  # Show every 10th tick, rotate for readability\n",
    "plt.tight_layout()  # Adjust layout to avoid clipping\n",
    "\n",
    "plt.axhline(y=10, color='red', linestyle='-', linewidth=1, label='Threshold (y=10)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904f00cf",
   "metadata": {},
   "source": [
    "# General descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec7dc33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q3\n",
       "Bachelor's degree    93\n",
       "High school          45\n",
       "Master's degree      29\n",
       "Vocational school    14\n",
       "Doctorate             9\n",
       "Other:                2\n",
       "Prefer not to say     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Education\n",
    "df[\"Q3\"].iloc[2:].value_counts()# .plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7edc73c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q1\n",
       "Male                 97\n",
       "Female               90\n",
       "Non-binary            4\n",
       "Other:                1\n",
       "Prefer not to say     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gender\n",
    "df[\"Q1\"].iloc[2:].value_counts()# .plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03d69564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    193.000000\n",
       "mean      32.176166\n",
       "std       12.278031\n",
       "min       18.000000\n",
       "25%       23.000000\n",
       "50%       28.000000\n",
       "75%       36.000000\n",
       "max       74.000000\n",
       "Name: Q2, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Age\n",
    "df[\"Q2\"].iloc[2:].dropna().apply(int).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93176d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q4\n",
       "it                     15\n",
       "education              14\n",
       "finance                10\n",
       "retail                  6\n",
       "engineering             4\n",
       "                       ..\n",
       "graphic design          1\n",
       "prefer not to say       1\n",
       "communications          1\n",
       "health and medicine     1\n",
       "events                  1\n",
       "Name: count, Length: 119, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Job type\n",
    "df[\"Q4\"].iloc[2:].str.lower().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14502fb",
   "metadata": {},
   "source": [
    "# Converting Likert to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14aba012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P70086050\\AppData\\Local\\Temp\\ipykernel_22380\\1055634327.py:18: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_co = df_co.replace({\"Strongly disagree\" : 0, \"Somewhat disagree\" : 1,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question text</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>6763fe3ad8eeb4e6d8ce1328</th>\n",
       "      <th>6769242286e30dd21cd8b084</th>\n",
       "      <th>664cd0f96e4b6f2e98b4ff03</th>\n",
       "      <th>5e020766b633b5db8b72c15b</th>\n",
       "      <th>66159ddb528ea605871b6e15</th>\n",
       "      <th>666b21f5d7612ba25e34262c</th>\n",
       "      <th>642afb016e098d3731a28cea</th>\n",
       "      <th>...</th>\n",
       "      <th>5fabca68273dd403ab40e361</th>\n",
       "      <th>677263c569e5abd57143ee7a</th>\n",
       "      <th>66a54af7261cf1fc1a5d89f3</th>\n",
       "      <th>5fdac6ef252afc58740d5560</th>\n",
       "      <th>5bcdaa50bdb0060001d4a4a8</th>\n",
       "      <th>66a40b4759c9803f4503814d</th>\n",
       "      <th>66aa826226ace74112a5a24f</th>\n",
       "      <th>614083f44ae49152b80502a1</th>\n",
       "      <th>66912a8462eaad8d5bdb34be</th>\n",
       "      <th>67894339aa346efa2532bf8d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Q1.1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q3.1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q4.1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Question text  2  3  6763fe3ad8eeb4e6d8ce1328  6769242286e30dd21cd8b084  \\\n",
       "Q1.1              2  1  1                         1                         0   \n",
       "Q2                3  3  2                         3                         4   \n",
       "Q3.1              1  1  1                         1                         0   \n",
       "Q4.1              1  1  1                         1                         0   \n",
       "Q5                1  2  3                         3                         4   \n",
       "\n",
       "      664cd0f96e4b6f2e98b4ff03  5e020766b633b5db8b72c15b  \\\n",
       "Q1.1                         1                         0   \n",
       "Q2                           3                         4   \n",
       "Q3.1                         3                         1   \n",
       "Q4.1                         0                         1   \n",
       "Q5                           2                         3   \n",
       "\n",
       "      66159ddb528ea605871b6e15  666b21f5d7612ba25e34262c  \\\n",
       "Q1.1                         1                         2   \n",
       "Q2                           2                         3   \n",
       "Q3.1                         1                         2   \n",
       "Q4.1                         0                         1   \n",
       "Q5                           2                         2   \n",
       "\n",
       "      642afb016e098d3731a28cea  ...  5fabca68273dd403ab40e361  \\\n",
       "Q1.1                         1  ...                         1   \n",
       "Q2                           3  ...                         1   \n",
       "Q3.1                         1  ...                         1   \n",
       "Q4.1                         2  ...                         0   \n",
       "Q5                           2  ...                         2   \n",
       "\n",
       "      677263c569e5abd57143ee7a  66a54af7261cf1fc1a5d89f3  \\\n",
       "Q1.1                         1                         0   \n",
       "Q2                           3                         4   \n",
       "Q3.1                         1                         0   \n",
       "Q4.1                         1                         0   \n",
       "Q5                           2                         1   \n",
       "\n",
       "      5fdac6ef252afc58740d5560  5bcdaa50bdb0060001d4a4a8  \\\n",
       "Q1.1                         1                         1   \n",
       "Q2                           4                         3   \n",
       "Q3.1                         1                         3   \n",
       "Q4.1                         1                         3   \n",
       "Q5                           3                         3   \n",
       "\n",
       "      66a40b4759c9803f4503814d  66aa826226ace74112a5a24f  \\\n",
       "Q1.1                         3                         0   \n",
       "Q2                           3                         2   \n",
       "Q3.1                         1                         0   \n",
       "Q4.1                         1                         0   \n",
       "Q5                           2                         3   \n",
       "\n",
       "      614083f44ae49152b80502a1  66912a8462eaad8d5bdb34be  \\\n",
       "Q1.1                         1                         1   \n",
       "Q2                           4                         3   \n",
       "Q3.1                         1                         3   \n",
       "Q4.1                         1                         1   \n",
       "Q5                           3                         3   \n",
       "\n",
       "      67894339aa346efa2532bf8d  \n",
       "Q1.1                         1  \n",
       "Q2                           3  \n",
       "Q3.1                         1  \n",
       "Q4.1                         2  \n",
       "Q5                           1  \n",
       "\n",
       "[5 rows x 195 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just the cognitive orientation questions per participant\n",
    "df_co = df[[\"PROLIFIC_PID\", \"Q1.1\", \"Q2 \", \"Q3.1\", \"Q4.1\", \"Q5\", \"Q6\",\n",
    "            \"Q7\", \"Q8\", \"Q9\", \"Q10\", \"Q11\", \"Q12\", \n",
    "            \"Q13\", \"Q14\", \"Q15\", \"Q16\", \"Q17\", \"Q18\", \n",
    "            \"Q19\", \"Q28\", \"Q29\", \"Q30\", \"Q31\", \"Q32\", \n",
    "            \"Q33\"]].T\n",
    "\n",
    "# Drop columns by testers\n",
    "df_co = df_co.rename(columns = {0 : \"Question text\"})\n",
    "\n",
    "# Set column names to prolific IDs\n",
    "new_headers = df_co.iloc[0, 1:].values  \n",
    "first_column_header = \"Question text\"\n",
    "df_co.columns = [first_column_header] + new_headers.tolist()\n",
    "df_co = df_co.drop(index = \"PROLIFIC_PID\")\n",
    "\n",
    "# Rescale\n",
    "df_co = df_co.replace({\"Strongly disagree\" : 0, \"Somewhat disagree\" : 1,\n",
    "                       \"Neither agree nor disagree\" : 2, \"Somewhat agree\" : 3,\n",
    "                       \"Strongly agree\" : 4})\n",
    "\n",
    "df_co.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e781454f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>6763fe3ad8eeb4e6d8ce1328</th>\n",
       "      <th>6769242286e30dd21cd8b084</th>\n",
       "      <th>664cd0f96e4b6f2e98b4ff03</th>\n",
       "      <th>5e020766b633b5db8b72c15b</th>\n",
       "      <th>66159ddb528ea605871b6e15</th>\n",
       "      <th>666b21f5d7612ba25e34262c</th>\n",
       "      <th>642afb016e098d3731a28cea</th>\n",
       "      <th>6543164e03fd084d9773d558</th>\n",
       "      <th>...</th>\n",
       "      <th>5fabca68273dd403ab40e361</th>\n",
       "      <th>677263c569e5abd57143ee7a</th>\n",
       "      <th>66a54af7261cf1fc1a5d89f3</th>\n",
       "      <th>5fdac6ef252afc58740d5560</th>\n",
       "      <th>5bcdaa50bdb0060001d4a4a8</th>\n",
       "      <th>66a40b4759c9803f4503814d</th>\n",
       "      <th>66aa826226ace74112a5a24f</th>\n",
       "      <th>614083f44ae49152b80502a1</th>\n",
       "      <th>66912a8462eaad8d5bdb34be</th>\n",
       "      <th>67894339aa346efa2532bf8d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Q1.1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q3.1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q4.1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q5</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      2  3  6763fe3ad8eeb4e6d8ce1328  6769242286e30dd21cd8b084  \\\n",
       "Q1.1  3  3                         3                         4   \n",
       "Q2    3  2                         3                         4   \n",
       "Q3.1  3  3                         3                         4   \n",
       "Q4.1  3  3                         3                         4   \n",
       "Q5    2  3                         3                         4   \n",
       "\n",
       "      664cd0f96e4b6f2e98b4ff03  5e020766b633b5db8b72c15b  \\\n",
       "Q1.1                         3                         4   \n",
       "Q2                           3                         4   \n",
       "Q3.1                         1                         3   \n",
       "Q4.1                         4                         3   \n",
       "Q5                           2                         3   \n",
       "\n",
       "      66159ddb528ea605871b6e15  666b21f5d7612ba25e34262c  \\\n",
       "Q1.1                         3                         2   \n",
       "Q2                           2                         3   \n",
       "Q3.1                         3                         2   \n",
       "Q4.1                         4                         3   \n",
       "Q5                           2                         2   \n",
       "\n",
       "      642afb016e098d3731a28cea  6543164e03fd084d9773d558  ...  \\\n",
       "Q1.1                         3                         3  ...   \n",
       "Q2                           3                         4  ...   \n",
       "Q3.1                         3                         1  ...   \n",
       "Q4.1                         2                         3  ...   \n",
       "Q5                           2                         3  ...   \n",
       "\n",
       "      5fabca68273dd403ab40e361  677263c569e5abd57143ee7a  \\\n",
       "Q1.1                         3                         3   \n",
       "Q2                           1                         3   \n",
       "Q3.1                         3                         3   \n",
       "Q4.1                         4                         3   \n",
       "Q5                           2                         2   \n",
       "\n",
       "      66a54af7261cf1fc1a5d89f3  5fdac6ef252afc58740d5560  \\\n",
       "Q1.1                         4                         3   \n",
       "Q2                           4                         4   \n",
       "Q3.1                         4                         3   \n",
       "Q4.1                         4                         3   \n",
       "Q5                           1                         3   \n",
       "\n",
       "      5bcdaa50bdb0060001d4a4a8  66a40b4759c9803f4503814d  \\\n",
       "Q1.1                         3                         1   \n",
       "Q2                           3                         3   \n",
       "Q3.1                         1                         3   \n",
       "Q4.1                         1                         3   \n",
       "Q5                           3                         2   \n",
       "\n",
       "      66aa826226ace74112a5a24f  614083f44ae49152b80502a1  \\\n",
       "Q1.1                         4                         3   \n",
       "Q2                           2                         4   \n",
       "Q3.1                         4                         3   \n",
       "Q4.1                         4                         3   \n",
       "Q5                           3                         3   \n",
       "\n",
       "      66912a8462eaad8d5bdb34be  67894339aa346efa2532bf8d  \n",
       "Q1.1                         3                         3  \n",
       "Q2                           3                         3  \n",
       "Q3.1                         1                         3  \n",
       "Q4.1                         3                         2  \n",
       "Q5                           3                         1  \n",
       "\n",
       "[5 rows x 194 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_groups = {\"Need for Cognition\" : {\n",
    "               \"Q1.1\" : {\"Reverse\" : True},\n",
    "               \"Q2 \"  : {\"Reverse\" : False},\n",
    "               \"Q3.1\" : {\"Reverse\" : True},\n",
    "               \"Q4.1\" : {\"Reverse\" : True},\n",
    "               \"Q5\"   : {\"Reverse\" : False}\n",
    "               },\n",
    "            \"Need for closure\" : {\n",
    "               \"Q6\"  : {\"Reverse\" : False},\n",
    "               \"Q7\"  : {\"Reverse\" : True},\n",
    "               \"Q8\"  : {\"Reverse\" : True},\n",
    "               \"Q9\"  : {\"Reverse\" : False}, \n",
    "               \"Q10\" : {\"Reverse\" : False},\n",
    "               \"Q11\" : {\"Reverse\" : False},\n",
    "               \"Q12\" : {\"Reverse\" : False}\n",
    "            },\n",
    "            \"Susceptibility to persuasion\" : {\n",
    "                \"Q13\" : {\"Reverse\" : False},\n",
    "                \"Q14\" : {\"Reverse\" : False},\n",
    "                \"Q15\" : {\"Reverse\" : False},\n",
    "                \"Q16\" : {\"Reverse\" : False}\n",
    "            },\n",
    "            \"Skepticism\" : {\n",
    "                \"Q17\" : {\"Reverse\" : False},\n",
    "                \"Q18\" : {\"Reverse\" : True},\n",
    "                \"Q19\" : {\"Reverse\" : False},\n",
    "                \"Q28\" : {\"Reverse\" : False},\n",
    "                \"Q29\" : {\"Reverse\" : False}\n",
    "            },\n",
    "            \"AI Expertise\" : {\n",
    "                \"Q30\" : {\"Reverse\" : False},\n",
    "                \"Q31\" : {\"Reverse\" : False},\n",
    "                \"Q32\" : {\"Reverse\" : False},\n",
    "                \"Q33\" : {\"Reverse\" : True}\n",
    "            }\n",
    "        }\n",
    "\n",
    "sub_dfs = {}\n",
    "\n",
    "for group, questions in co_groups.items():\n",
    "    temp = df_co.loc[list(questions.keys())]\n",
    "    \n",
    "    for question, reverse in questions.items():\n",
    "        if reverse[\"Reverse\"]:    \n",
    "            temp.loc[question] = temp.loc[question].replace({4:0, 3:1, 1:3, 0:4})\n",
    "            \n",
    "    temp = temp.drop(columns = \"Question text\")\n",
    "    \n",
    "    sub_dfs[group] = temp\n",
    "    \n",
    "sub_dfs[\"Need for Cognition\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b3f5ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scaled = pd.concat(list(sub_dfs.values()))\n",
    "\n",
    "# Drop incomplete responses\n",
    "all_scaled = all_scaled.drop(columns=all_scaled.columns[all_scaled.isna().sum() > 0]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f91327",
   "metadata": {},
   "source": [
    "# Confirmatory Factor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c9619db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping: Q9\n",
      "Dropping: Q10\n",
      "Dropping: Q12\n",
      "Dropping: Q18\n"
     ]
    }
   ],
   "source": [
    "co_groups_updated = defaultdict(dict)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "to_drop = []\n",
    "\n",
    "for group, questions in co_groups.items():\n",
    "    for question in questions:\n",
    "        if question not in [\"Q9\", \"Q10\", \"Q12\", \"Q18\"]:\n",
    "            \n",
    "            co_groups_updated[group][question] = co_groups[group][question]\n",
    "        \n",
    "        else:\n",
    "            print(f\"Dropping: {question}\")\n",
    "            to_drop.append(question)\n",
    "\n",
    "        counter += 1\n",
    "        \n",
    "co_groups = co_groups_updated\n",
    "all_scaled_corrected = all_scaled.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325ac8bf",
   "metadata": {},
   "source": [
    "# Calculating concept scores per participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c094db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Need for Cognition</th>\n",
       "      <th>Need for closure</th>\n",
       "      <th>Susceptibility to persuasion</th>\n",
       "      <th>Skepticism</th>\n",
       "      <th>AI Expertise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.678866</td>\n",
       "      <td>0.489691</td>\n",
       "      <td>0.658183</td>\n",
       "      <td>0.768041</td>\n",
       "      <td>0.641108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.155359</td>\n",
       "      <td>0.148033</td>\n",
       "      <td>0.151118</td>\n",
       "      <td>0.139380</td>\n",
       "      <td>0.150231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Need for Cognition  Need for closure  Susceptibility to persuasion  \\\n",
       "count          194.000000        194.000000                    194.000000   \n",
       "mean             0.678866          0.489691                      0.658183   \n",
       "std              0.155359          0.148033                      0.151118   \n",
       "min              0.200000          0.187500                      0.187500   \n",
       "25%              0.600000          0.375000                      0.562500   \n",
       "50%              0.700000          0.500000                      0.687500   \n",
       "75%              0.800000          0.562500                      0.750000   \n",
       "max              1.000000          0.875000                      1.000000   \n",
       "\n",
       "       Skepticism  AI Expertise  \n",
       "count  194.000000    194.000000  \n",
       "mean     0.768041      0.641108  \n",
       "std      0.139380      0.150231  \n",
       "min      0.375000      0.187500  \n",
       "25%      0.687500      0.562500  \n",
       "50%      0.750000      0.625000  \n",
       "75%      0.875000      0.750000  \n",
       "max      1.000000      1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate average scores for each concept\n",
    "concept_scores = pd.DataFrame()\n",
    "\n",
    "for concept, questions in co_groups.items():\n",
    "    concept_scores[concept] = all_scaled[list(questions.keys())].sum(axis=1) / (len(questions.keys()) * 4)\n",
    "\n",
    "# Output results\n",
    "concept_scores.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7569a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need for Cognition: ShapiroResult(statistic=0.9738554954528809, pvalue=0.0010849536629393697)\n",
      "Need for closure: ShapiroResult(statistic=0.9730498194694519, pvalue=0.0008573472150601447)\n",
      "Susceptibility to persuasion: ShapiroResult(statistic=0.978583574295044, pvalue=0.004558098968118429)\n",
      "Skepticism: ShapiroResult(statistic=0.9627742171287537, pvalue=5.272109410725534e-05)\n",
      "AI Expertise: ShapiroResult(statistic=0.9790768027305603, pvalue=0.005322488024830818)\n"
     ]
    }
   ],
   "source": [
    "for col in concept_scores.columns:\n",
    "    print(f\"{col}: {shapiro(concept_scores[col])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafb5451",
   "metadata": {},
   "source": [
    "# Data restructuring (evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10cc4613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P70086050\\AppData\\Local\\Temp\\ipykernel_22380\\2315859127.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_data.loc[index, f\"{lookup[submit]}_1\"] = np.nan\n",
      "C:\\Users\\P70086050\\AppData\\Local\\Temp\\ipykernel_22380\\2315859127.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_data.loc[index, f\"{lookup[submit]}_2\"] = np.nan\n",
      "C:\\Users\\P70086050\\AppData\\Local\\Temp\\ipykernel_22380\\2315859127.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_data.loc[index, f\"{lookup[submit]}_3\"] = np.nan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>PROLIFIC_PID</th>\n",
       "      <th>Q365_Page Submit</th>\n",
       "      <th>Q366_Page Submit</th>\n",
       "      <th>Q13_Page Submit</th>\n",
       "      <th>Q12_Page Submit</th>\n",
       "      <th>Q367_Page Submit</th>\n",
       "      <th>000000v000001_1</th>\n",
       "      <th>000000v000001_2</th>\n",
       "      <th>000000v000001_3</th>\n",
       "      <th>...</th>\n",
       "      <th>Q359_Page Submit</th>\n",
       "      <th>111101v111111_1</th>\n",
       "      <th>111101v111111_2</th>\n",
       "      <th>111101v111111_3</th>\n",
       "      <th>Q360_Page Submit</th>\n",
       "      <th>111110v111111_1</th>\n",
       "      <th>111110v111111_2</th>\n",
       "      <th>111110v111111_3</th>\n",
       "      <th>Q361_Page Submit</th>\n",
       "      <th>Q364_Page Submit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R_8xyWYB0rOpyjRuh</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.001</td>\n",
       "      <td>164.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R_2il5McbOGb6rpVr</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.927</td>\n",
       "      <td>167.271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>R_22VcLcH0ym5Ms3q</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.13</td>\n",
       "      <td>267.371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>R_1X0xxCGkUFlxJvb</td>\n",
       "      <td>6763fe3ad8eeb4e6d8ce1328</td>\n",
       "      <td>5.261</td>\n",
       "      <td>12.569</td>\n",
       "      <td>31.203</td>\n",
       "      <td>185.401</td>\n",
       "      <td>48.491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>R_2H4FtKSPleDaGQN</td>\n",
       "      <td>6769242286e30dd21cd8b084</td>\n",
       "      <td>8.487</td>\n",
       "      <td>8.507</td>\n",
       "      <td>21.31</td>\n",
       "      <td>139.86</td>\n",
       "      <td>2.935</td>\n",
       "      <td>Explanation A</td>\n",
       "      <td>Explanation A</td>\n",
       "      <td>Explanation A</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>R_6gM7yHAEAGkg8Jp</td>\n",
       "      <td>66a40b4759c9803f4503814d</td>\n",
       "      <td>76.362</td>\n",
       "      <td>184.297</td>\n",
       "      <td>25.947</td>\n",
       "      <td>408.504</td>\n",
       "      <td>8.183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>R_31uDLOfF6kZnEjU</td>\n",
       "      <td>66aa826226ace74112a5a24f</td>\n",
       "      <td>215.947</td>\n",
       "      <td>24.307</td>\n",
       "      <td>34.067</td>\n",
       "      <td>613.889</td>\n",
       "      <td>15.901</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>R_8fj8nHaeCCkqzur</td>\n",
       "      <td>614083f44ae49152b80502a1</td>\n",
       "      <td>12.062</td>\n",
       "      <td>45.483</td>\n",
       "      <td>90.449</td>\n",
       "      <td>348.496</td>\n",
       "      <td>323.313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>R_8Isk5Z1waUdsZWx</td>\n",
       "      <td>66912a8462eaad8d5bdb34be</td>\n",
       "      <td>22.501</td>\n",
       "      <td>12.766</td>\n",
       "      <td>17.1</td>\n",
       "      <td>183.614</td>\n",
       "      <td>9.295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>R_2LtUNNyDFtLX624</td>\n",
       "      <td>67894339aa346efa2532bf8d</td>\n",
       "      <td>2.614</td>\n",
       "      <td>8.401</td>\n",
       "      <td>12.092</td>\n",
       "      <td>179.878</td>\n",
       "      <td>41.177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows  648 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ResponseId              PROLIFIC_PID Q365_Page Submit  \\\n",
       "3    R_8xyWYB0rOpyjRuh                         1              NaN   \n",
       "4    R_2il5McbOGb6rpVr                         2              NaN   \n",
       "5    R_22VcLcH0ym5Ms3q                         3              NaN   \n",
       "6    R_1X0xxCGkUFlxJvb  6763fe3ad8eeb4e6d8ce1328            5.261   \n",
       "7    R_2H4FtKSPleDaGQN  6769242286e30dd21cd8b084            8.487   \n",
       "..                 ...                       ...              ...   \n",
       "197  R_6gM7yHAEAGkg8Jp  66a40b4759c9803f4503814d           76.362   \n",
       "198  R_31uDLOfF6kZnEjU  66aa826226ace74112a5a24f          215.947   \n",
       "199  R_8fj8nHaeCCkqzur  614083f44ae49152b80502a1           12.062   \n",
       "202  R_8Isk5Z1waUdsZWx  66912a8462eaad8d5bdb34be           22.501   \n",
       "203  R_2LtUNNyDFtLX624  67894339aa346efa2532bf8d            2.614   \n",
       "\n",
       "    Q366_Page Submit Q13_Page Submit Q12_Page Submit Q367_Page Submit  \\\n",
       "3                NaN          19.001           164.1              NaN   \n",
       "4                NaN          14.927         167.271              NaN   \n",
       "5                NaN           40.13         267.371              NaN   \n",
       "6             12.569          31.203         185.401           48.491   \n",
       "7              8.507           21.31          139.86            2.935   \n",
       "..               ...             ...             ...              ...   \n",
       "197          184.297          25.947         408.504            8.183   \n",
       "198           24.307          34.067         613.889           15.901   \n",
       "199           45.483          90.449         348.496          323.313   \n",
       "202           12.766            17.1         183.614            9.295   \n",
       "203            8.401          12.092         179.878           41.177   \n",
       "\n",
       "    000000v000001_1 000000v000001_2 000000v000001_3  ... Q359_Page Submit  \\\n",
       "3               NaN             NaN             NaN  ...              NaN   \n",
       "4               NaN             NaN             NaN  ...              NaN   \n",
       "5               NaN             NaN             NaN  ...              NaN   \n",
       "6               NaN             NaN             NaN  ...              NaN   \n",
       "7     Explanation A   Explanation A   Explanation A  ...              NaN   \n",
       "..              ...             ...             ...  ...              ...   \n",
       "197             NaN             NaN             NaN  ...              NaN   \n",
       "198             NaN             NaN             NaN  ...              NaN   \n",
       "199             NaN             NaN             NaN  ...              NaN   \n",
       "202             NaN             NaN             NaN  ...              NaN   \n",
       "203             NaN             NaN             NaN  ...              NaN   \n",
       "\n",
       "    111101v111111_1 111101v111111_2 111101v111111_3 Q360_Page Submit  \\\n",
       "3               NaN             NaN             NaN              NaN   \n",
       "4               NaN             NaN             NaN              NaN   \n",
       "5               NaN             NaN             NaN              NaN   \n",
       "6               NaN             NaN             NaN              NaN   \n",
       "7               NaN             NaN             NaN              NaN   \n",
       "..              ...             ...             ...              ...   \n",
       "197             NaN             NaN             NaN              NaN   \n",
       "198             NaN             NaN             NaN              NaN   \n",
       "199             NaN             NaN             NaN              NaN   \n",
       "202             NaN             NaN             NaN              NaN   \n",
       "203             NaN             NaN             NaN              NaN   \n",
       "\n",
       "    111110v111111_1 111110v111111_2 111110v111111_3 Q361_Page Submit  \\\n",
       "3               NaN             NaN             NaN              NaN   \n",
       "4               NaN             NaN             NaN              NaN   \n",
       "5               NaN             NaN             NaN              NaN   \n",
       "6               NaN             NaN             NaN              NaN   \n",
       "7               NaN             NaN             NaN              NaN   \n",
       "..              ...             ...             ...              ...   \n",
       "197             NaN             NaN             NaN              NaN   \n",
       "198             NaN             NaN             NaN              NaN   \n",
       "199             NaN             NaN             NaN              NaN   \n",
       "202             NaN             NaN             NaN              NaN   \n",
       "203             NaN             NaN             NaN              NaN   \n",
       "\n",
       "    Q364_Page Submit  \n",
       "3             13.837  \n",
       "4              4.869  \n",
       "5              4.816  \n",
       "6               6.23  \n",
       "7              4.428  \n",
       "..               ...  \n",
       "197             6.47  \n",
       "198             2.85  \n",
       "199            6.847  \n",
       "202           13.641  \n",
       "203           56.714  \n",
       "\n",
       "[195 rows x 648 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for columns related to explanation pair evaluations and participant-level identifiers\n",
    "pair_columns = [col for col in df.columns if (\"v\" in str(col)) or (\"Page Submit\" in str(col))]\n",
    "participant_columns = ['ResponseId', 'PROLIFIC_PID']\n",
    "subset_data = df[participant_columns + pair_columns]\n",
    "\n",
    "# Find submit times of all questions\n",
    "submits = sorted([i for i in pair_columns if re.match(\"Q\\\\d{3}_Page Submit\", i)])[:-4]\n",
    "qs = sorted(list(set([i[:-2] for i in pair_columns if re.match(\"\\\\d{6}v\\\\d{6}_\\\\d\", i)])))\n",
    "\n",
    "lookup = dict(zip(submits, qs))\n",
    "\n",
    "# Actually remove any evaluations that took less than b10 from the dataset\n",
    "for row in subset_data.iterrows():\n",
    "\n",
    "    index, row = row\n",
    "    \n",
    "    for submit in submits:\n",
    "        if float(row[submit]) < b10:\n",
    "            subset_data.loc[index, f\"{lookup[submit]}_1\"] = np.nan\n",
    "            subset_data.loc[index, f\"{lookup[submit]}_2\"] = np.nan\n",
    "            subset_data.loc[index, f\"{lookup[submit]}_3\"] = np.nan\n",
    "\n",
    "subset_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dff6c8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>PROLIFIC_PID</th>\n",
       "      <th>Evaluation</th>\n",
       "      <th>ExplanationPair</th>\n",
       "      <th>MetricType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6435</th>\n",
       "      <td>R_8xyWYB0rOpyjRuh</td>\n",
       "      <td>1</td>\n",
       "      <td>Explanation B</td>\n",
       "      <td>000001v001001</td>\n",
       "      <td>Trustworthiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6630</th>\n",
       "      <td>R_8xyWYB0rOpyjRuh</td>\n",
       "      <td>1</td>\n",
       "      <td>Explanation B</td>\n",
       "      <td>000001v001001</td>\n",
       "      <td>Transparency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6825</th>\n",
       "      <td>R_8xyWYB0rOpyjRuh</td>\n",
       "      <td>1</td>\n",
       "      <td>Explanation B</td>\n",
       "      <td>000001v001001</td>\n",
       "      <td>Usefulness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9555</th>\n",
       "      <td>R_8xyWYB0rOpyjRuh</td>\n",
       "      <td>1</td>\n",
       "      <td>Explanation A</td>\n",
       "      <td>000010v001010</td>\n",
       "      <td>Trustworthiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9750</th>\n",
       "      <td>R_8xyWYB0rOpyjRuh</td>\n",
       "      <td>1</td>\n",
       "      <td>Explanation B</td>\n",
       "      <td>000010v001010</td>\n",
       "      <td>Transparency</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ResponseId PROLIFIC_PID     Evaluation ExplanationPair  \\\n",
       "6435  R_8xyWYB0rOpyjRuh            1  Explanation B   000001v001001   \n",
       "6630  R_8xyWYB0rOpyjRuh            1  Explanation B   000001v001001   \n",
       "6825  R_8xyWYB0rOpyjRuh            1  Explanation B   000001v001001   \n",
       "9555  R_8xyWYB0rOpyjRuh            1  Explanation A   000010v001010   \n",
       "9750  R_8xyWYB0rOpyjRuh            1  Explanation B   000010v001010   \n",
       "\n",
       "           MetricType  \n",
       "6435  Trustworthiness  \n",
       "6630     Transparency  \n",
       "6825       Usefulness  \n",
       "9555  Trustworthiness  \n",
       "9750     Transparency  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape the explanation pair data into long format\n",
    "\n",
    "# Melt explanation pair columns to create a long-format dataframe\n",
    "\n",
    "long_data = pd.melt(\n",
    "    subset_data,\n",
    "    id_vars=participant_columns,  # Keep participant identifiers\n",
    "    value_vars=pair_columns,  # Explanation pair columns\n",
    "    var_name=\"ExplanationPair_Metric\",  # New column for explanation pair + metric\n",
    "    value_name=\"Evaluation\"  # Column for evaluation (trust, transparency, usefulness)\n",
    ")\n",
    "\n",
    "# Split ExplanationPair_Metric into ExplanationPair and MetricType\n",
    "long_data[['ExplanationPair', 'MetricType']] = long_data['ExplanationPair_Metric'].str.extract(r'(.*)_([1-3])')\n",
    "\n",
    "# Map MetricType to human-readable labels\n",
    "metric_map = {\n",
    "    \"1\": \"Trustworthiness\",\n",
    "    \"2\": \"Transparency\",\n",
    "    \"3\": \"Usefulness\"\n",
    "}\n",
    "\n",
    "long_data['MetricType'] = long_data['MetricType'].map(metric_map)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "long_data = long_data.drop(columns = [\"ExplanationPair_Metric\"])\n",
    "long_data = long_data.dropna(subset = [\"Evaluation\", \"ExplanationPair\"])\n",
    "\n",
    "# Display a sample of the reshaped data\n",
    "long_data.sort_values(by=[\"PROLIFIC_PID\", \"ExplanationPair\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b493aa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_values(pair):\n",
    "    \"\"\"\n",
    "    The bits used to represent the explanations are counterintuitive for\n",
    "    Persuasion, Detail, and Formality. Hence, we flip them. As a result, the coding is:\n",
    "    bit 0: 0 = low-stakes,       1 = high-stakes\n",
    "    bit 1: 0 = short,            1 = long\n",
    "    bit 2: 0 = running,          1 = bulleted\n",
    "    bit 3: 0 = informal,         1 = formal\n",
    "    bit 4: 0 = aggregated,       1 = comprehensive\n",
    "    bit 5: 0 = decision-support, 1 = persuasive\n",
    "    \"\"\"\n",
    "    \n",
    "    pair = list(pair)\n",
    "    pair[3], pair[10] = \"0\" if int(pair[3]) else \"1\", \"0\" if int(pair[10]) else \"1\"\n",
    "    pair[4], pair[11] = \"0\" if int(pair[4]) else \"1\", \"0\" if int(pair[11]) else \"1\"\n",
    "    pair[5], pair[12] = \"0\" if int(pair[5]) else \"1\", \"0\" if int(pair[12]) else \"1\"\n",
    " \n",
    "    \n",
    "    return \"\".join(pair)\n",
    "    \n",
    "long_data[\"ExplanationPair\"] = long_data[\"ExplanationPair\"].apply(flip_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "357e533a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_parser(explanation_pair):\n",
    "    \"\"\"\n",
    "    Converts the string-like representation of the explanation pair\n",
    "    to a categorical variable indicating which of the design dimensions\n",
    "    has been 'flipped' between the two explanations. In this flip, explanation\n",
    "    B always has a 1 ('higher' value) and explanation A a 0 ('lower' value)\n",
    "    \"\"\"\n",
    "    \n",
    "    explanation_a, explanation_b = explanation_pair.split(\"v\")\n",
    "    feature_names = [\"Domain\", \"Length\", \"Structure\", \"Formality\", \"Detail\", \"Persuasiveness\"]\n",
    "    \n",
    "    features_a = {f\"{feature}\": int(bit) for feature, bit in zip(feature_names, explanation_a)}\n",
    "    features_b = {f\"{feature}\": int(bit) for feature, bit in zip(feature_names, explanation_b)}       \n",
    "\n",
    "    return {\"Domain\": \"high\" if features_a[\"Domain\"] else \"low\", \n",
    "            \"flipped_dim\": feature_names[np.argmax([features_a[feature] != features_b[feature] \n",
    "                                         for feature in feature_names])]}\n",
    "        \n",
    "# Apply the function to the ExplanationPair column and expand the result into new columns\n",
    "binary_features = long_data['ExplanationPair'].map(pair_parser).apply(pd.Series)\n",
    "\n",
    "# Concatenate the binary features back into the main dataframe\n",
    "long_data = pd.concat([long_data, binary_features], axis=1)\n",
    "\n",
    "# Drop any unnecessary intermediate columns\n",
    "long_data = long_data.drop(columns=[\"ResponseId\", \"Features_A\", \"Features_B\"],\n",
    "                           errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f41945a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Need for Cognition</th>\n",
       "      <th>Need for closure</th>\n",
       "      <th>Susceptibility to persuasion</th>\n",
       "      <th>Skepticism</th>\n",
       "      <th>AI Expertise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6763fe3ad8eeb4e6d8ce1328</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6769242286e30dd21cd8b084</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664cd0f96e4b6f2e98b4ff03</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.5625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Need for Cognition  Need for closure  \\\n",
       "2                                       0.70            0.3750   \n",
       "3                                       0.70            0.2500   \n",
       "6763fe3ad8eeb4e6d8ce1328                0.75            0.7500   \n",
       "6769242286e30dd21cd8b084                1.00            0.7500   \n",
       "664cd0f96e4b6f2e98b4ff03                0.65            0.5625   \n",
       "\n",
       "                          Susceptibility to persuasion  Skepticism  \\\n",
       "2                                               0.6875      0.5625   \n",
       "3                                               0.5000      0.7500   \n",
       "6763fe3ad8eeb4e6d8ce1328                        0.5625      0.5625   \n",
       "6769242286e30dd21cd8b084                        1.0000      1.0000   \n",
       "664cd0f96e4b6f2e98b4ff03                        0.3750      0.6875   \n",
       "\n",
       "                          AI Expertise  \n",
       "2                               0.8750  \n",
       "3                               0.5000  \n",
       "6763fe3ad8eeb4e6d8ce1328        0.8750  \n",
       "6769242286e30dd21cd8b084        0.7500  \n",
       "664cd0f96e4b6f2e98b4ff03        0.5625  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55c8513a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P70086050\\AppData\\Local\\Temp\\ipykernel_22380\\2604196631.py:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  final_data[\"Evaluation\"] = final_data[\"Evaluation\"].replace({\"Explanation A\": 0, \"Explanation B\": 1}).dropna()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROLIFIC_PID</th>\n",
       "      <th>ExplanationPair</th>\n",
       "      <th>Need for Cognition</th>\n",
       "      <th>Need for closure</th>\n",
       "      <th>Susceptibility to persuasion</th>\n",
       "      <th>Skepticism</th>\n",
       "      <th>AI Expertise</th>\n",
       "      <th>Domain</th>\n",
       "      <th>flipped_dim</th>\n",
       "      <th>MetricType</th>\n",
       "      <th>Evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15015</th>\n",
       "      <td>1</td>\n",
       "      <td>000011v001011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>low</td>\n",
       "      <td>Structure</td>\n",
       "      <td>Trustworthiness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15210</th>\n",
       "      <td>1</td>\n",
       "      <td>000011v001011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>low</td>\n",
       "      <td>Structure</td>\n",
       "      <td>Transparency</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15405</th>\n",
       "      <td>1</td>\n",
       "      <td>000011v001011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>low</td>\n",
       "      <td>Structure</td>\n",
       "      <td>Usefulness</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9555</th>\n",
       "      <td>1</td>\n",
       "      <td>000101v001101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>low</td>\n",
       "      <td>Structure</td>\n",
       "      <td>Trustworthiness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9750</th>\n",
       "      <td>1</td>\n",
       "      <td>000101v001101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>low</td>\n",
       "      <td>Structure</td>\n",
       "      <td>Transparency</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PROLIFIC_PID ExplanationPair  Need for Cognition  Need for closure  \\\n",
       "15015            1   000011v001011                 NaN               NaN   \n",
       "15210            1   000011v001011                 NaN               NaN   \n",
       "15405            1   000011v001011                 NaN               NaN   \n",
       "9555             1   000101v001101                 NaN               NaN   \n",
       "9750             1   000101v001101                 NaN               NaN   \n",
       "\n",
       "       Susceptibility to persuasion  Skepticism  AI Expertise Domain  \\\n",
       "15015                           NaN         NaN           NaN    low   \n",
       "15210                           NaN         NaN           NaN    low   \n",
       "15405                           NaN         NaN           NaN    low   \n",
       "9555                            NaN         NaN           NaN    low   \n",
       "9750                            NaN         NaN           NaN    low   \n",
       "\n",
       "      flipped_dim       MetricType  Evaluation  \n",
       "15015   Structure  Trustworthiness           0  \n",
       "15210   Structure     Transparency           1  \n",
       "15405   Structure       Usefulness           1  \n",
       "9555    Structure  Trustworthiness           0  \n",
       "9750    Structure     Transparency           1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Include flipped_dim and domain as a column\n",
    "cols = [\"PROLIFIC_PID\", \"ExplanationPair\", \"Need for Cognition\",\n",
    "        \"Need for closure\", \"Susceptibility to persuasion\",\n",
    "        \"Skepticism\", \"AI Expertise\", \"Domain\", \"flipped_dim\", \n",
    "        \"MetricType\", \"Evaluation\"]\n",
    "    \n",
    "# Merge evaluations with cognitive orientations and restructure\n",
    "final_data = long_data.join(concept_scores, \n",
    "                            on=\"PROLIFIC_PID\", \n",
    "                            how=\"left\").sort_values(\n",
    "    by=[\"PROLIFIC_PID\", \"ExplanationPair\"]\n",
    ")[cols]\n",
    "\n",
    "final_data[\"Evaluation\"] = final_data[\"Evaluation\"].replace({\"Explanation A\": 0, \"Explanation B\": 1})\n",
    "\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09b6d79e-668f-4d66-bc88-480c5fcdd055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROLIFIC_PID</th>\n",
       "      <th>ExplanationPair</th>\n",
       "      <th>Need for Cognition</th>\n",
       "      <th>Need for closure</th>\n",
       "      <th>Susceptibility to persuasion</th>\n",
       "      <th>Skepticism</th>\n",
       "      <th>AI Expertise</th>\n",
       "      <th>Domain</th>\n",
       "      <th>flipped_dim</th>\n",
       "      <th>MetricType</th>\n",
       "      <th>Evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15015</th>\n",
       "      <td>1</td>\n",
       "      <td>000011v001011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>low</td>\n",
       "      <td>Structure</td>\n",
       "      <td>Trustworthiness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15210</th>\n",
       "      <td>1</td>\n",
       "      <td>000011v001011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>low</td>\n",
       "      <td>Structure</td>\n",
       "      <td>Transparency</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15405</th>\n",
       "      <td>1</td>\n",
       "      <td>000011v001011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>low</td>\n",
       "      <td>Structure</td>\n",
       "      <td>Usefulness</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9555</th>\n",
       "      <td>1</td>\n",
       "      <td>000101v001101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>low</td>\n",
       "      <td>Structure</td>\n",
       "      <td>Trustworthiness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9750</th>\n",
       "      <td>1</td>\n",
       "      <td>000101v001101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>low</td>\n",
       "      <td>Structure</td>\n",
       "      <td>Transparency</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PROLIFIC_PID ExplanationPair  Need for Cognition  Need for closure  \\\n",
       "15015            1   000011v001011                 NaN               NaN   \n",
       "15210            1   000011v001011                 NaN               NaN   \n",
       "15405            1   000011v001011                 NaN               NaN   \n",
       "9555             1   000101v001101                 NaN               NaN   \n",
       "9750             1   000101v001101                 NaN               NaN   \n",
       "\n",
       "       Susceptibility to persuasion  Skepticism  AI Expertise Domain  \\\n",
       "15015                           NaN         NaN           NaN    low   \n",
       "15210                           NaN         NaN           NaN    low   \n",
       "15405                           NaN         NaN           NaN    low   \n",
       "9555                            NaN         NaN           NaN    low   \n",
       "9750                            NaN         NaN           NaN    low   \n",
       "\n",
       "      flipped_dim       MetricType  Evaluation  \n",
       "15015   Structure  Trustworthiness           0  \n",
       "15210   Structure     Transparency           1  \n",
       "15405   Structure       Usefulness           1  \n",
       "9555    Structure  Trustworthiness           0  \n",
       "9750    Structure     Transparency           1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decision_flipper(row):\n",
    "    \"\"\"\n",
    "    Since we flipped three dimensions, their direction in terms of evaluation\n",
    "    has also been flipped (i.e., explanation A (baseline) has \"become\" explanation B (treatment)\n",
    "    since that one now has the 1 instead of the 0. As a result, we also have to flip the order of the \n",
    "    explanations and the evaluation for it, so that a 1 again indicates a preference for the treatment. \n",
    "    \"\"\"\n",
    "\n",
    "    split = row[\"ExplanationPair\"].split(\"v\")\n",
    "    reversed_order = f\"{split[1]}v{split[0]}\"\n",
    "    \n",
    "    if row[\"flipped_dim\"] in [\"Formality\", \"Detail\", \"Persuasiveness\"]:\n",
    "        return 0 if row[\"Evaluation\"] else 1, reversed_order \n",
    "    else:\n",
    "        return row[\"Evaluation\"], row[\"ExplanationPair\"]\n",
    "\n",
    "# Apply flipper\n",
    "for row in final_data.iterrows():\n",
    "    fixed_eval, fixed_explanation = decision_flipper(row[1])\n",
    "    \n",
    "    final_data.loc[row[0], \"Evaluation\"] = fixed_eval\n",
    "    final_data.loc[row[0], \"ExplanationPair\"] = fixed_explanation\n",
    "\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23413378",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec07d50",
   "metadata": {},
   "source": [
    "# Calculate polychoric correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6430a968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store correlation dataset as csv\n",
    "correlation_df = final_data[[\"PROLIFIC_PID\", \n",
    "                             \"MetricType\", \n",
    "                             \"Evaluation\",\n",
    "                             \"ExplanationPair\"]].pivot(\n",
    "                     columns=\"MetricType\", \n",
    "                     values=\"Evaluation\",\n",
    "                     index=[\"PROLIFIC_PID\", \"ExplanationPair\"]\n",
    "                 )\n",
    "\n",
    "correlation_df.to_csv(\"../results/correlation_df_jobs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff42e15c-0f2f-4da5-a405-f785dec017b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(polycor)\n",
    "\n",
    "data <- read.csv(\"correlation_df.csv\")\n",
    "\n",
    "calculate_p <- function(corr) {\n",
    "  rho = corr$rho\n",
    "  SE = sqrt(corr$var)\n",
    "  z <- rho / SE\n",
    "  p = 2 * (1 - pnorm(abs(z)))\n",
    "  return(as.numeric(p))\n",
    "}\n",
    "\n",
    "corr_use_trans = polychor(data$Usefulness, data$Transparency, std.err=TRUE)\n",
    "p_use_trans = calculate_p(corr_use_trans)\n",
    "\n",
    "corr_use_trust = polychor(data$Usefulness, data$Trustworthiness, std.err=TRUE)\n",
    "p_use_trust = calculate_p(corr_use_trust)\n",
    "\n",
    "corr_trust_trans = polychor(data$Trustworthiness, data$Transparency, std.err=TRUE)\n",
    "p_trust_trans = calculate_p(corr_trust_trans)\n",
    "\n",
    "print(corr_use_trans$rho)\n",
    "print(p_use_trans)\n",
    "print(corr_use_trust$rho)\n",
    "print(p_use_trust)\n",
    "print(corr_trust_trans$rho)\n",
    "print(p_trust_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b28cfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data.reset_index().drop(columns=\"index\")\n",
    "final_data.columns = [i.replace(\" \", \"_\") for i in final_data.columns]\n",
    "final_data = final_data.dropna()\n",
    "\n",
    "# Calculate share of evaluations where all metrics aligned\n",
    "decisions = final_data.groupby([\"PROLIFIC_PID\", \"ExplanationPair\"])[\"Evaluation\"].sum().values\n",
    "np.isin(decisions, [0, 3]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4117e4b0-2b23-4a8c-b9ec-03f08c4ed000",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a476c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROLIFIC_PID</th>\n",
       "      <th>ExplanationPair</th>\n",
       "      <th>Need_for_Cognition</th>\n",
       "      <th>Need_for_closure</th>\n",
       "      <th>Susceptibility_to_persuasion</th>\n",
       "      <th>Skepticism</th>\n",
       "      <th>AI_Expertise</th>\n",
       "      <th>Domain</th>\n",
       "      <th>flipped_dim</th>\n",
       "      <th>MetricType</th>\n",
       "      <th>Evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16576</th>\n",
       "      <td>2</td>\n",
       "      <td>000000v000010</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.875</td>\n",
       "      <td>low</td>\n",
       "      <td>Detail</td>\n",
       "      <td>Trustworthiness</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16771</th>\n",
       "      <td>2</td>\n",
       "      <td>000000v000010</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.875</td>\n",
       "      <td>low</td>\n",
       "      <td>Detail</td>\n",
       "      <td>Transparency</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16966</th>\n",
       "      <td>2</td>\n",
       "      <td>000000v000010</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.875</td>\n",
       "      <td>low</td>\n",
       "      <td>Detail</td>\n",
       "      <td>Usefulness</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11116</th>\n",
       "      <td>2</td>\n",
       "      <td>000000v000100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.875</td>\n",
       "      <td>low</td>\n",
       "      <td>Formality</td>\n",
       "      <td>Trustworthiness</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11311</th>\n",
       "      <td>2</td>\n",
       "      <td>000000v000100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.875</td>\n",
       "      <td>low</td>\n",
       "      <td>Formality</td>\n",
       "      <td>Transparency</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PROLIFIC_PID ExplanationPair  Need_for_Cognition  Need_for_closure  \\\n",
       "16576            2   000000v000010                 0.7             0.375   \n",
       "16771            2   000000v000010                 0.7             0.375   \n",
       "16966            2   000000v000010                 0.7             0.375   \n",
       "11116            2   000000v000100                 0.7             0.375   \n",
       "11311            2   000000v000100                 0.7             0.375   \n",
       "\n",
       "       Susceptibility_to_persuasion  Skepticism  AI_Expertise Domain  \\\n",
       "16576                        0.6875      0.5625         0.875    low   \n",
       "16771                        0.6875      0.5625         0.875    low   \n",
       "16966                        0.6875      0.5625         0.875    low   \n",
       "11116                        0.6875      0.5625         0.875    low   \n",
       "11311                        0.6875      0.5625         0.875    low   \n",
       "\n",
       "      flipped_dim       MetricType  Evaluation  \n",
       "16576      Detail  Trustworthiness           1  \n",
       "16771      Detail     Transparency           1  \n",
       "16966      Detail       Usefulness           1  \n",
       "11116   Formality  Trustworthiness           1  \n",
       "11311   Formality     Transparency           1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store dataframe used for logistic regressions\n",
    "final_data.columns = [col.replace(\" \", \"_\") for col in final_data.columns]\n",
    "final_data.to_csv(\"../results/evaluations_jobs.csv\")\n",
    "\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9727891a-68fc-4bf9-9ff5-3b657901b0fa",
   "metadata": {},
   "source": [
    "## Fitting the mixed-effects logistic regression model (without personalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabf6cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# Load required libraries\n",
    "library(lme4)\n",
    "library(dplyr)\n",
    "library(stats)\n",
    "\n",
    "# Load the data\n",
    "data <- read.csv(\"../results/evaluations.csv\")\n",
    "\n",
    "# Set categorical variables\n",
    "data$flipped_dim <- factor(data$flipped_dim, \n",
    "                           levels = c(\"Structure\", \"Length\", \"Formality\", \"Detail\", \"Persuasiveness\"))\n",
    "\n",
    "data$MetricType <- factor(data$MetricType, \n",
    "                          levels = c(\"Trustworthiness\", \"Usefulness\", \"Transparency\"))\n",
    "\n",
    "data$Domain <- factor(data$Domain, \n",
    "                      levels = c(\"high\", \"low\"))\n",
    "\n",
    "# Fit the mixed-effects logistic regression model\n",
    "model <- glmer(Evaluation ~ flipped_dim + MetricType + Domain +\n",
    "                 (1 | PROLIFIC_PID), \n",
    "               data = data, \n",
    "               family = binomial,\n",
    "               control = glmerControl(optimizer = \"bobyqa\", \n",
    "                                      optCtrl = list(maxfun = 1e6))\n",
    "               )\n",
    "\n",
    "print(summary(model))\n",
    "\n",
    "# Extract fixed effect coefficients\n",
    "coefs <- fixef(model)\n",
    "\n",
    "# Extract variance-covariance matrix\n",
    "vcov_matrix <- vcov(model)\n",
    "\n",
    "# Separate main effects and interaction terms\n",
    "main_effects <- coefs[grepl(\"^flipped_dim\", names(coefs))]\n",
    "\n",
    "# Derive the missing coefficient for 'Structure' (main effect)\n",
    "structure_main_effect <- -sum(main_effects)\n",
    "\n",
    "# Calculate standard errors for the missing coefficients\n",
    "# Main effect for 'Structure'\n",
    "main_effect_vars <- diag(vcov_matrix)[grepl(\"^flipped_dim\", names(coefs))]\n",
    "main_effect_covs <- vcov_matrix[grepl(\"^flipped_dim\", names(coefs)), grepl(\"^flipped_dim\", names(coefs))]\n",
    "main_effect_se <- sqrt(sum(main_effect_vars) + 2 * sum(main_effect_covs[lower.tri(main_effect_covs)]))\n",
    "\n",
    "# Calculate z-scores and p-values\n",
    "structure_main_z <- structure_main_effect / main_effect_se\n",
    "structure_main_p <- 2 * (1 - pnorm(abs(structure_main_z)))\n",
    "\n",
    "# Combine results into a data frame\n",
    "# Main effects\n",
    "main_results <- data.frame(\n",
    "  Predictor = gsub(\"flipped_dim\", \"\", names(main_effects)),\n",
    "  Coefficient = main_effects,\n",
    "  SE = sqrt(diag(vcov_matrix)[grepl(\"^flipped_dim\", names(coefs))]),\n",
    "  z = main_effects / sqrt(diag(vcov_matrix)[grepl(\"^flipped_dim\", names(coefs))]),\n",
    "  p_value = 2 * (1 - pnorm(abs(main_effects / sqrt(diag(vcov_matrix)[grepl(\"^flipped_dim\", names(coefs))]))))\n",
    ")\n",
    "\n",
    "# Missing coefficients (Structure)\n",
    "structure_results <- data.frame(\n",
    "  Predictor = \"Structure\",\n",
    "  Coefficient = structure_main_effect,\n",
    "  SE = main_effect_se,\n",
    "  z = structure_main_z,\n",
    "  p_value = structure_main_p\n",
    ")\n",
    "\n",
    "# Combine all results, explicitly including the intercept\n",
    "intercept_result <- data.frame(\n",
    "  Predictor = \"(Intercept)\",\n",
    "  Coefficient = coefs[\"(Intercept)\"],\n",
    "  SE = sqrt(diag(vcov_matrix)[\"(Intercept)\"]),\n",
    "  z = coefs[\"(Intercept)\"] / sqrt(diag(vcov_matrix)[\"(Intercept)\"]),\n",
    "  p_value = 2 * (1 - pnorm(abs(coefs[\"(Intercept)\"] / sqrt(diag(vcov_matrix)[\"(Intercept)\"]))))\n",
    ")\n",
    "\n",
    "# Combine all results\n",
    "final_results <- bind_rows(intercept_result, main_results, structure_results)\n",
    "\n",
    "# Format the table and include significance levels\n",
    "final_results <- final_results %>%\n",
    "  mutate(\n",
    "    Coefficient = round(Coefficient, 3),\n",
    "    SE = round(SE, 3),\n",
    "    z = round(z, 3),\n",
    "    p_value = round(p_value, 3),\n",
    "    Significance = case_when(\n",
    "      p_value < 0.001 ~ \"***\",\n",
    "      p_value < 0.01 ~ \"**\",\n",
    "      p_value < 0.05 ~ \"*\",\n",
    "      TRUE ~ \"\"\n",
    "    )\n",
    "  )\n",
    "\n",
    "# Fix ordering\n",
    "rownames(final_results) <- NULL\n",
    "custom_order <- c(\"(Intercept)\", \"Detail\", \"Formality\", \"Length\", \"Persuasiveness\", \"Structure\")\n",
    "\n",
    "final_results <- final_results[match(custom_order, final_results$Predictor), ]\n",
    "\n",
    "write.csv(final_results, \"../results/final_results_general.csv\", row.names = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce079b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictor</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>SE</th>\n",
       "      <th>Odds Ratio</th>\n",
       "      <th>Corrected p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Intercept)</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.096</td>\n",
       "      <td>1.419068</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Detail</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.097</td>\n",
       "      <td>1.648721</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Formality</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.097</td>\n",
       "      <td>1.403543</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Length</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.102</td>\n",
       "      <td>2.640584</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Persuasiveness</td>\n",
       "      <td>-0.746</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.474260</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Structure</td>\n",
       "      <td>-1.064</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.345073</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Predictor  Coefficient     SE  Odds Ratio  Corrected p-value\n",
       "0     (Intercept)        0.350  0.096    1.419068                0.0\n",
       "1          Detail        0.500  0.097    1.648721                0.0\n",
       "2       Formality        0.339  0.097    1.403543                0.0\n",
       "3          Length        0.971  0.102    2.640584                0.0\n",
       "4  Persuasiveness       -0.746  0.096    0.474260                0.0\n",
       "5       Structure       -1.064  0.303    0.345073                0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Routput = pd.read_csv(\"../results/final_results_general_jobs.csv\")\n",
    "\n",
    "corr = statsmodels.stats.multitest.fdrcorrection(Routput[\"p_value\"],\n",
    "                                                 alpha=0.05, \n",
    "                                                 method='indep',\n",
    "                                                 is_sorted=False)\n",
    "\n",
    "Routput[\"Odds Ratio\"] = np.exp(Routput[\"Coefficient\"])\n",
    "Routput[\"Corrected p-value\"] = corr[1]\n",
    "Routput[\"Reject H0\"] = corr[0]\n",
    "\n",
    "Routput[[\"Predictor\", \"Coefficient\", \"SE\", \"Odds Ratio\", \"Corrected p-value\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a3a3d1",
   "metadata": {},
   "source": [
    "## Fitting the mixed-effects logistic regression model (with personalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfee713",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# Load required libraries\n",
    "library(lme4)\n",
    "library(dplyr)\n",
    "library(stats)\n",
    "\n",
    "# Load the data\n",
    "data <- read.csv(\"../results/evaluations.csv\")\n",
    "\n",
    "# Set categorical variables\n",
    "data$flipped_dim <- factor(data$flipped_dim, \n",
    "                           levels = c(\"Structure\", \"Length\", \"Formality\", \"Detail\", \"Persuasiveness\"))\n",
    "\n",
    "data$MetricType <- factor(data$MetricType, \n",
    "                          levels = c(\"Trustworthiness\", \"Usefulness\", \"Transparency\"))\n",
    "\n",
    "data$Domain <- factor(data$Domain, \n",
    "                      levels = c(\"high\", \"low\"))\n",
    "\n",
    "# Fit the mixed-effects logistic regression model\n",
    "model <- glmer(Evaluation ~ Need_for_Cognition + Need_for_closure + \n",
    "                 Susceptibility_to_persuasion + Skepticism + \n",
    "                 AI_Expertise + flipped_dim + MetricType + Domain +\n",
    "                 (Need_for_Cognition + Need_for_closure + Susceptibility_to_persuasion + \n",
    "                    Skepticism + AI_Expertise):flipped_dim + \n",
    "                 (1 | PROLIFIC_PID), \n",
    "               data = data, \n",
    "               family = binomial,\n",
    "               control = glmerControl(optimizer = \"bobyqa\", \n",
    "                                      optCtrl = list(maxfun = 1e6))\n",
    "               )\n",
    "\n",
    "print(summary(model))\n",
    "\n",
    "# Extract fixed effect coefficients\n",
    "coefs <- fixef(model)\n",
    "\n",
    "# Extract variance-covariance matrix\n",
    "vcov_matrix <- vcov(model)\n",
    "\n",
    "# Separate main effects and interaction terms\n",
    "main_effects <- coefs[grepl(\"^flipped_dim\", names(coefs))]\n",
    "interaction_terms <- coefs[grepl(\":flipped_dim\", names(coefs))]\n",
    "continuous_effects <- coefs[!grepl(\"flipped_dim\", names(coefs)) & !grepl(\":\", names(coefs))]\n",
    "\n",
    "# Derive the missing coefficient for 'Structure' (main effect)\n",
    "structure_main_effect <- -sum(main_effects)\n",
    "\n",
    "# Derive the missing coefficients for 'Structure' (interactions)\n",
    "predictors <- c(\"Need_for_Cognition\", \"Need_for_closure\", \n",
    "                \"Susceptibility_to_persuasion\", \"Skepticism\", \"AI_Expertise\")\n",
    "structure_interactions <- sapply(predictors, function(pred) {\n",
    "  interaction_coefs <- coefs[grepl(paste0(pred, \":flipped_dim\"), names(coefs))]\n",
    "  -sum(interaction_coefs)\n",
    "})\n",
    "\n",
    "# Calculate standard errors for the missing coefficients\n",
    "# Main effect for 'Structure'\n",
    "main_effect_vars <- diag(vcov_matrix)[grepl(\"^flipped_dim\", names(coefs))]\n",
    "main_effect_covs <- vcov_matrix[grepl(\"^flipped_dim\", names(coefs)), grepl(\"^flipped_dim\", names(coefs))]\n",
    "main_effect_se <- sqrt(sum(main_effect_vars) + 2 * sum(main_effect_covs[lower.tri(main_effect_covs)]))\n",
    "\n",
    "# Interactions for 'Structure'\n",
    "interaction_se <- sapply(1:length(predictors), function(i) {\n",
    "  pred <- predictors[i]\n",
    "  interaction_indices <- which(grepl(paste0(pred, \":flipped_dim\"), names(coefs)))\n",
    "  interaction_vars <- diag(vcov_matrix)[interaction_indices]\n",
    "  interaction_covs <- vcov_matrix[interaction_indices, interaction_indices]\n",
    "  sqrt(sum(interaction_vars) + 2 * sum(interaction_covs[lower.tri(interaction_covs)]))\n",
    "})\n",
    "\n",
    "# Calculate z-scores and p-values\n",
    "structure_main_z <- structure_main_effect / main_effect_se\n",
    "structure_main_p <- 2 * (1 - pnorm(abs(structure_main_z)))\n",
    "\n",
    "interaction_z <- structure_interactions / interaction_se\n",
    "interaction_p <- 2 * (1 - pnorm(abs(interaction_z)))\n",
    "\n",
    "# Combine results into a data frame\n",
    "# Main effects\n",
    "main_results <- data.frame(\n",
    "  Predictor = gsub(\"flipped_dim\", \"\", names(main_effects)),\n",
    "  Coefficient = main_effects,\n",
    "  SE = sqrt(diag(vcov_matrix)[grepl(\"^flipped_dim\", names(coefs))]),\n",
    "  z = main_effects / sqrt(diag(vcov_matrix)[grepl(\"^flipped_dim\", names(coefs))]),\n",
    "  p_value = 2 * (1 - pnorm(abs(main_effects / sqrt(diag(vcov_matrix)[grepl(\"^flipped_dim\", names(coefs))]))))\n",
    ")\n",
    "\n",
    "# Continuous predictors (retain as-is)\n",
    "continuous_results <- data.frame(\n",
    "  Predictor = names(continuous_effects),\n",
    "  Coefficient = continuous_effects,\n",
    "  SE = sqrt(diag(vcov_matrix)[!grepl(\"flipped_dim\", names(coefs)) & !grepl(\":\", names(coefs))]),\n",
    "  z = continuous_effects / sqrt(diag(vcov_matrix)[!grepl(\"flipped_dim\", names(coefs)) & !grepl(\":\", names(coefs))]),\n",
    "  p_value = 2 * (1 - pnorm(abs(continuous_effects / sqrt(diag(vcov_matrix)[!grepl(\"flipped_dim\", names(coefs)) & !grepl(\":\", names(coefs))]))))\n",
    ")\n",
    "\n",
    "# Interaction terms\n",
    "interaction_results <- data.frame(\n",
    "  Predictor = gsub(\":flipped_dim\", \":\", names(interaction_terms)),\n",
    "  Coefficient = interaction_terms,\n",
    "  SE = sqrt(diag(vcov_matrix)[grepl(\":flipped_dim\", names(coefs))]),\n",
    "  z = interaction_terms / sqrt(diag(vcov_matrix)[grepl(\":flipped_dim\", names(coefs))]),\n",
    "  p_value = 2 * (1 - pnorm(abs(interaction_terms / sqrt(diag(vcov_matrix)[grepl(\":flipped_dim\", names(coefs))]))))\n",
    ")\n",
    "\n",
    "# Missing coefficients (Structure)\n",
    "structure_results <- data.frame(\n",
    "  Predictor = c(\"Structure\", paste0(predictors, \":Structure\")),\n",
    "  Coefficient = c(structure_main_effect, structure_interactions),\n",
    "  SE = c(main_effect_se, interaction_se),\n",
    "  z = c(structure_main_z, interaction_z),\n",
    "  p_value = c(structure_main_p, interaction_p)\n",
    ")\n",
    "\n",
    "# Combine all results\n",
    "final_results <- bind_rows(continuous_results, main_results, interaction_results, structure_results)\n",
    "\n",
    "# Format the table and include significance levels\n",
    "final_results <- final_results %>%\n",
    "  mutate(\n",
    "    Coefficient = round(Coefficient, 3),\n",
    "    SE = round(SE, 3),\n",
    "    z = round(z, 3),\n",
    "    p_value = round(p_value, 3),\n",
    "    Significance = case_when(\n",
    "      p_value < 0.001 ~ \"***\",\n",
    "      p_value < 0.01 ~ \"**\",\n",
    "      p_value < 0.05 ~ \"*\",\n",
    "      TRUE ~ \"\"\n",
    "    )\n",
    "  )\n",
    "\n",
    "# Fix ordering\n",
    "rownames(final_results) <- NULL\n",
    "custom_order <- c(\"(Intercept)\", \"Need_for_Cognition\", \"Need_for_closure\", \"Susceptibility_to_persuasion\",\n",
    "                  \"Skepticism\", \"AI_Expertise\", \"Detail\", \"Formality\", \"Length\", \"Persuasiveness\", \"Structure\",\n",
    "                  \"Need_for_Cognition:Detail\", \"Need_for_Cognition:Formality\", \"Need_for_Cognition:Length\",\n",
    "                  \"Need_for_Cognition:Persuasiveness\", \"Need_for_Cognition:Structure\", \"Need_for_closure:Detail\", \n",
    "                  \"Need_for_closure:Formality\", \"Need_for_closure:Length\", \"Need_for_closure:Persuasiveness\", \n",
    "                  \"Need_for_closure:Structure\", \"Susceptibility_to_persuasion:Detail\", \"Susceptibility_to_persuasion:Formality\",\n",
    "                  \"Susceptibility_to_persuasion:Length\", \"Susceptibility_to_persuasion:Persuasiveness\",\n",
    "                  \"Susceptibility_to_persuasion:Structure\", \"Skepticism:Detail\", \"Skepticism:Formality\", \n",
    "                  \"Skepticism:Length\", \"Skepticism:Persuasiveness\", \"Skepticism:Structure\", \"AI_Expertise:Detail\",\n",
    "                  \"AI_Expertise:Formality\",\"AI_Expertise:Length\",\"AI_Expertise:Persuasiveness\",\"AI_Expertise:Structure\")\n",
    "\n",
    "final_results <- final_results[match(custom_order, final_results$Predictor), ]\n",
    "\n",
    "write.csv(final_results, \"../results/final_results_personal.csv\", row.names = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18c8492a-90d1-4abd-bd1e-63c1d5af8d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictor</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>SE</th>\n",
       "      <th>Odds Ratio</th>\n",
       "      <th>z</th>\n",
       "      <th>Corrected p-value</th>\n",
       "      <th>Reject H0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Intercept)</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.714</td>\n",
       "      <td>1.622552</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.584129</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Need_for_Cognition</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.843665</td>\n",
       "      <td>-0.278</td>\n",
       "      <td>0.826941</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Need_for_closure</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.623</td>\n",
       "      <td>1.655329</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.584129</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Susceptibility_to_persuasion</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.538</td>\n",
       "      <td>1.290462</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.714375</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skepticism</td>\n",
       "      <td>-1.321</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.266868</td>\n",
       "      <td>-1.882</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AI_Expertise</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.593</td>\n",
       "      <td>1.997707</td>\n",
       "      <td>1.167</td>\n",
       "      <td>0.473400</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Detail</td>\n",
       "      <td>1.009</td>\n",
       "      <td>0.901</td>\n",
       "      <td>2.742857</td>\n",
       "      <td>1.119</td>\n",
       "      <td>0.473400</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Formality</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.880</td>\n",
       "      <td>1.813031</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.584129</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Length</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.847</td>\n",
       "      <td>1.851507</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.584129</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Persuasiveness</td>\n",
       "      <td>-1.638</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.194368</td>\n",
       "      <td>-1.892</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Structure</td>\n",
       "      <td>-0.582</td>\n",
       "      <td>2.710</td>\n",
       "      <td>0.558780</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>0.853714</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Need_for_Cognition:Detail</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.745</td>\n",
       "      <td>2.318685</td>\n",
       "      <td>1.129</td>\n",
       "      <td>0.473400</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Need_for_Cognition:Formality</td>\n",
       "      <td>1.348</td>\n",
       "      <td>0.740</td>\n",
       "      <td>3.849718</td>\n",
       "      <td>1.822</td>\n",
       "      <td>0.188308</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Need_for_Cognition:Length</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.745</td>\n",
       "      <td>1.707448</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.584129</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Need_for_Cognition:Persuasiveness</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.717</td>\n",
       "      <td>1.014098</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Need_for_Cognition:Structure</td>\n",
       "      <td>-2.737</td>\n",
       "      <td>2.324</td>\n",
       "      <td>0.064764</td>\n",
       "      <td>-1.178</td>\n",
       "      <td>0.473400</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Need_for_closure:Detail</td>\n",
       "      <td>-2.751</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.063864</td>\n",
       "      <td>-3.485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Need_for_closure:Formality</td>\n",
       "      <td>-0.738</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.478069</td>\n",
       "      <td>-0.949</td>\n",
       "      <td>0.559636</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Need_for_closure:Length</td>\n",
       "      <td>-2.401</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.090627</td>\n",
       "      <td>-3.115</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Need_for_closure:Persuasiveness</td>\n",
       "      <td>-0.662</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.515819</td>\n",
       "      <td>-0.893</td>\n",
       "      <td>0.582261</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Need_for_closure:Structure</td>\n",
       "      <td>6.553</td>\n",
       "      <td>2.349</td>\n",
       "      <td>701.345056</td>\n",
       "      <td>2.789</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Susceptibility_to_persuasion:Detail</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.370834</td>\n",
       "      <td>-1.416</td>\n",
       "      <td>0.376800</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Susceptibility_to_persuasion:Formality</td>\n",
       "      <td>-1.884</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.151981</td>\n",
       "      <td>-2.711</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Susceptibility_to_persuasion:Length</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.831104</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>0.826941</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Susceptibility_to_persuasion:Persuasiveness</td>\n",
       "      <td>1.677</td>\n",
       "      <td>0.677</td>\n",
       "      <td>5.349483</td>\n",
       "      <td>2.479</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Susceptibility_to_persuasion:Structure</td>\n",
       "      <td>1.383</td>\n",
       "      <td>2.064</td>\n",
       "      <td>3.986844</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.584129</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Skepticism:Detail</td>\n",
       "      <td>3.332</td>\n",
       "      <td>0.876</td>\n",
       "      <td>27.994274</td>\n",
       "      <td>3.804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Skepticism:Formality</td>\n",
       "      <td>1.882</td>\n",
       "      <td>0.833</td>\n",
       "      <td>6.566625</td>\n",
       "      <td>2.258</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Skepticism:Length</td>\n",
       "      <td>2.358</td>\n",
       "      <td>0.867</td>\n",
       "      <td>10.569791</td>\n",
       "      <td>2.721</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Skepticism:Persuasiveness</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.802</td>\n",
       "      <td>1.833084</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.584129</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Skepticism:Structure</td>\n",
       "      <td>-8.178</td>\n",
       "      <td>2.661</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>-3.073</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>AI_Expertise:Detail</td>\n",
       "      <td>-1.569</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.208253</td>\n",
       "      <td>-2.035</td>\n",
       "      <td>0.151200</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>AI_Expertise:Formality</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.370834</td>\n",
       "      <td>-1.359</td>\n",
       "      <td>0.391500</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>AI_Expertise:Length</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.472839</td>\n",
       "      <td>-1.021</td>\n",
       "      <td>0.526286</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>AI_Expertise:Persuasiveness</td>\n",
       "      <td>-0.546</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.579262</td>\n",
       "      <td>-0.761</td>\n",
       "      <td>0.584129</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>AI_Expertise:Structure</td>\n",
       "      <td>3.856</td>\n",
       "      <td>2.251</td>\n",
       "      <td>47.275869</td>\n",
       "      <td>1.713</td>\n",
       "      <td>0.223714</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Predictor  Coefficient     SE  \\\n",
       "0                                   (Intercept)        0.484  0.714   \n",
       "1                            Need_for_Cognition       -0.170  0.611   \n",
       "2                              Need_for_closure        0.504  0.623   \n",
       "3                  Susceptibility_to_persuasion        0.255  0.538   \n",
       "4                                    Skepticism       -1.321  0.702   \n",
       "5                                  AI_Expertise        0.692  0.593   \n",
       "6                                        Detail        1.009  0.901   \n",
       "7                                     Formality        0.595  0.880   \n",
       "8                                        Length        0.616  0.847   \n",
       "9                                Persuasiveness       -1.638  0.866   \n",
       "10                                    Structure       -0.582  2.710   \n",
       "11                    Need_for_Cognition:Detail        0.841  0.745   \n",
       "12                 Need_for_Cognition:Formality        1.348  0.740   \n",
       "13                    Need_for_Cognition:Length        0.535  0.745   \n",
       "14            Need_for_Cognition:Persuasiveness        0.014  0.717   \n",
       "15                 Need_for_Cognition:Structure       -2.737  2.324   \n",
       "16                      Need_for_closure:Detail       -2.751  0.789   \n",
       "17                   Need_for_closure:Formality       -0.738  0.777   \n",
       "18                      Need_for_closure:Length       -2.401  0.771   \n",
       "19              Need_for_closure:Persuasiveness       -0.662  0.741   \n",
       "20                   Need_for_closure:Structure        6.553  2.349   \n",
       "21          Susceptibility_to_persuasion:Detail       -0.992  0.700   \n",
       "22       Susceptibility_to_persuasion:Formality       -1.884  0.695   \n",
       "23          Susceptibility_to_persuasion:Length       -0.185  0.649   \n",
       "24  Susceptibility_to_persuasion:Persuasiveness        1.677  0.677   \n",
       "25       Susceptibility_to_persuasion:Structure        1.383  2.064   \n",
       "26                            Skepticism:Detail        3.332  0.876   \n",
       "27                         Skepticism:Formality        1.882  0.833   \n",
       "28                            Skepticism:Length        2.358  0.867   \n",
       "29                    Skepticism:Persuasiveness        0.606  0.802   \n",
       "30                         Skepticism:Structure       -8.178  2.661   \n",
       "31                          AI_Expertise:Detail       -1.569  0.771   \n",
       "32                       AI_Expertise:Formality       -0.992  0.730   \n",
       "33                          AI_Expertise:Length       -0.749  0.734   \n",
       "34                  AI_Expertise:Persuasiveness       -0.546  0.717   \n",
       "35                       AI_Expertise:Structure        3.856  2.251   \n",
       "\n",
       "    Odds Ratio      z  Corrected p-value  Reject H0  \n",
       "0     1.622552  0.677           0.584129      False  \n",
       "1     0.843665 -0.278           0.826941      False  \n",
       "2     1.655329  0.809           0.584129      False  \n",
       "3     1.290462  0.474           0.714375      False  \n",
       "4     0.266868 -1.882           0.180000      False  \n",
       "5     1.997707  1.167           0.473400      False  \n",
       "6     2.742857  1.119           0.473400      False  \n",
       "7     1.813031  0.677           0.584129      False  \n",
       "8     1.851507  0.728           0.584129      False  \n",
       "9     0.194368 -1.892           0.180000      False  \n",
       "10    0.558780 -0.215           0.853714      False  \n",
       "11    2.318685  1.129           0.473400      False  \n",
       "12    3.849718  1.822           0.188308      False  \n",
       "13    1.707448  0.717           0.584129      False  \n",
       "14    1.014098  0.020           0.984000      False  \n",
       "15    0.064764 -1.178           0.473400      False  \n",
       "16    0.063864 -3.485           0.000000       True  \n",
       "17    0.478069 -0.949           0.559636      False  \n",
       "18    0.090627 -3.115           0.018000       True  \n",
       "19    0.515819 -0.893           0.582261      False  \n",
       "20  701.345056  2.789           0.036000       True  \n",
       "21    0.370834 -1.416           0.376800      False  \n",
       "22    0.151981 -2.711           0.036000       True  \n",
       "23    0.831104 -0.285           0.826941      False  \n",
       "24    5.349483  2.479           0.058500      False  \n",
       "25    3.986844  0.670           0.584129      False  \n",
       "26   27.994274  3.804           0.000000       True  \n",
       "27    6.566625  2.258           0.096000      False  \n",
       "28   10.569791  2.721           0.036000       True  \n",
       "29    1.833084  0.756           0.584129      False  \n",
       "30    0.000281 -3.073           0.018000       True  \n",
       "31    0.208253 -2.035           0.151200      False  \n",
       "32    0.370834 -1.359           0.391500      False  \n",
       "33    0.472839 -1.021           0.526286      False  \n",
       "34    0.579262 -0.761           0.584129      False  \n",
       "35   47.275869  1.713           0.223714      False  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Routput = pd.read_csv(\"../results/final_results_personal_ads.csv\")\n",
    "\n",
    "corr = statsmodels.stats.multitest.fdrcorrection(Routput[\"p_value\"],\n",
    "                                                 alpha=0.05, \n",
    "                                                 method='indep',\n",
    "                                                 is_sorted=False)\n",
    "\n",
    "Routput[\"Odds Ratio\"] = np.exp(Routput[\"Coefficient\"])\n",
    "Routput[\"Corrected p-value\"] = corr[1]\n",
    "Routput[\"Reject H0\"] = corr[0]\n",
    "\n",
    "Routput[[\"Predictor\", \"Coefficient\", \"SE\", \"Odds Ratio\", \"z\", \"Corrected p-value\", \"Reject H0\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882dc48d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
